,TweetID,AuthorID,AuthorName,Tweets,arxiv_link,Abstract,Title
0,826517996420071424,377116752,Dr. Erika Palmerio,['New paper up on #arXiv! We talk about the magnetic structure of CMEs as they leave the Sun ☀️ Check it out here: <LINK>'],https://arxiv.org/abs/1701.08595,"A key aim in space weather research is to be able to use remote-sensing observations of the solar atmosphere to extend the lead time of predicting the geoeffectiveness of a coronal mass ejection (CME). In order to achieve this, the magnetic structure of the CME as it leaves the Sun must be known. In this article we address this issue by developing a method to determine the intrinsic flux rope type of a CME solely from solar disk observations. We use several well known proxies for the magnetic helicity sign, the axis orientation, and the axial magnetic field direction to predict the magnetic structure of the interplanetary flux rope. We present two case studies: the 2 June 2011 and the 14 June 2012 CMEs. Both of these events erupted from an active region and, despite having clear in situ counterparts, their eruption characteristics were relatively complex. The first event was associated with an active region filament that erupted in two stages, while for the other event the eruption originated from a relatively high coronal altitude and the source region did not feature the presence of a filament. Our magnetic helicity sign proxies include the analysis of magnetic tongues, soft X-ray and/or EUV sigmoids, coronal arcade skew, filament emission and absorption threads, and filament rotation. Since the inclination of the post-eruption arcades was not clear, we use the tilt of the polarity inversion line to determine the flux rope axis orientation, and coronal dimmings to determine the flux rope footpoints and, therefore, the direction of the axial magnetic field. The comparison of the estimated intrinsic flux rope structure to in situ observations at the Lagrangian point L1 indicated a good agreement with the predictions. Our results highlight the flux rope type determination techniques that are particularly useful for active region eruptions, where most geoeffective CMEs originate. ","Determining the Intrinsic CME Flux Rope Type Using Remote-sensing Solar
  Disk Observations"
1,826445720479756290,752505338511908864,Caglar Gulcehre,['Our paper on a new MANN(TARDIS) and analysis on the MANNs is on arXiv: <LINK>'],https://arxiv.org/abs/1701.08718,"Recent empirical results on long-term dependency tasks have shown that neural networks augmented with an external memory can learn the long-term dependency tasks more easily and achieve better generalization than vanilla recurrent neural networks (RNN). We suggest that memory augmented neural networks can reduce the effects of vanishing gradients by creating shortcut (or wormhole) connections. Based on this observation, we propose a novel memory augmented neural network model called TARDIS (Temporal Automatic Relation Discovery in Sequences). The controller of TARDIS can store a selective set of embeddings of its own previous hidden states into an external memory and revisit them as and when needed. For TARDIS, memory acts as a storage for wormhole connections to the past to propagate the gradients more effectively and it helps to learn the temporal dependencies. The memory structure of TARDIS has similarities to both Neural Turing Machines (NTM) and Dynamic Neural Turing Machines (D-NTM), but both read and write operations of TARDIS are simpler and more efficient. We use discrete addressing for read/write operations which helps to substantially to reduce the vanishing gradient problem with very long sequences. Read and write operations in TARDIS are tied with a heuristic once the memory becomes full, and this makes the learning problem simpler when compared to NTM or D-NTM type of architectures. We provide a detailed analysis on the gradient propagation in general for MANNs. We evaluate our models on different long-term dependency tasks and report competitive results in all of them. ",Memory Augmented Neural Networks with Wormhole Connections
2,826351829453832192,292313052,Martin Kilbinger,['New paper from my former student @Linc_tw <LINK> !'],https://arxiv.org/abs/1701.08748,"Two of the main problems encountered in the development and accurate validation of photometric redshift (photo-z) techniques are the lack of spectroscopic coverage in feature space (e.g. colours and magnitudes) and the mismatch between photometric error distributions associated with the spectroscopic and photometric samples. Although these issues are well known, there is currently no standard benchmark allowing a quantitative analysis of their impact on the final photo-z estimation. In this work, we present two galaxy catalogues, Teddy and Happy, built to enable a more demanding and realistic test of photo-z methods. Using photometry from the Sloan Digital Sky Survey and spectroscopy from a collection of sources, we constructed datasets which mimic the biases between the underlying probability distribution of the real spectroscopic and photometric sample. We demonstrate the potential of these catalogues by submitting them to the scrutiny of different photo-z methods, including machine learning (ML) and template fitting approaches. Beyond the expected bad results from most ML algorithms for cases with missing coverage in feature space, we were able to recognize the superiority of global models in the same situation and the general failure across all types of methods when incomplete coverage is convoluted with the presence of photometric errors - a data situation which photo-z methods were not trained to deal with up to now and which must be addressed by future large scale surveys. Our catalogues represent the first controlled environment allowing a straightforward implementation of such tests. The data are publicly available within the COINtoolbox (this https URL). ","On the realistic validation of photometric redshifts, or why Teddy will
  never be Happy"
3,826023527065194498,2444384845,Dr Viviane Pons,['My new paper is on ArXiv :) :) <LINK>'],https://arxiv.org/abs/1701.07995,"We explore lattice structures on integer binary relations (i.e. binary relations on the set $\{1, 2, \dots, n\}$ for a fixed integer $n$) and on integer posets (i.e. partial orders on the set $\{1, 2, \dots, n\}$ for a fixed integer $n$). We first observe that the weak order on the symmetric group naturally extends to a lattice structure on all integer binary relations. We then show that the subposet of this weak order induced by integer posets defines as well a lattice. We finally study the subposets of this weak order induced by specific families of integer posets corresponding to the elements, the intervals, and the faces of the permutahedron, the associahedron, and some recent generalizations of those. ",The weak order on integer posets
4,825001305462550528,1653127615,Chris Monahan,['New paper on the #arXiv <LINK> #physics #staggeredaintsobad'],https://arxiv.org/abs/1701.07559,"We report on salient features of a mixed lattice QCD action using valence M\""{o}bius domain-wall fermions solved on the dynamical $N_f=2+1+1$ HISQ ensembles generated by the MILC Collaboration. The approximate chiral symmetry properties of the valence fermions are shown to be significantly improved by utilizing the gradient-flow scheme to first smear the HISQ configurations. The greater numerical cost of the M\""{o}bius domain-wall inversions is mitigated by the highly efficient QUDA library optimized for NVIDIA GPU accelerated compute nodes. We have created an interface to this optimized QUDA solver in Chroma. We provide tuned parameters of the action and performance of QUDA using ensembles with the lattice spacings $a \simeq \{0.15, 0.12, 0.09\}$ fm and pion masses $m_\pi \simeq \{310, 220,130\}$ MeV. We have additionally generated two new ensembles with $a\sim0.12$ fm and $m_\pi\sim\{400, 350\}$ MeV. With a fixed flow-time of $t_{gf}=1$ in lattice units, the residual chiral symmetry breaking of the valence fermions is kept below 10\% of the light quark mass on all ensembles, $m_{res} \lesssim 0.1\times m_l$, with moderate values of the fifth dimension $L_5$ and a domain-wall height $M_5 \leq 1.3$. As a benchmark calculation, we perform a continuum, infinite volume, physical pion and kaon mass extrapolation of $F_{K^\pm}/F_{\pi^\pm}$ and demonstrate our results are independent of flow-time, and consistent with the FLAG determination of this quantity at the level of less than one standard deviation. ","M\""obius domain-wall fermions on gradient-flowed dynamical HISQ
  ensembles"
5,824887299909443587,1710697381,Diego F. Torres,"['New paper: ""Dust radiative transfer modelling of the infrared ring around the magnetar SGR 1900+14"" <LINK> <LINK>']",https://arxiv.org/abs/1701.07442,"A peculiar infrared ring-like structure was discovered by {\em Spitzer} around the strongly magnetised neutron star SGR 1900$+$14. This infrared structure was suggested to be due to a dust-free cavity, produced by the SGR Giant Flare occurred in 1998, and kept illuminated by surrounding stars. Using a 3D dust radiative transfer code, we aimed at reproducing the emission morphology and the integrated emission flux of this structure assuming different spatial distributions and densities for the dust, and different positions for the illuminating stars. We found that a dust-free ellipsoidal cavity can reproduce the shape, flux, and spectrum of the ring-like infrared emission, provided that the illuminating stars are inside the cavity and that the interstellar medium has high gas density ($n_H\sim$1000 cm$^{-3}$). We further constrain the emitting region to have a sharp inner boundary and to be significantly extended in the radial direction, possibly even just a cavity in a smooth molecular cloud. We discuss possible scenarios for the formation of the dustless cavity and the particular geometry that allows it to be IR-bright. ","Dust radiative transfer modelling of the infrared ring around the
  magnetar SGR 1900$+$14"
6,824431386639667200,169081481,Hanno Rein 💫,"['New paper with Dan Tamayo is out. We describe how to reproduce numerical experiments bit by bit. <LINK>', 'This is crucial if the system is chaotic. Even the smallest difference at machine precision (10⁻¹⁶) will lead to different outcomes.', 'The Solar System is an example of a chaotic system. Changing the position of the Earth by just 1m could lead to a collision in 5 Gyrs.', 'Simulating the Solar System accurately for 5 Gyrs takes weeks or months. Previously, it was not possible to reproduce such a simulation.', 'With the SimulationArchive, one now can reproduce these simulations bit-by-bit. Independent of operating system, compiler/library version.', 'There are other benefits to the SimulationArchive: One never has to worry again about which parameters to output or output cadence.', 'All this can be decided after the simulation has finished (or while it’s running). We think this will revolutionize how analyses are done.', '@astrocrash Good question! I actually did that calculation a while ago. What matters is the memory used. Here, it’s minimal, a few kilobytes', '@astrocrash If you are google and you have terabytes in RAM, then you have to take it into account.']",https://arxiv.org/abs/1701.07423,"The reproducibility of experiments is one of the main principles of the scientific method. However, numerical N-body experiments, especially those of planetary systems, are currently not reproducible. In the most optimistic scenario, they can only be replicated in an approximate or statistical sense. Even if authors share their full source code and initial conditions, differences in compilers, libraries, operating systems or hardware often lead to qualitatively different results. We provide a new set of easy-to-use, open-source tools that address the above issues, allowing for exact (bit-by-bit) reproducibility of N-body experiments. In addition to generating completely reproducible integrations, we show that our framework also offers novel and innovative ways to analyze these simulations. As an example, we present a high-accuracy integration of the Solar System spanning 10Gyrs, requiring several weeks to run on a modern CPU. In our framework we can not only easily access simulation data at predefined intervals for which we save snapshots, but at any time during the integration. We achieve this by integrating an on-demand reconstructed simulation forward in time from the nearest snapshot. This allows us to extract arbitrary quantities at any point in the saved simulation exactly (bit-by-bit), and within seconds rather than weeks. We believe that the tools we present in this paper offer a new paradigm for how N-body simulations are run, analyzed, and shared across the community. ","A new paradigm for reproducing and analyzing N-body simulations of
  planetary systems"
7,824423483706896386,98564917,Amir Husain,"['Just published new AI paper w Prof. Porter, Chairman @UTCompSci - ""AI Approaches To UCAV Autonomy"" <LINK> @SparkCognition']",https://arxiv.org/abs/1701.07103,"This paper covers a number of approaches that leverage Artificial Intelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle (UCAV) autonomy. An analysis of current approaches to autonomous control is provided followed by an exploration of how these techniques can be extended and enriched with AI techniques including Artificial Neural Networks (ANN), Ensembling and Reinforcement Learning (RL) to evolve control strategies for UCAVs. ",Artificial Intelligence Approaches To UCAV Autonomy
8,824364412890914816,2876139185,Arne Traulsen,['New paper by @EvolSci et al.: Timescales of evolutionary game dynamics on cycles with strong selection <LINK>'],https://arxiv.org/abs/1701.06615,"Evolutionary games on graphs describe how strategic interactions and population structure determine evolutionary success, quantified by the probability that a single mutant takes over a population. Graph structures, compared to the well-mixed case, can act as amplifiers or suppressors of selection by increasing or decreasing the fixation probability of a beneficial mutant. Properties of the associated mean fixation times can be more intricate, especially when selection is strong. The intuition is that fixation of a beneficial mutant happens fast (in a dominance game), that fixation takes very long (in a coexistence game), and that strong selection eliminates demographic noise. Here we show that these intuitions can be misleading in structured populations. We analyze mean fixation times on the cycle graph under strong frequency-dependent selection for two different microscopic evolutionary update rules (death-birth and birth-death). We establish exact analytical results for fixation times under strong selection, and show that there are coexistence games in which fixation occurs in time polynomial in population size. Depending on the underlying game, we observe inherence of demographic noise even under strong selection, if the process is driven by random death before selection for birth of an offspring (death-birth update). In contrast, if selection for an offspring occurs before random removal (birth-death update), strong selection can remove demographic noise almost entirely. ",Evolutionary games on cycles with strong selection
9,824264506016665601,2562351306,Alexander Engelen,['A novel way to measure the cosmic microwave background -- our new paper.  <LINK>'],https://arxiv.org/abs/1701.06992,"The Thomson optical depth from reionization is a limiting factor in measuring the amplitude of primordial fluctuations, and hence in measuring physics that affects the low-redshift amplitude, such as the neutrino masses. Current constraints on the optical depth, based on directly measuring large-scale cosmic microwave background (CMB) polarization, are challenging due to foregrounds and systematic effects. Here, we consider an indirect measurement of large-scale polarization, using observed maps of small-scale polarization together with maps of fields that distort the CMB, such as CMB lensing and patchy reionization. We find that very futuristic CMB surveys will be able to reconstruct large-scale polarization, and thus the mean optical depth, using only measurements on small scales. ",Reconstructing CMB fluctuations and the mean reionization optical depth
10,824244841412444161,215360052,Jonas L. Juul,"[""New paper 'Synergistic effects in threshold models on networks' with @masonporter \n\n <LINK>""]",https://arxiv.org/abs/1701.06646,"Network structure can have significant effects on the propagation of diseases, memes, and information on social networks. Such effects depend on the specific type of dynamical process that affects the nodes and edges of a network, and it is important to develop tractable models of spreading processes on networks to explore how network structure affects dynamics. In this paper, we incorporate the idea of \emph{synergy} into a two-state (""active"" or ""passive"") threshold model of social influence on networks. Our model's update rule is deterministic, and the influence of each meme-carrying (i.e., active) neighbor can --- depending on a parameter --- either be enhanced or inhibited by an amount that depends on the number of active neighbors of a node. Such a synergistic system models social behavior in which the willingness to adopt either accelerates or saturates depending on the number of neighbors who have adopted that behavior. We illustrate that the synergy parameter in our model has a crucial effect on system dynamics, as it determines whether degree-$k$ nodes are possible or impossible to activate. We simulate synergistic meme spreading on both random-graph models and networks constructed from empirical data. Using a local-tree approximation, we examine the spreading of synergistic memes and find good agreement on all but one of the networks on which we simulate spreading. We find for any network and for a broad family of synergistic models that one can predict which synergy-parameter values allow degree-$k$ nodes to be activated. ",Synergistic effects in threshold models on networks
11,824203726097383424,2780063142,Sabine Kraml,['Our new paper on the #LHC phenomenology of a simplified #DarkMatter model with a spin-2 mediator: <LINK>'],https://arxiv.org/abs/1701.07008,"We consider simplified dark matter models where a dark matter candidate couples to the standard model (SM) particles via an $s$-channel spin-2 mediator, and study constraints on the model parameter space from the current LHC data. Our focus lies on the complementarity among different searches, in particular monojet and multijet plus missing energy searches and resonance searches. For universal couplings of the mediator to SM particles, missing-energy searches can give stronger constraints than $WW$, $ZZ$, dijet, dihiggs, $t\bar t$, $b\bar b$ resonance searches in the low-mass region and/or when the coupling of the mediator to dark matter is much larger than its couplings to SM particles. The strongest constraints however come from diphoton and dilepton resonance searches. Only if these modes are suppressed, missing-energy searches can be competitive in constraining dark matter models with a spin-2 mediator. ",Simplified dark matter models with a spin-2 mediator at the LHC
12,824098191708536832,2691316122,Matthew Povich,['I have a new paper! [1701.06653] Candidate X-ray-Emitting OB Stars in the MYStIX Massive Star-Forming Regions <LINK>'],https://arxiv.org/abs/1701.06653,"Massive, O and early B-type (OB) stars remain incompletely catalogued in the nearby Galaxy due to high extinction, bright visible and infrared nebular emission in H II regions, and high field star contamination. These difficulties are alleviated by restricting the search to stars with X-ray emission. Using the X-ray point sources from the Massive Young star-forming complex Study in Infrared and X-rays (MYStIX) survey of OB-dominated regions, we identify 98 MYStIX candidate OB (MOBc) stars by fitting their 1-8 micron spectral energy distributions (SEDs) with reddened stellar atmosphere models. We identify 27 additional MOBc stars based on JHK photometry of X-ray stars lacking SED fitting. These candidate OB stars indicate that the current census of stars earlier than B1, taken across the 18 MYStIX regions studied, is less than 50% complete. We also fit the SEDs of 239 previously-published OB stars to measure interstellar extinction and bolometric luminosities, revealing six candidate massive binary systems and five candidate O-type (super)giants. As expected, candidate OB stars have systematically higher extinction than previously-published OB stars. Notable results for individual regions include: identification of the OB population of a recently discovered massive cluster in NGC 6357; an older OB association in the M17 complex; and new massive luminous O stars near the Trifid Nebula. In several relatively poorly-studied regions (RCW 38, NGC 6334, NGC 6357, Trifid, and NGC 3576), the OB populations may increase by factors of >2. ","Candidate X-ray-Emitting OB Stars in the MYStIX Massive Star-Forming
  Regions"
13,824093995626156032,3237721718,Christian Szegedy,['New neural theorem proving paper by our team is on arxiv: <LINK>'],https://arxiv.org/abs/1701.06972,"Deep learning techniques lie at the heart of several significant AI advances in recent years including object recognition and detection, image captioning, machine translation, speech recognition and synthesis, and playing the game of Go. Automated first-order theorem provers can aid in the formalization and verification of mathematical theorems and play a crucial role in program analysis, theory reasoning, security, interpolation, and system verification. Here we suggest deep learning based guidance in the proof search of the theorem prover E. We train and compare several deep neural network models on the traces of existing ATP proofs of Mizar statements and use them to select processed clauses during proof search. We give experimental evidence that with a hybrid, two-phase approach, deep learning based guidance can significantly reduce the average number of proof search steps while increasing the number of theorems proved. Using a few proof guidance strategies that leverage deep neural networks, we have found first-order proofs of 7.36% of the first-order logic translations of the Mizar Mathematical Library theorems that did not previously have ATP generated proofs. This increases the ratio of statements in the corpus with ATP generated proofs from 56% to 59%. ",Deep Network Guided Proof Search
14,821902158333362177,532752544,Michael Lopez,"['Have a new paper up on the arXiv: ""Estimation of causal effects with multiple treatments: a review and new ideas"" <LINK> <LINK>']",https://arxiv.org/abs/1701.05132,"The propensity score is a common tool for estimating the causal effect of a binary treatment in observational data. In this setting, matching, subclassification, imputation, or inverse probability weighting on the propensity score can reduce the initial covariate bias between the treatment and control groups. With more than two treatment options, however, estimation of causal effects requires additional assumptions and techniques, the implementations of which have varied across disciplines. This paper reviews current methods, and it identifies and contrasts the treatment effects that each one estimates. Additionally, we propose possible matching techniques for use with multiple, nominal categorical treatments, and use simulations to show how such algorithms can yield improved covariate similarity between those in the matched sets, relative the pre-matched cohort. To sum, this manuscript provides a synopsis of how to notate and use causal methods for categorical treatments. ","Estimation of causal effects with multiple treatments: a review and new
  ideas"
15,821706759823835137,317422543,Ricard Solé,"['The rise and fall of cooperation with synthetic biology: spatial hypercycles and their parasites, our new paper <LINK> <LINK>', '@marco_java Thanks!']",https://arxiv.org/abs/1701.04767,"Early theoretical work revealed that the simplest class of autocatalytic cycles, known as hypercycles, provide an elegant framework for understanding the evolution of mutualism. Furthermore, hypercycles are highly susceptible to parasites, spatial structure constituting a key protection against them. However, there is an insufficient experimental validation of these theoretical predictions, in addition to little knowledge on how environmental conditions could shape the spatial dynamics of hypercycles. Here, we constructed spatially extended hypercycles by using synthetic biology as a way to design mutualistic and parasitic {\em E. coli} strains. A mathematical model of the hypercycle front expansion is developed, providing analytic estimates of front speed propagation. Moreover, we explore how the environment affects the mutualistic consortium during range expansions. Interestingly, moderate improvements in environmental conditions (namely, increasing the availability of growth-limiting amino acids) can lead to a slowing-down of the front speed. Our agent-based simulations suggest that opportunistic depletion of environmental amino acids can lead to subsequent high fractions of stagnant cells at the front, and thus to the slow-down of the front speed. Moreover, environmental deterioration can also shape the interaction of the parasitic strain towards the hypercycle. On the one hand, the parasite is excluded from the population during range expansions in which the two species mutualism can thrive (in agreement with a classical theoretical prediction). On the other hand, environmental deterioration (e.g., associated with toxic chemicals) can lead to the survival of the parasitic strain, while reshaping the interactions within the three-species. The evolutionary and ecological implications for the design of synthetic consortia are outlined. ",Spatial dynamics of synthetic microbial hypercycles and their parasites
16,821526358161403904,1638610531,Tapa Ghosh,"['Second paper! \n""Towards a New Interpretation of Separable Convolutions""\n<LINK>']",https://arxiv.org/abs/1701.04489,"In recent times, the use of separable convolutions in deep convolutional neural network architectures has been explored. Several researchers, most notably (Chollet, 2016) and (Ghosh, 2017) have used separable convolutions in their deep architectures and have demonstrated state of the art or close to state of the art performance. However, the underlying mechanism of action of separable convolutions are still not fully understood. Although their mathematical definition is well understood as a depthwise convolution followed by a pointwise convolution, deeper interpretations such as the extreme Inception hypothesis (Chollet, 2016) have failed to provide a thorough explanation of their efficacy. In this paper, we propose a hybrid interpretation that we believe is a better model for explaining the efficacy of separable convolutions. ",Towards a New Interpretation of Separable Convolutions
17,821417330894729216,52381876,Edward Frenkel,['New paper with Aganagic &amp; Okounkov in which we propose a q-deformation of the quantum Langlands correspondence:\n<LINK> <LINK>'],https://arxiv.org/abs/1701.03146,"We formulate a two-parameter generalization of the geometric Langlands correspondence, which we prove for all simply-laced Lie algebras. It identifies the q-conformal blocks of the quantum affine algebra and the deformed W-algebra associated to two Langlands dual Lie algebras. Our proof relies on recent results in quantum K-theory of the Nakajima quiver varieties. The physical origin of the correspondence is the 6d little string theory. The quantum Langlands correspondence emerges in the limit in which the 6d string theory becomes the 6d conformal field theory with (2,0) supersymmetry. ",Quantum q-Langlands Correspondence
18,821289328148094977,2815170184,Oliver Müller,['New M101 dwarf galaxy paper out: <LINK> <LINK>'],https://arxiv.org/abs/1701.03681,"The fine details of the large-scale structure in the local universe provide important empirical benchmarks for testing cosmological models of structure formation. Dwarf galaxies are key object for such studies. Enlarge the sample of known dwarf galaxies in the local universe. We performed a search for faint, unresolved low-surface brightness dwarf galaxies in the M101 group complex, including the region around the major spiral galaxies M101, M51, and M63 lying at a distance 7.0, 8.6, and 9.0 Mpc, respectively. The new dwarf galaxy sample can be used in a first step to test for significant substructure in the 2D-distribution and in a second step to study the spatial distribution of the galaxy complex. Using filtering algorithms we surveyed 330 square degrees of imaging data obtained from the Sloan Digital Sky Survey. The images were visually inspected. The spatial distribution of known galaxies and candidates was analyzed transforming the system into a M101 eigenframe, using the geometrical alignment of the group. We discovered 15 new dwarf galaxies and carried out surface photometry in the g and r bands. The similarity of the photometric properties of these dwarfs to those of Local Group dwarfs suggest membership to the M101 group complex. The sky distribution of the candidates follows the thin planar structure outlined by the known members of the three subgroups. The ~3Mpc long filamentary structure has a rms thickness of 67 kpc. The planar structure of the embedded M101 subgroup is even thinner, with rms=46 kpc. The formation of this structure might be due to the expansion of the Local Void to which it borders. Other implications are discussed as well. We show the viability of SDSS data to extend the sample of dwarfs in the local universe and test cosmological models on small scales. ","The M101 group complex: new dwarf galaxy candidates and spatial
  structure"
19,821166568671444993,2766925212,Andrew Childs,['Another new paper: Quantum algorithm for multivariate polynomial interpolation with @chenkenshin and @hungshihhan <LINK>'],http://arxiv.org/abs/1701.03990,"How many quantum queries are required to determine the coefficients of a degree-$d$ polynomial in $n$ variables? We present and analyze quantum algorithms for this multivariate polynomial interpolation problem over the fields $\mathbb{F}_q$, $\mathbb{R}$, and $\mathbb{C}$. We show that $k_{\mathbb{C}}$ and $2k_{\mathbb{C}}$ queries suffice to achieve probability $1$ for $\mathbb{C}$ and $\mathbb{R}$, respectively, where $k_{\mathbb{C}}=\smash{\lceil\frac{1}{n+1}{n+d\choose d}\rceil}$ except for $d=2$ and four other special cases. For $\mathbb{F}_q$, we show that $\smash{\lceil\frac{d}{n+d}{n+d\choose d}\rceil}$ queries suffice to achieve probability approaching $1$ for large field order $q$. The classical query complexity of this problem is $\smash{n+d\choose d}$, so our result provides a speedup by a factor of $n+1$, $\frac{n+1}{2}$, and $\frac{n+d}{d}$ for $\mathbb{C}$, $\mathbb{R}$, and $\mathbb{F}_q$, respectively. Thus we find a much larger gap between classical and quantum algorithms than the univariate case, where the speedup is by a factor of $2$. For the case of $\mathbb{F}_q$, we conjecture that $2k_{\mathbb{C}}$ queries also suffice to achieve probability approaching $1$ for large field order $q$, although we leave this as an open problem. ",Quantum algorithm for multivariate polynomial interpolation
20,821012625257594880,2766925212,Andrew Childs,"['New paper with Berry, Ostrander, Wang: Quantum algorithm for linear diff eqs with complexity poly(log(1/ε)) <LINK>']",https://arxiv.org/abs/1701.03684,"We present a quantum algorithm for systems of (possibly inhomogeneous) linear ordinary differential equations with constant coefficients. The algorithm produces a quantum state that is proportional to the solution at a desired final time. The complexity of the algorithm is polynomial in the logarithm of the inverse error, an exponential improvement over previous quantum algorithms for this problem. Our result builds upon recent advances in quantum linear systems algorithms by encoding the simulation into a sparse, well-conditioned linear system that approximates evolution according to the propagator using a Taylor series. Unlike with finite difference methods, our approach does not require additional hypotheses to ensure numerical stability. ","Quantum algorithm for linear differential equations with exponentially
  improved dependence on precision"
21,819599397914902529,15285344,Alex Deibel,['Check out my new paper w/ @potentialwell on accreting neutron stars! 🤓 <LINK>'],https://arxiv.org/abs/1701.02730,"Nuclear burning near the surface of an accreting neutron star produces ashes that, when compressed deeper by further accretion, alter the star's thermal and compositional structure. Bygone nucleosynthesis can be constrained by the impact of compressed ashes on the thermal relaxation of quiescent neutron star transients. In particular, Urca cooling nuclei pairs in nuclear burning ashes, which cool the neutron star crust via neutrino emission from electron-capture/beta-decay cycles, provide signatures of prior nuclear burning over the ~century timescales it takes to accrete to the electron-capture depth of the strongest cooling pairs. Using crust cooling models of the accreting neutron star transient MAXI J0556-332, we show that this source likely lacked Type I X-ray bursts and superbursts >120 years ago. Reduced nuclear physics uncertainties in rp-process reaction rates and electron-capture ft-values for low-lying transitions will improve nucleosynthesis constraints using this technique. ",Constraints on Bygone Nucleosynthesis of Accreting Neutron Stars
22,819593161701867520,3291236113,Graeme Smith,['New paper with @felix_led and Nilanjana Datta on upper bounds for one-way distillable entanglement. #quantum  <LINK>'],https://arxiv.org/abs/1701.03081,"We derive general upper bounds on the distillable entanglement of a mixed state under one-way and two-way LOCC. In both cases, the upper bound is based on a convex decomposition of the state into 'useful' and 'useless' quantum states. By 'useful', we mean a state whose distillable entanglement is non-negative and equal to its coherent information (and thus given by a single-letter, tractable formula). On the other hand, 'useless' states are undistillable, i.e., their distillable entanglement is zero. We prove that in both settings the distillable entanglement is convex on such decompositions. Hence, an upper bound on the distillable entanglement is obtained from the contributions of the useful states alone, being equal to the convex combination of their coherent informations. Optimizing over all such decompositions of the input state yields our upper bound. The useful and useless states are given by degradable and antidegradable states in the one-way LOCC setting, and by maximally correlated and PPT states in the two-way LOCC setting, respectively. We also illustrate how our method can be extended to quantum channels. Interpreting our upper bound as a convex roof extension, we show that it reduces to a particularly simple, non-convex optimization problem for the classes of isotropic states and Werner states. In the one-way LOCC setting, this non-convex optimization yields an upper bound on the quantum capacity of the qubit depolarizing channel that is strictly tighter than previously known bounds for large values of the depolarizing parameter. In the two-way LOCC setting, the non-convex optimization achieves the PPT-relative entropy of entanglement for both isotropic and Werner states. ",Useful states and entanglement distillation
23,819379231247302658,20174338,Daniel Cotton,"[""Our new paper 'The intrinsic and interstellar broadband linear polarization of nearby FGK dwarfs' is online: <LINK>"", 'Main take-home is that active K-dwarfs are polarised – their magnetic fields produce differential saturation of their spectral lines.']",https://arxiv.org/abs/1701.02890,"We present linear polarization measurements of nearby FGK dwarfs to parts-per-million (ppm) precision. Before making any allowance for interstellar polarization, we found that the active stars within the sample have a mean polarization of 28.5 +/- 2.2 ppm while the inactive stars have a mean of 9.6 +/- 1.5 ppm. Amongst inactive stars we initially found no difference between debris disk host stars (9.1 +/- 2.5 ppm) and the other FGK dwarfs (9.9 +/- 1.9 ppm). We develop a model for the magnitude and direction of interstellar polarization for nearby stars. When we correct the observations for the estimated interstellar polarization we obtain 23.0 +/-2.2 ppm for the active stars, 7.8 +/- 2.9 ppm for the inactive debris disk host stars and 2.9 +/- 1.9 ppm for the other inactive stars. The data indicates that whilst some debris disk host stars are intrinsically polarized most inactive FGK dwarfs have negligible intrinsic polarization, but that active dwarfs have intrinsic polarization at levels ranging up to ~45 ppm. We briefly consider a number of mechanisms, and suggest differential saturation of spectral lines in the presence of magnetic fields is the best able to explain the polarization seen in active dwarfs. The results have implications for current attempts to detect polarized reflected light from hot Jupiters by looking at the combined light of the star and planet. ","The intrinsic and interstellar broadband linear polarization of nearby
  FGK dwarfs"
24,819357855459352577,267958924,Christian Ott,['New paper by Sherwood Richers+: Equation of State effects on Gravitational Waves from Rotating Core Collapse! <LINK> <LINK>'],https://arxiv.org/abs/1701.02752,"Gravitational waves (GWs) generated by axisymmetric rotating collapse, bounce, and early postbounce phases of a galactic core-collapse supernova will be detectable by current-generation gravitational wave observatories. Since these GWs are emitted from the quadrupole-deformed nuclear-density core, they may encode information on the uncertain nuclear equation of state (EOS). We examine the effects of the nuclear EOS on GWs from rotating core collapse and carry out 1824 axisymmetric general-relativistic hydrodynamic simulations that cover a parameter space of 98 different rotation profiles and 18 different EOS. We show that the bounce GW signal is largely independent of the EOS and sensitive primarily to the ratio of rotational to gravitational energy, and at high rotation rates, to the degree of differential rotation. The GW frequency of postbounce core oscillations shows stronger EOS dependence that can be parameterized by the core's EOS-dependent dynamical frequency $\sqrt{G\bar{\rho}_c}$. We find that the ratio of the peak frequency to the dynamical frequency follows a universal trend that is obeyed by all EOS and rotation profiles and that indicates that the nature of the core oscillations changes when the rotation rate exceeds the dynamical frequency. We find that differences in the treatments of low-density nonuniform nuclear matter, of the transition from nonuniform to uniform nuclear matter, and in the description of nuclear matter up to around twice saturation density can mildly affect the GW signal. We find that approximations and uncertainties in electron capture rates can lead to variations in the GW signal that are of comparable magnitude to those due to different nuclear EOS. This emphasizes the need for reliable nuclear electron capture rates and for self-consistent multi-dimensional neutrino radiation-hydrodynamic simulations of rotating core collapse. ","Equation of State Effects on Gravitational Waves from Rotating Core
  Collapse"
25,817359727881555968,4235719700,Marwin Segler,['Teaching neural networks to design drugs against malaria: our new paper <LINK>'],https://arxiv.org/abs/1701.01329,"In de novo drug design, computational strategies are used to generate novel molecules with good affinity to the desired biological target. In this work, we show that recurrent neural networks can be trained as generative models for molecular structures, similar to statistical language models in natural language processing. We demonstrate that the properties of the generated molecules correlate very well with the properties of the molecules used to train the model. In order to enrich libraries with molecules active towards a given biological target, we propose to fine-tune the model with small sets of molecules, which are known to be active against that target. Against Staphylococcus aureus, the model reproduced 14% of 6051 hold-out test molecules that medicinal chemists designed, whereas against Plasmodium falciparum (Malaria) it reproduced 28% of 1240 test molecules. When coupled with a scoring function, our model can perform the complete de novo drug design cycle to generate large sets of novel molecules for drug discovery. ","Generating Focussed Molecule Libraries for Drug Discovery with Recurrent
  Neural Networks"
26,817336960326975488,280083723,Yoh Tanimoto,"['so yes, we submitted a new paper :) <LINK> there are a lot of open problems, though.']",https://arxiv.org/abs/1701.01186,"We consider the entanglement entropy for a spacetime region and its spacelike complement in the framework of algebraic quantum field theory. For a M\""obius covariant local net satisfying a certain nuclearity property, we consider the von Neumann entropy for type I factors between local algebras and introduce an entropic quantity. Then we implement a cutoff on this quantity with respect to the conformal Hamiltonian and show that it remains finite as the distance of two intervals tends to zero. We compare our definition to others in the literature. ",Towards entanglement entropy with UV cutoff in conformal nets
27,816787671636844544,724173367645974529,Naoya Takahashi,['Our new paper on an audio feature for video analysis. \nPaper\n<LINK>\nCode\n<LINK>'],https://arxiv.org/abs/1701.00599,"We propose a new deep network for audio event recognition, called AENet. In contrast to speech, sounds coming from audio events may be produced by a wide variety of sources. Furthermore, distinguishing them often requires analyzing an extended time period due to the lack of clear sub-word units that are present in speech. In order to incorporate this long-time frequency structure of audio events, we introduce a convolutional neural network (CNN) operating on a large temporal input. In contrast to previous works this allows us to train an audio event detection system end-to-end. The combination of our network architecture and a novel data augmentation outperforms previous methods for audio event detection by 16%. Furthermore, we perform transfer learning and show that our model learnt generic audio features, similar to the way CNNs learn generic features on vision tasks. In video analysis, combining visual features and traditional audio features such as MFCC typically only leads to marginal improvements. Instead, combining visual features with our AENet features, which can be computed efficiently on a GPU, leads to significant performance improvements on action recognition and video highlight detection. In video highlight detection, our audio features improve the performance by more than 8% over visual features alone. ",AENet: Learning Deep Audio Features for Video Analysis
28,816565516705943552,2770204252,Michael Gygli,['Our new paper with @zuNaoya AENet: Learning Deep Audio Features for Video Analysis. <LINK>\nCode: <LINK> <LINK>'],https://arxiv.org/abs/1701.00599,"We propose a new deep network for audio event recognition, called AENet. In contrast to speech, sounds coming from audio events may be produced by a wide variety of sources. Furthermore, distinguishing them often requires analyzing an extended time period due to the lack of clear sub-word units that are present in speech. In order to incorporate this long-time frequency structure of audio events, we introduce a convolutional neural network (CNN) operating on a large temporal input. In contrast to previous works this allows us to train an audio event detection system end-to-end. The combination of our network architecture and a novel data augmentation outperforms previous methods for audio event detection by 16%. Furthermore, we perform transfer learning and show that our model learnt generic audio features, similar to the way CNNs learn generic features on vision tasks. In video analysis, combining visual features and traditional audio features such as MFCC typically only leads to marginal improvements. Instead, combining visual features with our AENet features, which can be computed efficiently on a GPU, leads to significant performance improvements on action recognition and video highlight detection. In video highlight detection, our audio features improve the performance by more than 8% over visual features alone. ",AENet: Learning Deep Audio Features for Video Analysis
29,816555960173031425,471177379,Wilhelm Braun,['Our new paper is now available as a preprint: <LINK>'],https://arxiv.org/abs/1701.00648,"First-passage time problems are ubiquitous across many fields of study including transport processes in semiconductors and biological synapses, evolutionary game theory and percolation. Despite their prominence, first-passage time calculations have proven to be particularly challenging. Analytical results to date have often been obtained under strong conditions, leaving most of the exploration of first-passage time problems to direct numerical computations. Here we present an analytical approach that allows the derivation of first-passage time distributions for the wide class of non-differentiable Gaussian processes. We demonstrate that the concept of sign changes naturally generalises the common practice of counting crossings to determine first-passage events. Our method works across a wide range of time-dependent boundaries and noise strengths thus alleviating common hurdles in first-passage time calculations. ",Sign-changes as a universal concept in first-passage time calculations
30,816473886170546176,1331105262,Konstantin Zuev,"['Our new paper ""#Reliability of Critical #Infrastructure #Networks: Challenges"", for #ASCE report <LINK>  #networkscience <LINK>']",https://arxiv.org/abs/1701.00594,"Critical infrastructures form a technological skeleton of our world by providing us with water, food, electricity, gas, transportation, communication, banking, and finance. Moreover, as urban population increases, the role of infrastructures become more vital. In this paper, we adopt a network perspective and discuss the ever growing need for fundamental interdisciplinary study of critical infrastructure networks, efficient methods for estimating their reliability, and cost-effective strategies for enhancing their resiliency. We also highlight some of the main challenges arising on this way, including cascading failures, feedback loops, and cross-sector interdependencies. ",Reliability of Critical Infrastructure Networks: Challenges
31,826044370063233025,793183274457821184,Jesús Arroyo,['New paper on arxiv: Network classification with applications to brain connectomics <LINK> #brainnetworks'],https://arxiv.org/abs/1701.08140,"While statistical analysis of a single network has received a lot of attention in recent years, with a focus on social networks, analysis of a sample of networks presents its own challenges which require a different set of analytic tools. Here we study the problem of classification of networks with labeled nodes, motivated by applications in neuroimaging. Brain networks are constructed from imaging data to represent functional connectivity between regions of the brain, and previous work has shown the potential of such networks to distinguish between various brain disorders, giving rise to a network classification problem. Existing approaches tend to either treat all edge weights as a long vector, ignoring the network structure, or focus on graph topology as represented by summary measures while ignoring the edge weights. Our goal is to design a classification method that uses both the individual edge information and the network structure of the data in a computationally efficient way, and that can produce a parsimonious and interpretable representation of differences in brain connectivity patterns between classes. We propose a graph classification method that uses edge weights as predictors but incorporates the network nature of the data via penalties that promote sparsity in the number of nodes, in addition to the usual sparsity penalties that encourage selection of edges. We implement the method via efficient convex optimization and provide a detailed analysis of data from two fMRI studies of schizophrenia. ",Network classification with applications to brain connectomics
32,824427138917007360,282227303,Dane Wilburne,"['Our new paper, ""Random Monomial Ideals"", is up:\n<LINK>']",https://arxiv.org/abs/1701.07130,"Inspired by the study of random graphs and simplicial complexes, and motivated by the need to understand average behavior of ideals, we propose and study probabilistic models of random monomial ideals. We prove theorems about the probability distributions, expectations and thresholds for events involving monomial ideals with given Hilbert function, Krull dimension, first graded Betti numbers, and present several experimentally-backed conjectures about regularity, projective dimension, strong genericity, and Cohen-Macaulayness of random monomial ideals. ",Random Monomial Ideals
33,823844537017700352,307880202,Blai Vidiella 🎗,['Synthetic Associative Learning! Our new paper @CSLab_UPF \n<LINK> <LINK>'],https://arxiv.org/abs/1701.06086,"Associative learning is one of the key mechanisms displayed by living organisms in order to adapt to their changing environments. It was early recognized to be a general trait of complex multicellular organisms but also found in ""simpler"" ones. It has also been explored within synthetic biology using molecular circuits that are directly inspired in neural network models of conditioning. These designs involve complex wiring diagrams to be implemented within one single cell and the presence of diverse molecular wires become a challenge that might be very difficult to overcome. Here we present three alternative circuit designs based on two-cell microbial consortia able to properly display associative learning responses to two classes of stimuli and displaying long and short-term memory (i. e. the association can be lost with time). These designs might be a helpful approach for engineering the human gut microbiome or even synthetic organoids, defining a new class of decision-making biological circuits capable of memory and adaptation to changing conditions. The potential implications and extensions are outlined. ",Synthetic associative learning in engineered multicellular consortia
34,823837800441249792,317422543,Ricard Solé,"[""Engineering learning and Pavlov's conditioning on synthetic cellular consortia: our new paper  <LINK> <LINK>"", '@MathCancer @ara_anderson Many thanks!']",https://arxiv.org/abs/1701.06086,"Associative learning is one of the key mechanisms displayed by living organisms in order to adapt to their changing environments. It was early recognized to be a general trait of complex multicellular organisms but also found in ""simpler"" ones. It has also been explored within synthetic biology using molecular circuits that are directly inspired in neural network models of conditioning. These designs involve complex wiring diagrams to be implemented within one single cell and the presence of diverse molecular wires become a challenge that might be very difficult to overcome. Here we present three alternative circuit designs based on two-cell microbial consortia able to properly display associative learning responses to two classes of stimuli and displaying long and short-term memory (i. e. the association can be lost with time). These designs might be a helpful approach for engineering the human gut microbiome or even synthetic organoids, defining a new class of decision-making biological circuits capable of memory and adaptation to changing conditions. The potential implications and extensions are outlined. ",Synthetic associative learning in engineered multicellular consortia
35,824009819711504384,56805505,Ingo Scholtes,['In our latest work we study controllability of temporal networks from a higher-order network perspective: <LINK>'],https://arxiv.org/abs/1701.06331,"In many complex systems, elements interact via time-varying network topologies. Recent research shows that temporal correlations in the chronological ordering of interactions crucially influence network properties and dynamical processes. How these correlations affect our ability to control systems with time-varying interactions remains unclear. In this work, we use higher-order network models to extend the framework of structural controllability to temporal networks, where the chronological ordering of interactions gives rise to time-respecting paths with non-Markovian characteristics. We study six empirical data sets and show that non-Markovian characteristics of real systems can both increase or decrease the minimum time needed to control the whole system. With both empirical data and synthetic models, we further show that spectral properties of generalisations of graph Laplacians to higher-order networks can be used to analytically capture the effect of temporal correlations on controllability. Our work highlights that (i) correlations in the chronological ordering of interactions are an important source of complexity that significantly influences the controllability of temporal networks, and (ii) higher-order network models are a powerful tool to understand the temporal-topological characteristics of empirical systems. ","Higher-order models capture changes in controllability of temporal
  networks"
36,821417330894729216,52381876,Edward Frenkel,['New paper with Aganagic &amp; Okounkov in which we propose a q-deformation of the quantum Langlands correspondence:\n<LINK> <LINK>'],https://arxiv.org/abs/1701.03146,"We formulate a two-parameter generalization of the geometric Langlands correspondence, which we prove for all simply-laced Lie algebras. It identifies the q-conformal blocks of the quantum affine algebra and the deformed W-algebra associated to two Langlands dual Lie algebras. Our proof relies on recent results in quantum K-theory of the Nakajima quiver varieties. The physical origin of the correspondence is the 6d little string theory. The quantum Langlands correspondence emerges in the limit in which the 6d string theory becomes the 6d conformal field theory with (2,0) supersymmetry. ",Quantum q-Langlands Correspondence
37,816978812617400320,378228706,Hannah Wakeford,['We find no evidence of H2O features in the atm. of WASP-101b So is not optimum for #JWST ERS obs. of clear features <LINK>'],http://arxiv.org/abs/1701.00843,"We present results from the first observations of the Hubble Space Telescope (HST) Panchromatic Comparative Exoplanet Treasury (PanCET) program for WASP-101b, a highly inflated hot Jupiter and one of the community targets proposed for the James Webb Space Telescope (JWST) Early Release Science (ERS) program. From a single HST Wide Field Camera 3 (WFC3) observation, we find that the near-infrared transmission spectrum of WASP-101b contains no significant H$_2$O absorption features and we rule out a clear atmosphere at 13{\sigma}. Therefore, WASP-101b is not an optimum target for a JWST ERS program aimed at observing strong molecular transmission features. We compare WASP-101b to the well studied and nearly identical hot Jupiter WASP-31b. These twin planets show similar temperature-pressure profiles and atmospheric features in the near-infrared. We suggest exoplanets in the same parameter space as WASP-101b and WASP-31b will also exhibit cloudy transmission spectral features. For future HST exoplanet studies, our analysis also suggests that a lower count limit needs to be exceeded per pixel on the detector in order to avoid unwanted instrumental systematics. ","HST PanCET program: A Cloudy Atmosphere for the promising JWST target
  WASP-101b"
