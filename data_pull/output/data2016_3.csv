,TweetID,AuthorID,AuthorName,Tweets,arxiv_link,Abstract,Title
0,717864496119808001,4509741,Matthew Salganik,"['New working paper: ""Network survival method for estimating adult mortality"" <LINK>  w @dennisfeehan <LINK>']",http://arxiv.org/abs/1603.08588,"Adult death rates are a critical indicator of population health and wellbeing. Wealthy countries have high-quality vital registration systems, but poor countries lack this infrastructure and must rely on estimates that are often problematic. In this paper, we introduce the network survival method, a new approach for estimating adult death rates. We derive the precise conditions under which it produces estimates that are consistent and unbiased. Further, we develop an analytical framework for sensitivity analysis. To assess the performance of the network survival method in a realistic setting, we conducted a nationally-representative survey experiment in Rwanda (n=4,669). Network survival estimates were similar to estimates from other methods, even though the network survival estimates were made with substantially smaller samples and are based entirely on data from Rwanda, with no need for model life tables or pooling of data from other countries. Our analytic results demonstrate that the network survival method has attractive properties, and our empirical results show that it can be used in countries where reliable estimates of adult death rates are sorely needed. ","The network survival method for estimating adult mortality: Evidence
  from a survey experiment in Rwanda"
1,715974420569985024,192826908,Jorge Lillo-Box,['New accepted paper! Close-in planets around GS: lack of hot-Jupiters and prevalence of multi-planetary systems: <LINK>'],http://arxiv.org/abs/1603.09719,"Extrasolar planets abound in almost any possible configuration. However, until five years ago, there was a lack of planets orbiting closer than 0.5 au to giant or subgiant stars. Since then, recent detections have started to populated this regime by confirming 13 planetary systems. We discuss the properties of these systems in terms of their formation and evolution off the main sequence. Interestingly, we find that $70.0\pm6.6$ % of the planets in this regime are inner components of multiplanetary systems. This value is 4.2$\sigma$ higher than for main-sequence hosts, which we find to be $42.4\pm0.1$ %. The properties of the known planets seem to indicate that the closest-in planets (a < 0.06 au) to main-sequence stars are massive (i.e., hot Jupiters) and isolated and that they are subsequently engulfed by their host as it evolves to the red giant branch, leaving only the predominant population of multiplanetary systems in orbits 0.06 < a < 0.5 au. We discuss the implications of this emerging observational trend in the context of formation and evolution of hot Jupiters. ","Close-in planets around giant stars. Lack of hot-Jupiters and prevalence
  of multi-planetary systems"
2,715894633000222722,14350332,Steve Renals,['new paper with Pawel on Differentiable Pooling for Unsupervised Acoustic Model Adaptation - <LINK>'],http://arxiv.org/abs/1603.09630,"We present a deep neural network (DNN) acoustic model that includes parametrised and differentiable pooling operators. Unsupervised acoustic model adaptation is cast as the problem of updating the decision boundaries implemented by each pooling operator. In particular, we experiment with two types of pooling parametrisations: learned $L_p$-norm pooling and weighted Gaussian pooling, in which the weights of both operators are treated as speaker-dependent. We perform investigations using three different large vocabulary speech recognition corpora: AMI meetings, TED talks and Switchboard conversational telephone speech. We demonstrate that differentiable pooling operators provide a robust and relatively low-dimensional way to adapt acoustic models, with relative word error rates reductions ranging from 5--20% with respect to unadapted systems, which themselves are better than the baseline fully-connected DNN-based acoustic models. We also investigate how the proposed techniques work under various adaptation conditions including the quality of adaptation data and complementarity to other feature- and model-space adaptation methods, as well as providing an analysis of the characteristics of each of the proposed approaches. ",Differentiable Pooling for Unsupervised Acoustic Model Adaptation
3,715594024497733632,545215361,Stefano Valenti,['Our new paper on supernovae type II with @lcogt data is out ! <LINK>'],http://arxiv.org/abs/1603.08953,"High-quality collections of Type II supernova (SN) light curves are scarce because they evolve for hundreds of days, making follow-up observations time consuming and often extending over multiple observing seasons. In light of these difficulties, the diversity of SNe II is not fully understood. Here we present ultraviolet and optical photometry of 12 SNe II monitored by the Las Cumbres Observatory Global Telescope Network (LCOGT) during 2013-2014, and compare them with previously studied SNe having well-sampled light curves. We explore SN II diversity by searching for correlations between the slope of the linear light-curve decay after maximum light (historically used to divide SNe II into IIL and IIP) and other measured physical properties. While SNe IIL are found to be on average more luminous than SNe IIP, SNe IIL do not appear to synthesize more 56Ni than SNe IIP. Finally, optical nebular spectra obtained for several SNe in our sample are found to be consistent with models of red supergiant progenitors in the 12-16 Msun range. Consequently, SNe IIL appear not to account for the deficit of massive red supergiants as SN II progenitors. ","The diversity of Type II supernova versus the similarity in their
  progenitors"
4,715216656163872769,81929622,Alex Chepurnoy,"['The new paper of mine(&amp; not only): ""A Prunable Blockchain Consensus Protocol..."" <LINK>']",http://arxiv.org/abs/1603.07926,"Bitcoin is the first successful decentralized global digital cash system. Its mining process requires intense computational resources, therefore its usefulness remains a disputable topic. We aim to solve three problems with Bitcoin and other blockchain systems of today by repurposing their work. First, space to store a blockchain is growing linearly with number of transactions. Second, a honest node is forced to be irrational regarding storing full blocks by a way implementations are done. Third, a trustless bootstrapping process for a new node involves downloading and processing all the transactions ever written into a blockchain. In this paper we present a new consensus protocol for Bitcoin-like peer-to-peer systems where a right to generate a block is given to a party providing non-interactive proofs of storing a subset of the past state snapshots. Unlike the blockchain systems in use today, a network using our protocol is safe if the nodes prune full blocks not needed for mining. We extend the GKL model to describe our Proof-of-Work scheme and a transactional model modifications needed for it. We provide a detailed analysis of our protocol and proofs of its security. ","Rollerchain, a Blockchain With Safely Pruneable Full Blocks"
5,715210529120325632,2956121356,Russ Salakhutdinov,['New paper on Revisiting Semi-Supervised Learning with Graph Embeddings\n<LINK>\nwith Zhilin Yang and William Cohen'],http://arxiv.org/abs/1603.08861,"We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models. ",Revisiting Semi-Supervised Learning with Graph Embeddings
6,715115467095072769,26716739,Mattias Villani,"['New subsampling MCMC paper. Exact this time around. <LINK>', '@chris_naesseth The sampler converges to the underlying posterior. Previous subsampling MCMC only approximately correct even in the limit.']",http://arxiv.org/abs/1603.08232,"Speeding up Markov Chain Monte Carlo (MCMC) for datasets with many observations by data subsampling has recently received considerable attention. A pseudo-marginal MCMC method is proposed that estimates the likelihood by data subsampling using a block-Poisson estimator. The estimator is a product of Poisson estimators, allowing us to update a single block of subsample indicators in each MCMC iteration so that a desired correlation is achieved between the logs of successive likelihood estimates. This is important since pseudo-marginal MCMC with positively correlated likelihood estimates can use substantially smaller subsamples without adversely affecting the sampling efficiency. The block-Poisson estimator is unbiased but not necessarily positive, so the algorithm runs the MCMC on the absolute value of the likelihood estimator and uses an importance sampling correction to obtain consistent estimates of the posterior mean of any function of the parameters. Our article derives guidelines to select the optimal tuning parameters for our method and shows that it compares very favourably to regular MCMC without subsampling, and to two other recently proposed exact subsampling approaches in the literature. ",The block-Poisson estimator for optimally tuned exact subsampling MCMC
7,714973516165021696,267958924,Christian Ott,['New paper w/ Viktoriya Morozova+ <LINK> Early Light Curves of IIP SNe. Open science: <LINK>'],http://arxiv.org/abs/1603.08530,"The early rise of Type IIP supernovae (SN IIP) provides important information for constraining the properties of their progenitors. This can in turn be compared to pre-explosion imaging constraints and stellar models to develop a more complete picture of how massive stars evolve and end their lives. Using the SuperNova Explosion Code (SNEC), we model the first 40 days of SNe IIP to better understand what constraints can be derived from their early light curves. We use two sets of red supergiant progenitor models with zero-age main sequence masses in the range between 9 Msol and 20 Msol. We find that the early properties of the light curve depend most sensitively on the radius of the progenitor, and thus provide a relation between the g-band rise time and the radius at the time of explosion. This relation will be useful for deriving constraints on progenitors from future observations, especially in cases where detailed modeling of the entire rise is not practical. When comparing to observed rise times, the radii we find are a factor of a few larger than previous semi-analytic derivations and generally in better agreement with what is found with current stellar evolution calculations. ",Numerical Modeling of the Early Light Curves of Type IIP Supernovae
8,714745184584671232,3391925555,Vincent Van Eylen,"[""Check out today's ArXiv with new paper on tides for binary stars! Relevant for planets too! <LINK> <LINK>""]",http://arxiv.org/abs/1603.08224,"The rate of tidal circularization is predicted to be faster for relatively cool stars with convective outer layers, compared to hotter stars with radiative outer layers. Observing this effect is challenging, because it requires large and well-characterized samples including both hot and cool stars. Here we seek evidence for the predicted dependence of circularization upon stellar type, using a sample of 945 eclipsing binaries observed by Kepler. This sample complements earlier studies of this effect, which employed smaller samples of better-characterized stars. For each Kepler binary we measure $e\cos\omega$ based on the relative timing of the primary and secondary eclipses. We examine the distribution of $e\cos\omega$ as a function of period for binaries composed of hot stars, cool stars, and mixtures of the two types. At the shortest periods, hot-hot binaries are most likely to be eccentric; for periods shorter than 4 days, significant eccentricities occur frequently for hot-hot binaries, but not for hot-cool or cool-cool binaries. This is in qualitative agreement with theoretical expectations based on the slower dissipation rates of hot stars. However, the interpretation of our results is complicated by the largely unknown ages and evolutionary states of the stars in our sample. ",Orbital Circularization of Hot and Cool Kepler Eclipsing Binaries
9,714612939240542208,595554321,Jason D Lotay,"[""It's been a long time coming, but my new paper with Joel Fine and Michael Singer is finally here for enjoyment: <LINK>""]",http://arxiv.org/abs/1603.08170,"Let X be a compact 4-manifold with boundary. We study the space of hyperk\""ahler triples on X, modulo diffeomorphisms which are the identity on the boundary. We prove that this moduli space is a smooth infinite-dimensional manifold and describe the tangent space in terms of triples of closed anti-self-dual 2-forms. We also explore the corresponding boundary value problem: a hyperk\""ahler triple restricts to a closed framing of the bundle of 2-forms on the boundary; we identify the infinitesimal deformations of this closed framing that can be filled in to hyperk\""ahler deformations of the original triple. Finally we study explicit examples coming from gravitational instantons with isometric actions of SU(2). ","The space of hyperk\""ahler metrics on a 4-manifold with boundary"
10,714291027742425088,2233489694,Theofanis Karaletsos,['New paper with Andreas Veit and @SergeBelongie  available <LINK>'],http://arxiv.org/abs/1603.07810,"What makes images similar? To measure the similarity between images, they are typically embedded in a feature-vector space, in which their distance preserve the relative dissimilarity. However, when learning such similarity embeddings the simplifying assumption is commonly made that images are only compared to one unique measure of similarity. A main reason for this is that contradicting notions of similarities cannot be captured in a single space. To address this shortcoming, we propose Conditional Similarity Networks (CSNs) that learn embeddings differentiated into semantically distinct subspaces that capture the different notions of similarities. CSNs jointly learn a disentangled embedding where features for different similarities are encoded in separate dimensions as well as masks that select and reweight relevant dimensions to induce a subspace that encodes a specific similarity notion. We show that our approach learns interpretable image representations with visually relevant semantic subspaces. Further, when evaluating on triplet questions from multiple similarity notions our model even outperforms the accuracy obtained by training individual specialized networks for each notion separately. ",Conditional Similarity Networks
11,713400715658407936,91437029,Richard Galvez,['New paper out on the arxiv #moduli #inflation in #stringtheory. Hope someone enjoys! <LINK>'],http://arxiv.org/abs/1603.06631,In this paper we present an initial exploration of the Calabi-Yau landscape in the context of Kahler moduli inflation. We review how the slow-roll requirement on the scalar potential translates to a geometric constraint on the Kahler geometry of the vacuum. This constraint leads to a hard bound on the moduli space geometry and we consider the effects of this constraint on the string landscape that arises in type IIB string compactifications on an O3/O7 orientifold. Most notably we find that the inflationary constraint is independent of the moduli space dimension and only 6.57% of geometries inspected support high-scale Kahler moduli inflation. ,"Kahler Moduli Inflation in Type IIB Compactifications: A random tumble
  through the Calabi-Yau landscape"
12,713281901667172352,75249390,Axel Maas,['I have published a new paper on #scalar particles - see <LINK> #np3'],http://arxiv.org/abs/1603.07525,"It is a long-standing question whether the confinement of matter fields in QCD has an imprint in the (gauge-dependent) correlation functions, especially the propagators. As the analytic structure plays an important role in this question, high-precision data is necessary for lattice investigations. Also, it is interesting how this depends on the dimensionality of the theory. To make a study over a wide range of parameters possible this suggests to use scalar particles. This is done here: The propagator of a fundamental scalar is studied in two, three, and four dimensions in quenched SU(2) Yang-Mills theory in minimal Landau gauge, both in momentum space and position space. Particular emphasis is put on the effects of renormalization. The results suggest a quite intricate volume dependence and the presence of an intrinsic mass scale, but no obvious connection to confinement. ",The quenched SU(2) fundamental scalar propagator in minimal Landau gauge
13,713205939168366592,296161364,Chris Power,['Aaron and I have a new paper on testing dark matter models with extended stellar structures around galaxies - see <LINK>'],http://arxiv.org/abs/1603.07422,"Deep observations of galaxies reveal faint extended stellar components (hereafter ESCs) of streams, shells, and halos. These are a natural prediction of hierarchical galaxy formation, as accreted satellite galaxies are tidally disrupted by their host. We investigate whether or not global properties of the ESC could be used to test of dark matter, reasoning that they should be sensitive to the abundance of low-mass satellites, and therefore the underlying dark matter model. Using cosmological simulations of galaxy formation in the favoured Cold Dark Matter (CDM) and Warm Dark Matter (WDM) models ($m_{\rm WDM}$=0.5,1,2 keV/$c^2$), which suppress the abundance of low-mass satellites, we find that the kinematics and orbital structure of the ESC is consistent across models. However, we find striking differences in its spatial structure, as anticipated -- a factor of $\sim$10 drop in spherically averaged mass density between $\sim$10% and $\sim$75% of the virial radius in the more extreme WDM runs ($m_{\rm WDM}$=0.5, 1 keV/$c^2$) relative to the CDM run. These differences are consistent with the mass assembly histories of the different components, and are present across redshifts. However, even the least discrepant of the WDM models is incompatible with current observational limits on $m_{\rm WDM}$. Importantly, the differences we observe when varying the underlying dark matter are comparable to the galaxy-to-galaxy variation we expect within a fixed dark matter model. This suggests that it will be challenging to place limits on dark matter using only the unresolved spatial structure of the the ESC. ",Extended Stellar Components of Galaxies & the Nature of Dark Matter
14,713108546997592064,64177350,Hans-Peter Schadler,['Our new paper about Polyakov loop with 2+1 flavors for 116 MeV &lt;T&lt; 5814 MeV is out: <LINK> #LatticeQCD #QCD'],http://arxiv.org/abs/1603.06637,"We study the free energy of a static quark in QCD with 2+1 flavors in a wide temperature region, 116 MeV $< T < $ 5814 MeV, using the highly improved staggered quark (HISQ) action. We analyze the transition region in detail, obtain the entropy of a static quark, show that it peaks at temperatures close to the chiral crossover temperature and also revisit the temperature dependence of the Polyakov loop susceptibilities using gradient flow. We discuss the implications of our findings for the deconfinement and chiral crossover phenomena at physical values of the quark masses. Finally a comparison of the lattice results at high temperatures with the weak-coupling calculations is presented. ",Polyakov loop in 2+1 flavor QCD from low to high temperatures
15,713010480722350081,156804540,Francisco Rodrigues,['Our new paper on arxiv: \n Tweaking Synchronisation by Link Addition\n<LINK>\nWith @thomas_peron.'],http://arxiv.org/abs/1603.07157,"Natural and man-made networks often possess locally tree-like sub-structures. Taking such tree networks as our starting point, we show how the addition of links changes the synchronization properties of the network. We focus on two different methods of link addition. The first method adds single links that create cycles of a well-defined length. Following a topological approach we introduce cycles of varying length and analyze how this feature, as well as the position in the network, alters the synchronous behaviour. We show that in particular short cycles can lead to a maximum change of the Laplacian's eigenvalue spectrum, dictating the synchronization properties of such networks. The second method connects a certain proportion of the initially unconnected nodes. We simulate dynamical systems on these network topologies, with the nodes' local dynamics being either a discrete or continuous. Here our main result is that a certain amount of additional links, with the relative position in the network being crucial, can be beneficial to ensure stable synchronization. ",Tweaking Synchronisation by Link Addition
16,712880970739875840,10666172,Sabine Hossenfelder,"[""Somewhere along the line I wrote a new paper. Yes, it's about antigravitation. <LINK>"", '@kennethminoo Yes, as always there are many ways to make it more complicated... Let me figure out the simple cases first ;)']",http://arxiv.org/abs/1603.07075,We derive a family of exact solutions for bi-metric gravity with an exchange symmetry between the two metrics. In this two-parameter family of solutions the gravitational field is sourced by a time-independent massless scalar field. We find that the only limit in which the scalar field entirely vanishes is flat space. The regular Schwarzschild-solution is left with a scalar field hidden in the second metric's sector. ,Static Scalar Field Solutions in Symmetric Gravity
17,712679736095469569,2791978125,Christian JÃ¤h,['We have submitted our new paper on well-posedness for weakly hyperbolic systems. <LINK> #maths #research @lborouniversity'],http://arxiv.org/abs/1603.03602,"We study hyperbolic systems with multiplicities and smo\-oth coefficients. In the case of non-analytic, smooth coefficients, we prove well-posedness in any Gevrey class and when the coefficients are analytic, we prove $C^\infty$ well-posedness. The proof is based on a transformation to block Sylvester form introduced by D'Ancona and Spagnolo in Ref. 9 which increases the system size but does not change the eigenvalues. This reduction introduces lower order terms for which appropriate Levi-type conditions are found. These translate then into conditions on the original coefficient matrix. This paper can be considered as a generalisation of Ref. 12, where weakly hyperbolic higher order equations with lower order terms were considered. ","Well-posedness of hyperbolic systems with multiplicities and smooth
  coefficients"
18,712595876535992321,30775583,Dennis V. Perepelitsa ðŸ‡ºðŸ‡¦ðŸ‡ºðŸ‡²,"['New paper by me and Colorado guys: some interesting things one can do with a projectile species ""p+A"" scan at RHIC: <LINK>']",http://arxiv.org/abs/1603.06607,"Recent measurements of jet production rates at large transverse momentum ($p_T$) in the collisions of small projectiles with large nuclei at RHIC and the LHC indicate that they have an unexpected relationship with estimates of the collision centrality. One compelling interpretation of the data is that it captures an $x_p$-dependent decrease in the average interaction strength of the nucleon in the projectile undergoing a hard scattering. A weakly interacting or ""shrinking"" nucleon in the projectile strikes fewer nucleons in the nucleus, resulting in a particular pattern of centrality-dependent modifications to high-$p_T$ processes. We describe a simple one-parameter geometric implementation of this picture within a modified Monte Carlo Glauber model tuned to $d$$+$Au jet data, and explore two of its major consequences. First, the model predicts a particular projectile-species dependence to the centrality dependence at high-$x_p$, opposite to that expected from an energy loss effect. Second, we find that some of the large centrality dependence observed for forward di-hadron production in $d$$+$Au collisions at RHIC may arise from the physics of the ""shrinking"" projectile nucleon, in addition to impact parameter-dependent shadowing or saturation effects at low nuclear-$x$. We conclude that analogous measurements in recently collected $p$$+$Au and $^3$He$+$Au collision data at RHIC can provide a unique test of these predictions. ","Consequences of high-$x$ proton size fluctuations in small collision
  systems at RHIC"
19,712100497591705600,2956121356,Russ Salakhutdinov,['Check out our new paper: Multi-Task Cross-Lingual Sequence Tagging from Scratch:\n<LINK>\nwith Zhilin Yang and William Cohen.'],http://arxiv.org/abs/1603.06270,"We present a deep hierarchical recurrent neural network for sequence tagging. Given a sequence of words, our model employs deep gated recurrent units on both character and word levels to encode morphology and context information, and applies a conditional random field layer to predict the tags. Our model is task independent, language independent, and feature engineering free. We further extend our model to multi-task and cross-lingual joint training by sharing the architecture and parameters. Our model achieves state-of-the-art results in multiple languages on several benchmark tasks including POS tagging, chunking, and NER. We also demonstrate that multi-task and cross-lingual joint training can improve the performance in various cases. ",Multi-Task Cross-Lingual Sequence Tagging from Scratch
20,712086011149471744,1576235694,Michael Brown,"["".@amelia_fmc's new paper, The Many Assembly Histories of Massive Void Galaxies as Revealed by IFU Spectroscopy. \n<LINK>""]",http://arxiv.org/abs/1603.06295,"We present the first detailed integral field spectroscopy study of nine central void galaxies with M*>10^10 Msun using the Wide Field Spectrograph (WiFeS) to determine how a range of assembly histories manifest themselves in the current day Universe. While the majority of these galaxies are evolving secularly, we find a range of morphologies, merger histories and stellar population distributions, though similarly low Halpha-derived star formation rates (<1 Msun/yr). Two of our nine galaxies host AGNs, and two have kinematic disruptions to their gas that are not seen in their stellar component. Most massive void galaxies are red and discy, which we attribute to a lack of major mergers. Some have disturbed morphologies and may be in the process of evolving to early-type thanks to ongoing minor mergers at present times, likely fed by tendrils leading off filaments. The diversity in our small galaxy sample, despite being of similar mass and environment means that these galaxies are still assembling at present day, with minor mergers playing an important role in their evolution. We compare our sample to a mass and magnitude-matched sample of field galaxies, using data from the Sydney-AAO Multi-object Integral field spectrograph (SAMI) galaxy survey. We find that despite environmental differences, galaxies of mass M*>10^10 Msun have similarly low star formation rates (<3 Msun/yr). The lack of distinction between the star formation rates of the void and field environments points to quenching of massive galaxies being a largely mass-related effect. ","The Many Assembly Histories of Massive Void Galaxies as Revealed by
  Integral Field Spectroscopy"
21,712009068731195393,242915641,Kim Bott,['New paper on HIPPI polarimetry of HD 189733b on arXiv today and in MNRAS soon <LINK> @quasibody @dvcotton @astrojonty'],http://arxiv.org/abs/1603.05745,"We present linear polarization observations of the exoplanet system HD 189733 made with the HIgh Precision Polarimetric Instrument (HIPPI) on the Anglo-Australian Telescope (AAT). The observations have higher precision than any previously reported for this object. They do not show the large amplitude polarization variations reported by Berdyugina et al. 2008 and Berdyugina et al. 2011. Our results are consistent with polarization data presented by Wiktorowicz et al. 2015. A formal least squares fit of a Rayleigh-Lambert model yields a polarization amplitude of 29.4 +/- 15.6 parts-per-million. We observe a background constant level of polarization of ~ 55-70 ppm, which is a little higher than expected for interstellar polarization at the distance of HD 189733. ",The polarisation of HD 189733
22,710842624840699904,292832009,Tomasz Kacprzak,['Our new paper is out!\n<LINK>\n<LINK>\nA mass map of part of the DES area: <LINK>'],http://arxiv.org/abs/1603.05040v1,"Shear peak statistics has gained a lot of attention recently as a practical alternative to the two point statistics for constraining cosmological parameters. We perform a shear peak statistics analysis of the Dark Energy Survey (DES) Science Verification (SV) data, using weak gravitational lensing measurements from a 139 deg$^2$ field. We measure the abundance of peaks identified in aperture mass maps, as a function of their signal-to-noise ratio, in the signal-to-noise range $0<\mathcal S / \mathcal N<4$. To predict the peak counts as a function of cosmological parameters we use a suite of $N$-body simulations spanning 158 models with varying $\Omega_{\rm m}$ and $\sigma_8$, fixing $w = -1$, $\Omega_{\rm b} = 0.04$, $h = 0.7$ and $n_s=1$, to which we have applied the DES SV mask and redshift distribution. In our fiducial analysis we measure $\sigma_{8}(\Omega_{\rm m}/0.3)^{0.6}=0.77 \pm 0.07$, after marginalising over the shear multiplicative bias and the error on the mean redshift of the galaxy sample. We introduce models of intrinsic alignments, blending, and source contamination by cluster members. These models indicate that peaks with $\mathcal S / \mathcal N>4$ would require significant corrections, which is why we do not include them in our analysis. We compare our results to the cosmological constraints from the two point analysis on the SV field and find them to be in good agreement in both the central value and its uncertainty. We discuss prospects for future peak statistics analysis with upcoming DES data. ","] Cosmology constraints from shear peak statistics in Dark Energy Survey
  Science Verification data"
23,710708533440942081,526115229,Kevin Heng,"['New paper on atmospheric chemistry (#55 overall, #29 as first author): <LINK>']",http://arxiv.org/abs/1603.05418,"We present novel, analytical, equilibrium-chemistry formulae for the abundances of molecules in hot exoplanetary atmospheres that include the carbon, oxygen and nitrogen networks. Our hydrogen-dominated solutions involve acetylene (C$_2$H$_2$), ammonia (NH$_3$), carbon dioxide (CO$_2$), carbon monoxide (CO), ethylene (C$_2$H$_4$), hydrogen cyanide (HCN), methane (CH$_4$), molecular nitrogen (N$_2$) and water (H$_2$O). By considering only the gas phase, we prove that the mixing ratio of carbon monoxide is governed by a decic equation (polynomial equation of degree 10). We validate our solutions against numerical calculations of equilibrium chemistry that perform Gibbs free energy minimization and demonstrate that they are accurate at the $\sim 1\%$ level for temperatures from 500 to 3000 K. In hydrogen-dominated atmospheres, the ratio of abundances of HCN to CH$_4$ is nearly constant across a wide range of carbon-to-oxygen ratios, which makes it a robust diagnostic of the metallicity in the gas phase. Our validated formulae allow for the convenient benchmarking of chemical kinetics codes and provide an efficient way of enforcing chemical equilibrium in atmospheric retrieval calculations. ","Analytical Models of Exoplanetary Atmospheres. III. Gaseous C-H-O-N
  Chemistry with 9 Molecules"
24,709757472295280640,11990112,Quercia,"[""+1 RT @denadai2: Our new  #www2016 paper - A #cityscience study of Jane Jacobs' theories <LINK> <LINK>""]",http://arxiv.org/abs/1603.04012,"The Death and Life of Great American Cities was written in 1961 and is now one of the most influential book in city planning. In it, Jane Jacobs proposed four conditions that promote life in a city. However, these conditions have not been empirically tested until recently. This is mainly because it is hard to collect data about ""city life"". The city of Seoul recently collected pedestrian activity through surveys at an unprecedented scale, with an effort spanning more than a decade, allowing researchers to conduct the first study successfully testing Jacobs's conditions. In this paper, we identify a valuable alternative to the lengthy and costly collection of activity survey data: mobile phone data. We extract human activity from such data, collect land use and socio-demographic information from the Italian Census and Open Street Map, and test the four conditions in six Italian cities. Although these cities are very different from the places for which Jacobs's conditions were spelled out (i.e., great American cities) and from the places in which they were recently tested (i.e., the Asian city of Seoul), we find those conditions to be indeed associated with urban life in Italy as well. Our methodology promises to have a great impact on urban studies, not least because, if replicated, it will make it possible to test Jacobs's theories at scale. ","The Death and Life of Great Italian Cities: A Mobile Phone Data
  Perspective"
25,709659067950743552,5935462,Marco De Nadai,"[""You know what? Our new @www2016ca paper's out! A #cityscience study of Jane Jacobs' theories <LINK> <LINK>"", '@www2016ca @brulepri @danielequercia @stjaco @SKIL_Lab @guardiancities @FBKcom cc @taslanous @themiurgo @socdatalab @hyejin_youn @benhamner']",https://arxiv.org/abs/1603.04012,"The Death and Life of Great American Cities was written in 1961 and is now one of the most influential book in city planning. In it, Jane Jacobs proposed four conditions that promote life in a city. However, these conditions have not been empirically tested until recently. This is mainly because it is hard to collect data about ""city life"". The city of Seoul recently collected pedestrian activity through surveys at an unprecedented scale, with an effort spanning more than a decade, allowing researchers to conduct the first study successfully testing Jacobs's conditions. In this paper, we identify a valuable alternative to the lengthy and costly collection of activity survey data: mobile phone data. We extract human activity from such data, collect land use and socio-demographic information from the Italian Census and Open Street Map, and test the four conditions in six Italian cities. Although these cities are very different from the places for which Jacobs's conditions were spelled out (i.e., great American cities) and from the places in which they were recently tested (i.e., the Asian city of Seoul), we find those conditions to be indeed associated with urban life in Italy as well. Our methodology promises to have a great impact on urban studies, not least because, if replicated, it will make it possible to test Jacobs's theories at scale. ","The Death and Life of Great Italian Cities: A Mobile Phone Data
  Perspective"
26,709354059950628864,169081481,Hanno Rein ðŸ’«,"['New paper is on the arXiv! ""Second-order variational equations for N-body simulations"" <LINK> <LINK>', '@astrocrash You have no idea how many sign errors I made while working on this! Hurray to unit tests!', '@njgoldbaum @astrocrash ;-) Just the implementation. But that still helped finding errors in the algebra.']",http://arxiv.org/abs/1603.03424,"First-order variational equations are widely used in N-body simulations to study how nearby trajectories diverge from one another. These allow for efficient and reliable determinations of chaos indicators such as the Maximal Lyapunov characteristic Exponent (MLE) and the Mean Exponential Growth factor of Nearby Orbits (MEGNO). In this paper we lay out the theoretical framework to extend the idea of variational equations to higher order. We explicitly derive the differential equations that govern the evolution of second-order variations in the N-body problem. Going to second order opens the door to new applications, including optimization algorithms that require the first and second derivatives of the solution, like the classical Newton's method. Typically, these methods have faster convergence rates than derivative-free methods. Derivatives are also required for Riemann manifold Langevin and Hamiltonian Monte Carlo methods which provide significantly shorter correlation times than standard methods. Such improved optimization methods can be applied to anything from radial-velocity/transit-timing-variation fitting to spacecraft trajectory optimization to asteroid deflection. We provide an implementation of first and second-order variational equations for the publicly available REBOUND integrator package. Our implementation allows the simultaneous integration of any number of first and second-order variational equations with the high-accuracy IAS15 integrator. We also provide routines to generate consistent and accurate initial conditions without the need for finite differencing. ",Second-order variational equations for N-body simulations
27,709174610277715969,169081481,Hanno Rein ðŸ’«,"['My new paper with @astrodantamayo is now online! Title: ""Second-order variational equations for N-body simulations"" <LINK>', 'Code is on @github. Better yet: reproduce all figures interactively in the browser. #NoInstallation! @ProjectJupyter https://t.co/SJQMCI85rx', 'Effort seems to pay off: Just a few minutes after the paper appeared on the arXiv, 30 people are running the code! https://t.co/l2qHiLscbD']",http://arxiv.org/abs/1603.03424,"First-order variational equations are widely used in N-body simulations to study how nearby trajectories diverge from one another. These allow for efficient and reliable determinations of chaos indicators such as the Maximal Lyapunov characteristic Exponent (MLE) and the Mean Exponential Growth factor of Nearby Orbits (MEGNO). In this paper we lay out the theoretical framework to extend the idea of variational equations to higher order. We explicitly derive the differential equations that govern the evolution of second-order variations in the N-body problem. Going to second order opens the door to new applications, including optimization algorithms that require the first and second derivatives of the solution, like the classical Newton's method. Typically, these methods have faster convergence rates than derivative-free methods. Derivatives are also required for Riemann manifold Langevin and Hamiltonian Monte Carlo methods which provide significantly shorter correlation times than standard methods. Such improved optimization methods can be applied to anything from radial-velocity/transit-timing-variation fitting to spacecraft trajectory optimization to asteroid deflection. We provide an implementation of first and second-order variational equations for the publicly available REBOUND integrator package. Our implementation allows the simultaneous integration of any number of first and second-order variational equations with the high-accuracy IAS15 integrator. We also provide routines to generate consistent and accurate initial conditions without the need for finite differencing. ",Second-order variational equations for N-body simulations
28,708236918841024514,38217933,Pierre Vandergheynst,['New paper on uncertainty principles for signals on graphs on #arxiv and for everyone to enjoy! <LINK>'],http://arxiv.org/abs/1603.03030,"Uncertainty principles such as Heisenberg's provide limits on the time-frequency concentration of a signal, and constitute an important theoretical tool for designing and evaluating linear signal transforms. Generalizations of such principles to the graph setting can inform dictionary design for graph signals, lead to algorithms for reconstructing missing information from graph signals via sparse representations, and yield new graph analysis tools. While previous work has focused on generalizing notions of spreads of a graph signal in the vertex and graph spectral domains, our approach is to generalize the methods of Lieb in order to develop uncertainty principles that provide limits on the concentration of the analysis coefficients of any graph signal under a dictionary transform whose atoms are jointly localized in the vertex and graph spectral domains. One challenge we highlight is that due to the inhomogeneity of the underlying graph data domain, the local structure in a single small region of the graph can drastically affect the uncertainty bounds for signals concentrated in different regions of the graph, limiting the information provided by global uncertainty principles. Accordingly, we suggest a new way to incorporate a notion of locality, and develop local uncertainty principles that bound the concentration of the analysis coefficients of each atom of a localized graph spectral filter frame in terms of quantities that depend on the local structure of the graph around the center vertex of the given atom. Finally, we demonstrate how our proposed local uncertainty measures can improve the random sampling of graph signals. ",Global and Local Uncertainty Principles for Signals on Graphs
29,708118345480994816,51700215,Phil Bull,"['New paper: You can see a tell-tale modified gravity ""screening"" effect by plotting galaxy velocities against density <LINK>', '(Paper led by my student Magnus Fagernes Ivarsen in Oslo)']",http://arxiv.org/abs/1603.03072,"Alternative theories of gravity typically invoke an environment-dependent screening mechanism to allow phenomenologically interesting deviations from general relativity (GR) to manifest on larger scales, while reducing to GR on small scales. The observation of the transition from screened to unscreened behavior would be compelling evidence for beyond-GR physics. We show that pairwise peculiar velocity statistics, in particular the relative radial velocity dispersion, $\sigma_\parallel$ , can be used to observe this transition when they are binned by some measure of halo environment. We established this by measuring the radial velocity dispersion between pairs of halos in N-body simulations for three $f(R)$ gravity and four symmetron models. We developed an estimator involving only line-of-sight velocities to show that this quantity is observable, and binned the results in halo mass, ambient density, and the isolatedness of halos. Ambient density is found to be the most relevant measure of environment; it is distinct from isolatedness, and correlates well with theoretical expectations for the symmetron model. By binning $\sigma_\parallel$ in ambient density, we find a strong environment-dependent signature for the symmetron models, with the velocities showing a clear transition from GR to non-GR behavior. No such transition is observed for $f(R)$, as the relevant scales are deep in the unscreened regime. Observations of the relative radial velocity dispersion in forthcoming peculiar velocity surveys, if binned appropriately by environment, therefore offer a valuable way of detecting the screening signature of modified gravity. ","Distinguishing screening mechanisms with environment-dependent velocity
  statistics"
30,707990652064104448,288965677,Chris Casper,['New paper summarizes #solareclipse research. Ideas for cool amateur or #STEM science projects for #eclipse2017?\n<LINK>'],http://arxiv.org/abs/1603.02987,"This article reviews atmospheric changes associated with 44 solar eclipses, beginning with the first quantitative results available, from 1834 (earlier qualitative, accounts also exist). Eclipse meteorology attracted relatively few publications until the total solar eclipse of 16 February 1980, with the 11 August 1999 eclipse producing the most papers. Eclipses passing over populated areas such as Europe, China and India now regularly attract scientific attention, whereas atmospheric measurements of eclipses at remote locations remain rare. Many measurements and models have been used to exploit the uniquely predictable solar forcing provided by an eclipse. In this paper we compile the available publications and review a sub-set of them chosen on the basis of importance and novelty. Beyond the obvious reduction in incoming solar radiation, atmospheric cooling from eclipses can induce dynamical changes. Observations and meteorological modelling provide evidence for the generation of a local eclipse circulation which may be the origin of the ""eclipse wind"". Gravity waves set up by the eclipse can, in principle, be detected as atmospheric pressure fluctuations, though theoretical predictions are limited, and many of the data are inconclusive. Eclipse events providing important early insights into the ionisation of the upper atmosphere are also briefly reviewed. ",Atmospheric changes from solar eclipses
31,707820004796973056,26716739,Mattias Villani,"[""Our new paper  'Block-Wise Pseudo-Marginal Metropolis-Hastings' <LINK>"", '@chris_naesseth yes, blocking the particles/subsample indicators and updating a single block jointly with the original model parameters.', '@chris_naesseth it is another way of correlating the particles. Less general, but has some interesting advantages.']",http://arxiv.org/abs/1603.02485,"The pseudo-marginal (PM) approach is increasingly used for Bayesian inference in statistical models, where the likelihood is intractable but can be estimated unbiasedly. %Examples include random effect models, state-space models and data subsampling in big-data settings. Deligiannidis et al. (2016) show how the PM approach can be made much more efficient by correlating the underlying Monte Carlo (MC) random numbers used to form the estimate of the likelihood at the current and proposed values of the unknown parameters. Their approach greatly speeds up the standard PM algorithm, as it requires a much smaller number of samples or particles to form the optimal likelihood estimate. Our paper presents an alternative implementation of the correlated PM approach, called the block PM, which divides the underlying random numbers into blocks so that the likelihood estimates for the proposed and current values of the parameters only differ by the random numbers in one block. We show that this implementation of the correlated PM can be much more efficient for some specific problems than the implementation in Deligiannidis et al. (2016); for example when the likelihood is estimated by subsampling or the likelihood is a product of terms each of which is given by an integral which can be estimated unbiasedly by randomised quasi-Monte Carlo. Our article provides methodology and guidelines for efficiently implementing the block PM. A second advantage of the the block PM is that it provides a direct way to control the correlation between the logarithms of the estimates of the likelihood at the current and proposed values of the parameters than the implementation in Deligiannidis et al. (2016). We obtain methods and guidelines for selecting the optimal number of samples based on idealized but realistic assumptions. ",The Block Pseudo-Marginal Sampler
32,707774191945314306,526115229,Kevin Heng,['New paper: <LINK>\nThough he spelt my name wrong...'],http://arxiv.org/abs/1603.02794,"General circulation models of the atmosphere of hot Jupiters have shown the existence of a supersonic eastward equatorial jet. In this paper, we investigate the effects of compressibility on the atmospheric dynamics by solving the standard Euler equations. This is done by means of a series of simulations performed in the framework of the equatorial beta-plane approximation using the finite volume shock-capturing code RAMSES. At low resolution, we recover the classical results described in the literature: we find a strong and steady supersonic equatorial jet of a few km/s that displays no signature of shocks. We next show that the jet zonal velocity depends significantly on the grid meridional resolution. When that resolution is fine enough to properly resolve the jet, the latter is subject to a Kelvin-Helmholtz instability. The jet zonal mean velocity displays regular oscillations with a typical timescale of few days and a significant amplitude of about 15% of the jet velocity. We also find compelling evidence for the development of a vertical shear instability at pressure levels of a few bars. It seems to be responsible for an increased downward kinetic energy flux, significantly affecting the temperature of the deep atmosphere, and appears to act as a form of drag on the equatorial jet. This instability also creates velocity fluctuations that propagate upward and steepen into weak shocks at pressure levels of a few mbars. We conclude that hot Jupiter equatorial jets are potentially unstable to both a barotropic Kelvin-Helmholtz instability and a vertical shear instability. Upon confirmation using more realistic models, both instabilities could result in significant time variability of the atmospheric winds, may provide a small scale dissipation mechanism in the flow, and might have consequences for the internal evolution of hot Jupiters. ",Shear-driven instabilities and shocks in the atmospheres of hot Jupiters
33,707761145382359040,1921725858,Steven Byrnes,"['My new paper: How light travels through multi-layer thin films, in excessive detail. <LINK>']",http://arxiv.org/abs/1603.02720,"When light hits a multilayer planar stack, it is reflected, refracted, and absorbed in a way that can be derived from the Fresnel equations. The analysis is treated in many textbooks, and implemented in many software programs, but certain aspects of it are difficult to find explicitly and consistently worked out in the literature. Here, we derive the formulas underlying the transfer-matrix method of calculating the optical properties of these stacks, including oblique-angle incidence, absorption-vs-position profiles, and ellipsometry parameters. We discuss and explain some strange consequences of the formulas in the situation where the incident and/or final (semi-infinite) medium are absorptive, such as calculating $T>1$ in the absence of gain. We also discuss some implementation details like complex-plane branch cuts. Finally, we derive modified formulas for including one or more ""incoherent"" layers, i.e. very thick layers in which interference can be neglected. This document was written in conjunction with the ""tmm"" Python software package, which implements these calculations. ",Multilayer optical calculations
34,707381486014615552,49137494,Steven Tingay,"['Latest MWA paper, a radio search for signals associated with neutrinos.  With our (many) new friends from the... <LINK>']",https://arxiv.org/abs/1603.02271,"We present a search, using the Murchison Widefield Array (MWA), for electromagnetic counterparts to two candidate high energy neutrino events detected by the ANTARES neutrino telescope in 2013 November and 2014 March. These events were selected by ANTARES because they are consistent, within 0.4 degrees, with the locations of galaxies within 20 Mpc of Earth. Using MWA archival data at frequencies between 118 and 182 MHz, taken ~20 days prior to, at the same time as, and up to a year after the neutrino triggers, we look for transient or strongly variable radio sources consistent with the neutrino positions. No such counterparts are detected, and we set a 5 sigma upper limit for low-frequency radio emission of ~1E37 erg/s for progenitors at 20 Mpc. If the neutrino sources are instead not in nearby galaxies, but originate in binary neutron star coalescences, our limits place the progenitors at z > 0.2. While it is possible, due to the high background from atmospheric neutrinos, that neither event is astrophysical, the MWA observations are nevertheless among the first to follow up neutrino candidates in the radio, and illustrate the promise of wide-field instruments like MWA to detect electromagnetic counterparts to such events. ","Murchison Widefield Array Limits on Radio Emission from ANTARES Neutrino
  Events"
35,706735909081776128,3250001664,Colin Hill,"['our kSZ paper is out -- a new (hmm, ""zombie"") method using projected fields w/ @DavidSpergel, S. Ferraro, +more <LINK>']",http://arxiv.org/abs/1603.01608,"The kinematic Sunyaev-Zel'dovich (kSZ) effect --- the Doppler boosting of cosmic microwave background (CMB) photons due to Compton-scattering off free electrons with non-zero bulk velocity --- probes the abundance and distribution of baryons in the Universe. All kSZ measurements to date have explicitly required spectroscopic redshifts. Here, we implement a novel estimator for the kSZ -- large-scale structure cross-correlation based on projected fields: it does not require redshift estimates for individual objects, allowing kSZ measurements from large-scale imaging surveys. We apply this estimator to cleaned CMB temperature maps constructed from Planck and Wilkinson Microwave Anisotropy Probe data and a galaxy sample from the Wide-field Infrared Survey Explorer (WISE). We measure the kSZ effect at 3.8-4.5$\sigma$ significance, depending on the use of additional WISE galaxy bias constraints. We verify that our measurements are robust to possible dust emission from the WISE galaxies. Assuming the standard $\Lambda$CDM cosmology, we directly constrain $( {f_{b}}/{0.158} ) ( {f_{\rm free}}/{1.0} ) = 1.48 \pm 0.19$ (statistical error only) at redshift $z \approx 0.4$, where $f_{b}$ is the fraction of matter in baryonic form and $f_{\rm free}$ is the free electron fraction. This is the tightest kSZ-derived constraint reported to date on these parameters. The consistency between the $f_{b}$ value found here and the values inferred from analyses of the primordial CMB and Big Bang nucleosynthesis verifies that baryons approximately trace the dark matter distribution down to $\sim$Mpc scales. While our projected-field estimator is already competitive with other kSZ approaches when applied to current datasets (because we are able to use the full-sky WISE photometric survey), it will yield enormous signal-to-noise when applied to upcoming high-resolution, multi-frequency CMB surveys. ","The Kinematic Sunyaev-Zel'dovich Effect with Projected Fields: A Novel
  Probe of the Baryon Distribution with Planck, WMAP, and WISE Data"
36,705776590437924864,4758937001,Duncan Christie,"['New paper with Jake Turner:\n\n""Investigation of the environment around close-in transiting exoplanets using CLOUDY""\n\n<LINK>']",http://arxiv.org/abs/1603.01229,"It has been suggested that hot stellar wind gas in a bow shock around an exoplanet is sufficiently opaque to absorb stellar photons and give rise to an observable transit depth at optical and UV wavelengths. In the first part of this paper, we use the CLOUDY plasma simulation code to model the absorption from X-ray to radio wavelengths by 1-D slabs of gas in coronal equilibrium with varying densities ($10^{4}-10^{8} \, {\rm cm^{-3}}$) and temperatures ($2000-10^{6} \ {\rm K}$) illuminated by a solar spectrum. For slabs at coronal temperatures ($10^{6} \ {\rm K}$) and densities even orders of magnitude larger than expected for the compressed stellar wind ($10^{4}-10^{5} \, {\rm cm^{-3}}$), we find optical depths orders of magnitude too small ($> 3\times10^{-7}$) to explain the $\sim3\%$ UV transit depths seen with Hubble. Using this result and our modeling of slabs with lower temperatures ($2000-10^4 {\rm K}$), the conclusion is that the UV transits of WASP-12b and HD 189733b are likely due to atoms originating in the planet, as the stellar wind is too highly ionized. A corollary of this result is that transport of neutral atoms from the denser planetary atmosphere outward must be a primary consideration when constructing physical models. In the second part of this paper, additional calculations using CLOUDY are carried out to model a slab of planetary gas in radiative and thermal equilibrium with the stellar radiation field. Promising sources of opacity from the X-ray to radio wavelengths are discussed, some of which are not yet observed. ","Investigation of the environment around close-in transiting exoplanets
  using CLOUDY"
37,705205683554156544,2337598033,Geraint F. Lewis,"['Ace new paper on arxiv on Major Substructure in the M31 Outer Halo with @nfmartin1980 &amp; @pascaljelahi    \n<LINK>', '@nfmartin1980 @pascaljelahi @ickbat @dougalmackey sorry dudes, my excuse was that I was a cloud computing conference and tweeting on the fly', '@nfmartin1980 @pascaljelahi @ickbat @dougalmackey you can do things like that ""in the cloud""!!!!']",http://arxiv.org/abs/1603.00528,"We present a renewed look at M31's Giant Stellar Stream along with the nearby structures Stream C and Stream D, exploiting a new algorithm capable of fitting to the red giant branch (RGB) of a structure in both colour and magnitude space. Using this algorithm, we are able to generate probability distributions in distance, metallicity and RGB width for a series of subfields spanning these structures. Specifically, we confirm a distance gradient of approximately 20 kpc per degree along a 6 degree extension of the Giant Stellar Stream, with the farthest subfields from M31 lying ~ 120 kpc more distant than the inner-most subfields. Further, we find a metallicity that steadily increases from -0.7^{+0.1}_{-0.1} dex to -0.2^{+0.2}_{-0.1} dex along the inner half of the stream before steadily dropping to a value of -1.0^{+0.2}_{-0.2} dex at the farthest reaches of our coverage. The RGB width is found to increase rapidly from 0.4^{+0.1}_{-0.1} dex to 1.1^{+0.2}_{-0.1} dex in the inner portion of the stream before plateauing and decreasing marginally in the outer subfields of the stream. In addition, we estimate Stream C to lie at a distance between 794 and 862 kpc and Stream D between 758 kpc and 868 kpc. We estimate the median metallicity of Stream C to lie in the range -0.7 to -1.6 dex and a metallicity of -1.1^{+0.3}_{-0.2} dex for Stream D. RGB widths for the two structures are estimated to lie in the range 0.4 to 1.2 dex and 0.3 to 0.7 dex respectively. In total, measurements are obtained for 19 subfields along the Giant Stellar Stream, 4 along Stream C, 5 along Stream D and 3 general M31 spheroid fields for comparison. We thus provide a higher resolution coverage of the structures in these parameters than has previously been available in the literature. ","Major Substructure in the M31 Outer Halo: Distances and Metallicities
  along the Giant Stellar Stream"
38,705066326935654400,149075374,Stephanie T. Douglas,"['My new paper is out! K2 Rotation Periods for Low-mass Hyads, and the Implications for Gyrochronology: <LINK>', ""Need Prot for Hyades M dwarfs? Want to know how binaries impact mass-period distribution? We've got you covered: https://t.co/8w6P74DOZ0"", '@SeeTheStarsRise thanks! ðŸ˜Š']",http://arxiv.org/abs/1603.00419,"As the closest open cluster to the Sun, the Hyades is an important benchmark for many stellar properties, but its members are also scattered widely over the sky. Previous studies of stellar rotation in the Hyades relied on targeted observations of single stars or data from shallower all-sky variability surveys. The re-purposed Kepler mission, K2, is the first opportunity to measure rotation periods ($P_{rot}$) for many Hyads simultaneously while also being sensitive to fully convective M dwarf members. We analyze K2 data for 65 Hyads and present $P_{rot}$ values for 48. Thirty-seven of these are new measurements, including the first $P_{rot}$ measurements for fully convective Hyads. For nine of the 11 stars with $P_{rot}$ in the literature and this work, the measurements are consistent; we attribute the two discrepant cases to spot evolution. Nearly all stars with masses $\le0.3M_\odot$ are rapidly rotating, indicating a change in rotation properties at the boundary to full convection. When confirmed and candidate binaries are removed from the mass-period plane, only three rapid rotators with masses $\ge0.3M_\odot$ remain. This is in contrast to previous results showing that the single-valued mass-period sequence for $\approx$600 Myr-old stars ends at $\approx0.65M_\odot$ when binaries are included. We also find that models of rotational evolution predict faster rotation than is actually observed at $\approx$600 Myrs for stars $\le0.9M_\odot$. The dearth of single rapid rotators more massive than $\approx0.3M_\odot$ indicates that magnetic braking is more efficient than previously thought, and that age-rotation studies must account for multiplicity. ","K2 Rotation Periods for low-mass Hyads and the Implications for
  Gyrochronology"
39,704959359843999744,237682040,Daniel Manzano,['My new paper is out: Dynamical signatures of molecular symmetries in nonequilibrium quantum\n transport\n\n<LINK>'],http://arxiv.org/abs/1603.00156,"Symmetries play a crucial role in ubiquitous systems found in Nature. In this work, we propose an elegant approach to detect symmetries by measuring quantum currents. Our detection scheme relies on initiating the system in an anti-symmetric initial condition, with respect to the symmetric sites, and using a probe that acts like a local noise. Depending on the position of the probe the currents exhibit unique signatures such as a quasi-stationary plateau indicating the presence of meta-stability and multi-exponential decays in case of multiple symmetries. The signatures are sensitive to the probe and vanish completely when the timescale of the coherent system dynamics is much longer than the timescale of the probe. These results are demonstrated using a $4$-site model and an archetypal example of the para-benzene ring and are shown to be robust under a weak disorder. ","Dynamical signatures of molecular symmetries in nonequilibrium quantum
  transport"
40,704899430349144064,96779364,Arnab Bhattacharyya,['New paper: An optimal algorithm for finding heavy hitters in insertion streams! <LINK>'],http://arxiv.org/abs/1603.00213,"We give the first optimal bounds for returning the $\ell_1$-heavy hitters in a data stream of insertions, together with their approximate frequencies, closing a long line of work on this problem. For a stream of $m$ items in $\{1, 2, \dots, n\}$ and parameters $0 < \epsilon < \phi \leq 1$, let $f_i$ denote the frequency of item $i$, i.e., the number of times item $i$ occurs in the stream. With arbitrarily large constant probability, our algorithm returns all items $i$ for which $f_i \geq \phi m$, returns no items $j$ for which $f_j \leq (\phi -\epsilon)m$, and returns approximations $\tilde{f}_i$ with $|\tilde{f}_i - f_i| \leq \epsilon m$ for each item $i$ that it returns. Our algorithm uses $O(\epsilon^{-1} \log\phi^{-1} + \phi^{-1} \log n + \log \log m)$ bits of space, processes each stream update in $O(1)$ worst-case time, and can report its output in time linear in the output size. We also prove a lower bound, which implies that our algorithm is optimal up to a constant factor in its space complexity. A modification of our algorithm can be used to estimate the maximum frequency up to an additive $\epsilon m$ error in the above amount of space, resolving Question 3 in the IITK 2006 Workshop on Algorithms for Data Streams for the case of $\ell_1$-heavy hitters. We also introduce several variants of the heavy hitters and maximum frequency problems, inspired by rank aggregation and voting schemes, and show how our techniques can be applied in such settings. Unlike the traditional heavy hitters problem, some of these variants look at comparisons between items rather than numerical values to determine the frequency of an item. ","An Optimal Algorithm for l1-Heavy Hitters in Insertion Streams and
  Related Problems"
41,717536253927788544,48712353,Sungjin Ahn ðŸ‡ºðŸ‡¦,['Pointing the unknown words! Our new paper on the rare/unknown word problem in conditional language model. <LINK>'],https://arxiv.org/abs/1603.08148,"The problem of rare and unknown words is an important issue that can potentially influence the performance of many NLP systems, including both the traditional count-based and the deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models using attention. Our model uses two softmax layers in order to predict the next word in conditional language models: one predicts the location of a word in the source sentence, and the other predicts a word in the shortlist vocabulary. At each time-step, the decision of which softmax layer to use choose adaptively made by an MLP which is conditioned on the context.~We motivate our work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known.~We observe improvements on two tasks, neural machine translation on the Europarl English to French parallel corpora and text summarization on the Gigaword dataset using our proposed model. ",Pointing the Unknown Words
42,705198778408521728,353206839,Peter Bailis,"['New paper: ""MacroBase: Analytic Monitoring for the Internet of Things"" <LINK>']",https://arxiv.org/abs/1603.00567,"As data volumes continue to rise, manual inspection is becoming increasingly untenable. In response, we present MacroBase, a data analytics engine that prioritizes end-user attention in high-volume fast data streams. MacroBase enables efficient, accurate, and modular analyses that highlight and aggregate important and unusual behavior, acting as a search engine for fast data. MacroBase is able to deliver order-of-magnitude speedups over alternatives by optimizing the combination of explanation and classification tasks and by leveraging a new reservoir sampler and heavy-hitters sketch specialized for fast data streams. As a result, MacroBase delivers accurate results at speeds of up to 2M events per second per query on a single core. The system has delivered meaningful results in production, including at a telematics company monitoring hundreds of thousands of vehicles. ",MacroBase: Prioritizing Attention in Fast Data
43,710033468386893824,268169845,AndrÃ©s Asensio Ramos,['Nice piece of work by one of our PhD students. We find active region filaments might have weak fields after all <LINK>'],http://arxiv.org/abs/1603.04645,"Recent spectropolarimetric observations of active region filaments have revealed polarization profiles with signatures typical of the strong field Zeeman regime. The conspicuous absence in those observations of scattering polarization and Hanle effect signatures was then pointed out by some authors. This was interpreted either as a signature of mixed ""turbulent"" field components or as a result of optical thickness. In this article, we present a natural scenario to explain these Zeeman-only spectro-polarimetric observations of active region filaments. We propose a two-component model, one on top of the other. Both components have horizontal fields, the azimuth difference between them being close to 90 degrees. The component that lies lower in the atmosphere is permeated by a strong field of the order of 600 G, while the upper component has much weaker fields, of the order of 10 G. The ensuing scattering polarization signatures of the individual components have opposite signs, so that its combination along the line of sight reduces --and even can cancel out-- the Hanle signatures, giving rise to an apparent only-Zeeman profile. This model is also applicable to other chromospheric structures seen in absorption above active regions. ",Active region filaments might harbor weak magnetic fields
44,710698331681456128,347181485,Jason Spyromilio; Î™Î¬ÏƒÏ‰Î½ Î£Ï€Ï…ÏÎ¿Î¼Î¯Î»Î¹Î¿Ï‚,['look what we found! Molecular Hydrogen in #supernova 1987A. \n<LINK> <LINK>'],https://arxiv.org/abs/1603.05560,"Both CO and SiO have been observed at early and late phases in SN 1987A. H_2 was predicted to form at roughly the same time as these molecules, but was not detected at early epochs. Here we report the detection of NIR lines from H_2 at 2.12 mu and 2.40 mu in VLT/SINFONI spectra obtained between days 6489 and 10,120. The emission is concentrated to the core of the supernova in contrast to H-alpha and approximately coincides with the [Si I]/[Fe II] emission detected previously in the ejecta. Different excitation mechanisms and power sources of the emission are discussed. From the nearly constant H_2 luminosities we favour excitation resulting from the 44Ti decay. ",Discovery of molecular hydrogen in SN 1987A
