,TweetID,AuthorID,AuthorName,Tweets,arxiv_link,Abstract,Title
0,695565872891621376,75249390,Axel Maas,['I have published a new blog entry on our recent paper (<LINK>) on #2HDM at <LINK> #np3'],http://arxiv.org/abs/1601.02006,"Observable states are gauge-invariant. In a non-Abelian gauge theory, these are necessarily composite operators. We investigate the spectrum of these operators in the two-Higgs-doublet model. For this purpose, we are working along the lines of the Fr\""ohlich-Morchio-Strocchi mechanism to relate the physical spectrum to the spectrum of the elementary particles. We also investigate the consequences of spontaneous breaking of the global (custodial) symmetry group. Finally, we briefly comment on how to test the results using lattice methods. ","Gauge invariance and the physical spectrum in the two-Higgs-doublet
  model"
1,694223402932899841,212431150,Faryad Sahneh,"['Our new paper: ""Sequential Monte Carlo Filtering Estimation of Ebola Progression in West Africa"" <LINK> #NetSE']",http://arxiv.org/abs/1601.07606,We use a multivariate formulation of sequential Monte Carlo filter that utilizes mechanistic models for Ebola virus propagation and available incidence data to simultaneously estimate the disease progression states and the model parameters. This method has the advantage of performing the inference online as the new data becomes available and estimates the evolution of basic reproductive ratio $R_0(t)$ of the Ebola outbreak through time. Our analysis identifies a peak in the basic reproductive ratio close to the time when Ebola cases were reported in Europe and the USA. ,"Sequential Monte Carlo Filtering Estimation of Ebola Progression in West
  Africa"
2,694093392414937088,2999702157,Anton Ilderton,['New paper on measuring vacuum birefringence using intense laser fields <LINK>'],http://arxiv.org/abs/1601.08045,"The measurement of vacuum polarisation effects, in particular vacuum birefringence, using combined optical and x-ray laser pulses is now actively pursued. Here we briefly examine the feasibility of two alternative setups. The first utilises an alternative target, namely a converging dipole pulse, and the second uses an alternative probe, namely the synchrotron-like emission from highly energetic particles, themselves interacting with a laser pulse. The latter setup has been proposed for experiments at ELI-NP. ","Prospects for studying vacuum polarisation using dipole and synchrotron
  radiation"
3,694076172372697088,1430303833,Dave Woods,['New paper on arXiv on screening for GLMs with @j_mcgree and Sue Lewis: <LINK>'],http://arxiv.org/abs/1601.08088,"The first investigation is made of designs for screening experiments where the response variable is approximated by a generalised linear model. A Bayesian information capacity criterion is defined for the selection of designs that are robust to the form of the linear predictor. For binomial data and logistic regression, the effectiveness of these designs for screening is assessed through simulation studies using all-subsets regression and model selection via maximum penalised likelihood and a generalised information criterion. For Poisson data and log-linear regression, similar assessments are made using maximum likelihood and the Akaike information criterion for minimally-supported designs that are constructed analytically. The results show that effective screening, that is, high power with moderate type I error rate and false discovery rate, can be achieved through suitable choices for the number of design support points and experiment size. Logistic regression is shown to present a more challenging problem than log-linear regression. Some areas for future work are also indicated. ","Model selection via Bayesian information capacity designs for
  generalised linear models"
4,693490180162977792,180240998,Franck Marchis,"['New @PlanetImager paper ""The PDS 66 Circumstellar Disk as seen in Polarized Light with GPI"" <LINK> <LINK>']",https://arxiv.org/abs/1601.07248,"We present H and K band imaging polarimetry for the PDS 66 circumstellar disk obtained during the commissioning of the Gemini Planet Imager (GPI). Polarization images reveal a clear detection of the disk in to the 0.12'' inner working angle (IWA) in H band, almost 3 times as close to the star as the previous HST observations with NICMOS and STIS (0.35'' effective IWA). The centro-symmetric polarization vectors confirm that the bright inner disk detection is due to circumstellar scattered light. A more diffuse disk extends to a bright outer ring centered at 80 AU. We discuss several physical mechanisms capable of producing the observed ring + gap structure. GPI data confirm enhanced scattering on the East side of the disk which is inferred to be nearer to us. We also detect a lateral asymmetry in the South possibly due to shadowing from material within the inner working angle. This likely corresponds to a temporally variable azimuthal asymmetry observed in HST/STIS coronagraphic imaging. ","The PDS 66 Circumstellar Disk as seen in Polarized Light with the Gemini
  Planet Imager"
5,693122964586258432,21611239,Sean Carroll,"[""Gravity as an entropic force - what works &amp; what doesn't. New paper with Grant Remmen. <LINK> <LINK>""]",http://arxiv.org/abs/1601.07558,"We investigate theories in which gravity arises as a consequence of entropy. We distinguish between two approaches to this idea: holographic gravity, in which Einstein's equation arises from keeping entropy stationary in equilibrium under variations of the geometry and quantum state of a small region, and thermodynamic gravity, in which Einstein's equation emerges as a local equation of state from constraints on the area of a dynamical lightsheet in a fixed spacetime background. Examining holographic gravity, we argue that its underlying assumptions can be justified in part using recent results on the form of the modular energy in quantum field theory. For thermodynamic gravity, on the other hand, we find that it is difficult to formulate a self-consistent definition of the entropy, which represents an obstacle for this approach. This investigation points the way forward in understanding the connections between gravity and entanglement. ",What is the Entropy in Entropic Gravity?
6,693046154318192641,1408022179,Lia Sartori,['What happens around a dying quasar? Have a look at my new paper <LINK>'],http://arxiv.org/abs/1601.07550v1,"We present deep Chandra X-ray observations of the core of IC 2497, the galaxy associated with Hanny's Voorwerp and hosting a fading AGN. We find extended soft X-ray emission from hot gas around the low intrinsic luminosity (unobscured) AGN ($L_{\rm bol} \sim 10^{42}-10^{44}$ erg s$^{-1}$). The temperature structure in the hot gas suggests the presence of a bubble or cavity around the fading AGN ($\mbox{E$_{\rm bub}$} \sim 10^{54} - 10^{55}$ erg). A possible scenario is that this bubble is inflated by the fading AGN, which after changing accretion state is now in a kinetic mode. Other possibilities are that the bubble has been inflated by the past luminous quasar ($L_{\rm bol} \sim 10^{46}$ erg s$^{-1}$), or that the temperature gradient is an indication of a shock front from a superwind driven by the AGN. We discuss the possible scenarios and the implications for the AGN-host galaxy interaction, as well as an analogy between AGN and X-ray binaries lifecycles. We conclude that the AGN could inject mechanical energy into the host galaxy at the end of its lifecycle, and thus provide a source for mechanical feedback, in a similar way as observed for X-ray binaries. ","] Extended X-ray emission in the IC 2497 - Hanny's Voorwerp system: energy
  injection in the gas around a fading AGN"
7,692896993237045248,3885912072,Marshall Johnson,"['New 1st author paper: 2 hot Jupiters, written in 3 weeks for my 4th paper on arXiv &amp; 5th submitted: <LINK>']",http://arxiv.org/abs/1601.07844,"We confirm the planetary nature of two transiting hot Jupiters discovered by the Kepler spacecraft's K2 extended mission in its Campaign 4, using precise radial velocity measurements from FIES@NOT, HARPS-N@TNG, and the coud\'e spectrograph on the McDonald Observatory 2.7 m telescope. K2-29 b (EPIC 211089792 b) transits a K1V star with a period of $3.2589263\pm0.0000015$ days; its orbit is slightly eccentric ($e=0.084_{-0.023}^{+0.032}$). It has a radius of $R_P=1.000_{-0.067}^{+0.071}$ $R_J$ and a mass of $M_P=0.613_{-0.026}^{+0.027}$ $M_J$. Its host star exhibits significant rotational variability, and we measure a rotation period of $P_{\mathrm{rot}}=10.777 \pm 0.031$ days. K2-30 b (EPIC 210957318 b) transits a G6V star with a period of $4.098503\pm0.000011$ days. It has a radius of $R_P=1.039_{-0.051}^{+0.050}$ $R_J$ and a mass of $M_P=0.579_{-0.027}^{+0.028}$ $M_J$. The star has a low metallicity for a hot Jupiter host, $[\mathrm{Fe}/\mathrm{H}]=-0.15 \pm 0.05$. ",Two Hot Jupiters from K2 Campaign 4
8,692802022576357376,340435374,Joshua Weitz,['New paper <LINK> - how intrinsic noise affects confidence in estimating epidemic spread w/@bradfordptaylor &amp; @jd_mathbio'],http://arxiv.org/abs/1601.06829,"Dynamic models - often deterministic in nature - were used to estimate the basic reproductive number, R_0, of the 2014-5 Ebola virus disease (EVD) epidemic outbreak in West Africa. Estimates of R_0 were then used to project the likelihood for large outbreak sizes, e.g., exceeding hundreds of thousands of cases. Yet fitting deterministic models can lead to over-confidence in the confidence intervals of the fitted R_0, and, in turn, the type and scope of necessary interventions. In this manuscript we propose a hybrid stochastic-deterministic method to estimate R_0 and associated confidence intervals (CIs). The core idea is that stochastic realizations of an underlying deterministic model can be used to evaluate the compatibility of candidate values of R_0 with observed epidemic curves. The compatibility is based on comparing the distribution of expected epidemic growth rates with the observed epidemic growth rate given ""process noise"", i.e., arising due to stochastic transmission, recovery and death events. By applying our method to reported EVD case counts from Guinea, Liberia and Sierra Leone, we show that prior estimates of R_0 based on deterministic fits appear to be more confident than analysis of stochastic trajectories suggests should be possible. Moving forward, we recommend including a hybrid stochastic-deterministic fitting procedure when quantifying the full R_0 CI at the onset of an epidemic due to multiple sources of noise. ","Stochasticity and the limits to confidence when estimating R_0 of Ebola
  and other emerging infectious diseases"
9,692517871637913600,143549353,Torsten Timm,['New paper on ArXiv: Co-Occurrence Patterns in the Voynich Manuscript <LINK> #Voynich'],http://arxiv.org/abs/1601.07435,The Voynich Manuscript is a medieval book written in an unknown script. This paper studies the distribution of similarly spelled words in the Voynich Manuscript. It shows that the distribution of words within the manuscript is not compatible with natural languages. ,Co-Occurrence Patterns in the Voynich Manuscript
10,692364559223492609,314014164,Adrian Price-Whelan,"['New paper suggesting the Galactic bar induces chaos in the inner Milky Way, as inferred from a weird stellar stream:\n<LINK>', 'The first evidence for the importance of chaos in the orbits of stars around the Milky Way! (cc @JamesGleick)']",http://arxiv.org/abs/1601.06790,"The Ophiuchus stellar stream is peculiar: (1) its length is short given the age of its constituent stars, and (2) several probable member stars that lie close in both sky position and velocity have dispersions in these dimensions that far exceed those seen within the stream. The stream's proximity to the Galactic center suggests that the bar must have a significant influence on its dynamical history: The triaxiality and time-dependence of the bar may generate chaotic orbits in the vicinity of the stream that can greatly affect its morphology. We explore this hypothesis with models of stream formation along orbits consistent with Ophiuchus' properties in a Milky Way potential model that includes a rotating bar. We find that in all choices for the rotation parameters of the bar, orbits fit to the stream are strongly chaotic. Mock streams generated along these orbits qualitatively match the observed properties of the stream: because of chaos, stars stripped early generally form low-density, high-dispersion ""fans"" leaving only the most recently disrupted material detectable as a strong over-density. Our models predict that there should be more low-surface-brightness tidal debris than detected so far, likely with a complex phase-space morphology. The existence of or lack of these features around the Ophiuchus stream would provide an interesting constraint on the properties of the Milky Way bar and would help distinguish between formation scenarios for the stream. This is the first time that chaos has been used to explain the properties of a stellar stream and is the first demonstration of the dynamical importance of chaos in the Galactic halo. The existence of long, thin streams around the Milky Way---presumably formed along non- or weakly-chaotic orbits---may represent only a subset of the total population of disrupted satellites. ","Spending too much time at the Galactic bar: chaotic fanning of the
  Ophiuchus stream"
11,691982510578884608,3119088280,Dr. Victoria Grinberg,['Working with RXTE-HEXTE data? You may need our new calibration paper! <LINK> (P.S. We also have one for PCA!)'],http://arxiv.org/abs/1601.06174,"We have developed a correction tool to improve the quality of RXTE HEXTE spectra by employing the same method we used earlier to improve the quality of RXTE PCA spectra. We fit all of the hundreds of HEXTE spectra of the Crab individually to a simple power-law model, some 37 million counts in total for Cluster A and 39 million counts for Cluster B, and we create for each cluster a combined spectrum of residuals. We find that the residual spectrum of Cluster A is free of instrumental artifacts while that of Cluster B contains significant features with amplitudes ~1%; the most prominent is in the energy range 30-50 keV, which coincides with the iodine K edge. Starting with the residual spectrum for Cluster B, via an iterative procedure we created the calibration tool hexBcorr for correcting any Cluster B spectrum of interest. We demonstrate the efficacy of the tool by applying it to Cluster B spectra of two bright black holes, which contain several million counts apiece. For these spectra, application of the tool significantly improves the goodness of fit, while affecting only slightly the broadband fit parameters. The tool may be important for the study of spectral features, such as cyclotron lines, a topic that is beyond the scope of this paper. ",An Empirical Method for Improving the Quality of RXTE HEXTE Spectra
12,691976640025485313,1119518358,Emanuele D'Osualdo,"['My new paper with L. Ong ""On Hierarchical Communication Topologies in the pi-calculus"" accepted at #ESOP16 <LINK>']",http://arxiv.org/abs/1601.01725,"This paper is concerned with the shape invariants satisfied by the communication topology of {\pi}-terms, and the automatic inference of these invariants. A {\pi}-term P is hierarchical if there is a finite forest T such that the communication topology of every term reachable from P satisfies a T-shaped invariant. We design a static analysis to prove a term hierarchical by means of a novel type system that enjoys decidable inference. The soundness proof of the type system employs a non-standard view of {\pi}-calculus reactions. The coverability problem for hierarchical terms is decidable. This is proved by showing that every hierarchical term is depth-bounded, an undecidable property known in the literature. We thus obtain an expressive static fragment of the {\pi}-calculus with decidable safety verification problems. ",On Hierarchical Communication Topologies in the pi-calculus
13,691537603934457856,572479189,Manlio De Domenico,['Using mux nets to evaluate the impact of interdisciplinary research? Or new paper with @elisa_omodei @_AlexArenas <LINK>'],http://arxiv.org/abs/1601.06075,"Nowadays, scientific challenges usually require approaches that cross traditional boundaries between academic disciplines, driving many researchers towards interdisciplinarity. Despite its obvious importance, there is a lack of studies on how to quantify the influence of interdisciplinarity on the research impact, posing uncertainty in a proper evaluation for hiring and funding purposes. Here we propose a method based on the analysis of bipartite interconnected multilayer networks of citations and disciplines, to assess scholars, institutions and countries interdisciplinary importance. Using data about physics publications and US patents, we show that our method allows to reward, using a quantitative approach, scholars and institutions that have carried out interdisciplinary work and have had an impact in different scientific areas. The proposed method could be used by funding agencies, universities and scientific policy decision makers for hiring and funding purposes, and to complement existing methods to rank universities and countries. ","Evaluating the impact of interdisciplinary research: a multilayer
  network approach"
14,690851144457961472,246677519,Michael Batty,"['Agglomeration, The Keys to the Good City? New Paper by Clementine Coitteau from CASA group <LINK> &amp; <LINK>']",https://arxiv.org/abs/1601.05664,"Agglomeration economies are a persistent subject of debate among economists and urban planners. Their definition turns on whether or not larger cities and regions are more efficient and more productive than smaller ones. We complement existing discussion on agglomeration economies and the urban wage premium here by providing a sensitivity analysis of estimated coefficients to different delineations of urban agglomeration as well as to different definitions of the economic measure that summarises the urban premium. This quantity can consist of total wages measured at the place of work, or of income registered at the place of residence. The chosen option influences the scaling behaviour of city size as well as the spatial distribution of the phenomenon at the city level. Spatial discrepancies between the distribution of jobs and the distribution of households at different economic levels makes city definitions crucial to the estimation of economic relations which vary with city size. We argue this point by regressing measures of income and wage over about five thousands different definitions of cities in France, based on our algorithmic aggregation of administrative spatial units at regular cutoffs which reflect density, population thresholds and commuting flows. We also go beyond aggregated observations of wages and income by searching for evidence of larger inequalities and economic segregation in the largest cities. This paper therefore considers the spatial and economic complexity of cities with respect to discussion about how we measure agglomeration economies. It provides a basis for reflection on alternative ways to model the processes which lead to observed variations, and this can provide insights for more comprehensive regional planning. ",Defining urban agglomerations to detect agglomeration economies
15,689807711026819073,2999702157,Anton Ilderton,['New paper on vacuum polarisation effects -- how virtual particles lead to scattering of real photons <LINK>'],http://arxiv.org/abs/1601.05021,"We apply worldline methods to the study of vacuum polarisation effects in plane wave backgrounds, in both scalar and spinor QED. We calculate helicity-flip probabilities to one loop order and treated exactly in the background field, and provide a toolkit of methods for use in investigations of higher-order processes. We also discuss the connections between the worldline, S-matrix, and lightfront approaches to vacuum polarisation effects. ",The worldline approach to helicity flip in plane waves
16,689711427393683457,234398193,Hal Tasaki,"['[New Paper]\nA. Tanaka &amp; H. Tasaki\nMetallic ferromagnetism supported by a single band in a multi-band Hubbard model\n<LINK>', 'Latest work in the ""constructive approach"" to metallic ferromagnetism.  The result may not be too impressive, but we introduce a new', 'interesting technique intrinsic to conducting systems.  Worth reading if you are serious about proving ferromagnetism in the Hubbard model.', '(I know that not too many are really serious about developing rigorous theory of the Hubbard model...)']",http://arxiv.org/abs/1601.04265,"We construct a multi-band Hubbard model on the lattice obtained by ""decorating"" a closely packed $d$-dimensional lattice $\mathcal{M}$ (such as the triangular lattice) where $d\ge2$. We take the limits in which the Coulomb interaction and the band gap become infinitely large. Then there remains only a single band with finite energy, on which electrons are supported. Let the electron number be $N_\mathrm{e}=|\mathcal{M}|-N_\mathrm{h}$, where $|\mathcal{M}|$ corresponds to the electron number which makes the lowest (finite energy) band half-filled, and $N_\mathrm{h}$ is the number of ""holes"". It is expected that the model exhibits metallic ferromagnetism if $N_\mathrm{h}/|\mathcal{M}|$ is nonvanishing but sufficiently small. We prove that the ground states exhibit saturated ferromagnetism if $N_\mathrm{h}\le(\text{const.})|\mathcal{M}|^{2/(d+2)}$, and exhibit (not necessarily saturated) ferromagnetism if $N_\mathrm{h}\le(\mathrm{const.})|\mathcal{M}|^{(d+1)/(d+2)}$. This may be regarded as a rigorous example of metallic ferromagnetism provided that the system size $|\mathcal{M}|$ is not too large. ","Metallic ferromagnetism supported by a single band in a multi-band
  Hubbard model"
17,689510129176215552,4438354094,Tom Wong,"['Posted a new paper! ""Quantum Walk Search on Johnson Graphs"" <LINK> <LINK>']",http://arxiv.org/abs/1601.04212,"The Johnson graph $J(n,k)$ is defined by $n$ symbols, where vertices are $k$-element subsets of the symbols, and vertices are adjacent if they differ in exactly one symbol. In particular, $J(n,1)$ is the complete graph $K_n$, and $J(n,2)$ is the strongly regular triangular graph $T_n$, both of which are known to support fast spatial search by continuous-time quantum walk. In this paper, we prove that $J(n,3)$, which is the $n$-tetrahedral graph, also supports fast search. In the process, we show that a change of basis is needed for degenerate perturbation theory to accurately describe the dynamics. This method can also be applied to general Johnson graphs $J(n,k)$ with fixed $k$. ",Quantum Walk Search on Johnson Graphs
18,689497554241720320,3008464880,Carnegie Astronomy,['New paper from Magellan telescopes @ LCO: Detailed Chemical Abundances in Ultra-Faint Dwarf Galaxy Reticulum 2 <LINK>'],http://arxiv.org/abs/1601.04070,"The ultra-faint dwarf galaxy Reticulum 2 (Ret 2) was recently discovered in images obtained by the Dark Energy Survey. We have observed the four brightest red giants in Ret 2 at high spectral resolution using the Michigan/Magellan Fiber System. We present detailed abundances for as many as 20 elements per star, including 12 elements heavier than the Fe group. We confirm previous detection of high levels of r-process material in Ret 2 (mean [Eu/Fe]=+1.69+/-0.05) found in three of these stars (mean [Fe/H]=-2.88+/-0.10). The abundances closely match the r-process pattern found in the well-studied metal-poor halo star CS22892-052. Such r-process-enhanced stars have not been found in any other ultra-faint dwarf galaxy, though their existence has been predicted by at least one model. The fourth star in Ret 2 ([Fe/H]=-3.42+/-0.20) contains only trace amounts of Sr ([Sr/Fe]=-1.73+/-0.43) and no detectable heavier elements. One r-process enhanced star is also enhanced in C (natal [C/Fe]=+1.1). This is only the third such star known, which suggests that the nucleosynthesis sites leading to C and r-process enhancements are decoupled. The r-process-deficient star is enhanced in Mg ([Mg/Fe]=+0.81+/-0.14), and the other three stars show normal levels of alpha-enhancement (mean [Mg/Fe]=+0.34+/-0.03). The abundances of other alpha and Fe-group elements closely resemble those in ultra-faint dwarf galaxies and metal-poor halo stars, suggesting that the nucleosynthesis that led to the large r-process enhancements either produced no light elements or produced light-element abundance signatures indistinguishable from normal supernovae. ","Detailed Chemical Abundances in the r-Process-Rich Ultra-Faint Dwarf
  Galaxy Reticulum 2"
19,689402185147293696,382134761,Michele Tizzoni ðŸ‡ºðŸ‡¦,"['New paper out! ""Predicting human mobility through the assimilation of social media traces into mobility models"" <LINK>']",http://arxiv.org/abs/1601.04560,"Predicting human mobility flows at different spatial scales is challenged by the heterogeneity of individual trajectories and the multi-scale nature of transportation networks. As vast amounts of digital traces of human behaviour become available, an opportunity arises to improve mobility models by integrating into them proxy data on mobility collected by a variety of digital platforms and location-aware services. Here we propose a hybrid model of human mobility that integrates a large-scale publicly available dataset from a popular photo-sharing system with the classical gravity model, under a stacked regression procedure. We validate the performance and generalizability of our approach using two ground-truth datasets on air travel and daily commuting in the United States: using two different cross-validation schemes we show that the hybrid model affords enhanced mobility prediction at both spatial scales. ","Predicting human mobility through the assimilation of social media
  traces into mobility models"
20,688997045391257600,582233920,Antoine Allard,['New paper on arXiv investigating the hidden geometry of weighted complex networks <LINK> @clabbarcelona'],https://arxiv.org/abs/1601.03891,"The topology of many real complex networks has been conjectured to be embedded in hidden metric spaces, where distances between nodes encode their likelihood of being connected. Besides of providing a natural geometrical interpretation of their complex topologies, this hypothesis yields the recipe for sustainable Internet's routing protocols, sheds light on the hierarchical organization of biochemical pathways in cells, and allows for a rich characterization of the evolution of international trade. We present empirical evidence that this geometric interpretation also applies to the weighted organisation of real complex networks. We introduce a very general and versatile model and use it to quantify the level of coupling between their topology, their weights, and an underlying metric space. Our model accurately reproduces both their topology and their weights, and our results suggest that the formation of connections and the assignment of their magnitude are ruled by different processes. ",The hidden geometry of weighted complex networks
21,687599579542466560,526115229,Kevin Heng,['New paper on optical phase curves by my student: <LINK>'],http://arxiv.org/abs/1601.03050,"Optical phase curves have become one of the common probes of exoplanetary atmospheres, but the information they encode has not been fully elucidated. Building on a diverse body of work, we upgrade the Flexible Modeling System (FMS) to include scattering in the two-stream, dual-band approximation and generate plausible, three-dimensional structures of irradiated atmospheres to study the radiative effects of aerosols or condensates. In the optical, we treat the scattering of starlight using a generalisation of Beer's law that allows for a finite Bond albedo to be prescribed. In the infrared, we implement the two-stream solutions and include scattering via an infrared scattering parameter. We present a suite of four-parameter general circulation models for Kepler-7b and demonstrate that its climatology is expected to be robust to variations in optical and infrared scattering. The westward and eastward shifts of the optical and infrared phase curves, respectively, are shown to be robust outcomes of the simulations. Assuming micron-sized particles and a simplified treatment of local brightness, we further show that the peak offset of the optical phase curve is sensitive to the composition of the aerosols or condensates. However, to within the measurement uncertainties, we cannot distinguish between aerosols made of silicates (enstatite or forsterite), iron, corundum or titanium oxide, based on a comparison to the measured peak offset ($41^\circ \pm 12^\circ$) of the optical phase curve of Kepler-7b. Measuring high-precision optical phase curves will provide important constraints on the atmospheres of cloudy exoplanets and reduce degeneracies in interpreting their infrared spectra. ","Optical phase curves as diagnostics for aerosol composition in
  exoplanetary atmospheres"
22,687434967207538688,628967454,Bruce Desmarais,['new paper with @jakewbowers on designing experiments on networks -- <LINK>'],http://arxiv.org/abs/1601.00992,"How should a network experiment be designed to achieve high statistical power? Ex- perimental treatments on networks may spread. Randomizing assignment of treatment to nodes enhances learning about the counterfactual causal effects of a social network experiment and also requires new methodology (ex. Aronow and Samii 2017a; Bow- ers et al. 2013; Toulis and Kao 2013). In this paper we show that the way in which a treatment propagates across a social network affects the statistical power of an ex- perimental design. As such, prior information regarding treatment propagation should be incorporated into the experimental design. Our findings justify reconsideration of standard practice in circumstances where units are presumed to be independent even in simple experiments: information about treatment effects is not maximized when we assign half the units to treatment and half to control. We also present an exam- ple in which statistical power depends on the extent to which the network degree of nodes is correlated with treatment assignment probability. We recommend that re- searchers think carefully about the underlying treatment propagation model motivat- ing their study in designing an experiment on a network. ","Models, Methods and Network Topology: Experimental Design for the Study
  of Interference"
23,687385384842465280,3008464880,Carnegie Astronomy,['Ultrahigh-energy cosmic rays from the birth of magnetars! New paper from two of our theorists incl. @thejunaverse  <LINK>'],http://arxiv.org/abs/1601.02625,"Rapidly-spinning magnetars can potentially form by the accretion induced collapse of a white dwarf or by neutron star mergers if the equation of state of nuclear density matter is such that two low mass neutron stars can sometimes form a massive neutron star rather than a black hole. In either case, the newly born magnetar is an attractive site for producing ultrahigh-energy cosmic rays (particles with individual energies exceeding $10^{18}\,{\rm eV}$; UHECRs). The short-period spin and strong magnetic field are able to accelerate particles up to the appropriate energies, and the composition of material on and around the magnetar may naturally explain recent inferences of heavy elements in UHECRs. We explore whether the small amount of natal debris surrounding these magnetars allows the UHECRs to easily escape. We also investigate the impact on the UHECRs of the unique environment around the magnetar, which consists of a bubble of relativistic particles and magnetic field within the debris. Rates and energetics of UHECRs are consistent with such an origin even though the rates of events that produce rapidly-spinning magnetars remain very uncertain. The low ejecta mass also helps limit the high-energy neutrino background associated with this scenario to be below current IceCube constraints over most of the magnetar parameter space. A unique prediction is that UHECRs may be generated in old stellar environments without strong star formation in contrast to what would be expected for other UHECR scenarios, such as active galactic nuclei or long gamma-ray bursts. ","Ultrahigh-Energy Cosmic Rays from the ""En Caul"" Birth of Magnetars"
24,687294516160786432,975068215,Sarah Leslie,['Our new @SAMI_survey paper on galactic winds is on astroph <LINK> Well done I-Ting!'],http://arxiv.org/abs/1601.02022,"We investigate a sample of 40 local, main-sequence, edge-on disc galaxies using integral field spectroscopy with the Sydney-AAO Multi-object Integral field spectrograph (SAMI) Galaxy Survey to understand the link between properties of the extraplanar gas and their host galaxies. The kinematics properties of the extraplanar gas, including velocity asymmetries and increased dispersion, are used to differentiate galaxies hosting large-scale galactic winds from those dominated by the extended diffuse ionized gas. We find rather that a spectrum of diffuse gas-dominated to wind dominated galaxies exist. The wind-dominated galaxies span a wide range of star formation rates ($-1 \lesssim \log({\rm SFR/M_{\odot} yr^{-1}}) \lesssim 0.5$) across the whole stellar mass range of the sample ($8.5 \lesssim \log({\rm M_{*}/M_{\odot}}) \lesssim 11$). The wind galaxies also span a wide range in SFR surface densities ($10^{-3} \textrm{--} 10^{-1.5}\rm~M_{\odot} ~yr^{-1}~kpc^{-2}$) that is much lower than the canonical threshold of $\rm0.1~M_{\odot} ~yr^{-1}~kpc^{-2}$. The wind galaxies on average have higher SFR surface densities and higher $\rm H\delta_A$ values than those without strong wind signatures. The enhanced $\rm H\delta_A$ indicates that bursts of star formation in the recent past are necessary for driving large-scale galactic winds. We demonstrate with Sloan Digital Sky Survey data that galaxies with high SFR surface density have experienced bursts of star formation in the recent past. Our results imply that the galactic winds revealed in our study are indeed driven by bursts of star formation, and thus probing star formation in the time domain is crucial for finding and understanding galactic winds. ","The SAMI Galaxy Survey: extraplanar gas, galactic winds, and their
  association with star formation history"
25,686914695253618689,378228706,Hannah Wakeford,['My new paper about how we can best correct for systematics in @HUBBLE_space data is out :D <LINK> <LINK>'],http://arxiv.org/abs/1601.02587,"Hubble Space Telescope (HST) Wide Field Camera 3 (WFC3) infrared observations at 1.1-1.7$\mu$m probe primarily the H$_2$O absorption band at 1.4$\mu$m, and has provided low resolution transmission spectra for a wide range of exoplanets. We present the application of marginalisation based on Gibson (2014) to analyse exoplanet transit lightcurves obtained from HST WFC3, to better determine important transit parameters such as R$_p$/R$_*$, important for accurate detections of H$_2$O. We approximate the evidence, often referred to as the marginal likelihood, for a grid of systematic models using the Akaike Information Criterion (AIC). We then calculate the evidence-based weight assigned to each systematic model and use the information from all tested models to calculate the final marginalised transit parameters for both the band-integrated, and spectroscopic lightcurves to construct the transmission spectrum. We find that a majority of the highest weight models contain a correction for a linear trend in time, as well as corrections related to HST orbital phase. We additionally test the dependence on the shift in spectral wavelength position over the course of the observations and find that spectroscopic wavelength shifts $\delta_\lambda(\lambda)$, best describe the associated systematic in the spectroscopic lightcurves for most targets, while fast scan rate observations of bright targets require an additional level of processing to produce a robust transmission spectrum. The use of marginalisation allows for transparent interpretation and understanding of the instrument and the impact of each systematic evaluated statistically for each dataset, expanding the ability to make true and comprehensive comparisons between exoplanet atmospheres. ",Marginalising instrument systematics in HST WFC3 transit lightcurves
26,686874279820984320,804483812,Matteo Fasiolo,"['New paper on arxiv: ""An Extended Empirical Saddlepoint Approximation for Intractable Likelihoods"" <LINK>']",http://arxiv.org/abs/1601.01849,"The challenges posed by complex stochastic models used in computational ecology, biology and genetics have stimulated the development of approximate approaches to statistical inference. Here we focus on Synthetic Likelihood (SL), a procedure that reduces the observed and simulated data to a set of summary statistics, and quantifies the discrepancy between them through a synthetic likelihood function. SL requires little tuning, but it relies on the approximate normality of the summary statistics. We relax this assumption by proposing a novel, more flexible, density estimator: the Extended Empirical Saddlepoint approximation. In addition to proving the consistency of SL, under either the new or the Gaussian density estimator, we illustrate the method using two examples. One of these is a complex individual-based forest model for which SL offers one of the few practical possibilities for statistical inference. The examples show that the new density estimator is able to capture large departures from normality, while being scalable to high dimensions, and this in turn leads to more accurate parameter estimates, relative to the Gaussian alternative. The new density estimator is implemented by the esaddle R package, which can be found on the Comprehensive R Archive Network (CRAN). ","An Extended Empirical Saddlepoint Approximation for Intractable
  Likelihoods"
27,686469522379898880,75249390,Axel Maas,['We have put out a new paper on field theory for two instead of one #Higgs (two-Higgs-doublet models) - <LINK> #np3'],http://arxiv.org/abs/1601.02006,"Observable states are gauge-invariant. In a non-Abelian gauge theory, these are necessarily composite operators. We investigate the spectrum of these operators in the two-Higgs-doublet model. For this purpose, we are working along the lines of the Fr\""ohlich-Morchio-Strocchi mechanism to relate the physical spectrum to the spectrum of the elementary particles. We also investigate the consequences of spontaneous breaking of the global (custodial) symmetry group. Finally, we briefly comment on how to test the results using lattice methods. ","Gauge invariance and the physical spectrum in the two-Higgs-doublet
  model"
28,685668593296527360,2932678322,Keaton Bell,['New paper featuring a bunch of data that I acquired at @mcdonaldobs \n<LINK>'],http://arxiv.org/abs/1601.01316,"We report the discovery of 42 white dwarfs in the original Kepler mission field, including nine new confirmed pulsating hydrogen-atmosphere white dwarfs (ZZ Ceti stars). Guided by the Kepler-INT Survey (KIS), we selected white dwarf candidates on the basis of their U-g, g-r, and r-H_alpha photometric colours. We followed up these candidates with high-signal-to-noise optical spectroscopy from the 4.2-m William Herschel Telescope. Using ground-based, time-series photometry, we put our sample of new spectroscopically characterized white dwarfs in the context of the empirical ZZ Ceti instability strip. Prior to our search, only two pulsating white dwarfs had been observed by Kepler. Ultimately, four of our new ZZ Cetis were observed from space. These rich datasets are helping initiate a rapid advancement in the asteroseismic investigation of pulsating white dwarfs, which continues with the extended Kepler mission, K2. ",The search for ZZ Ceti stars in the original Kepler mission
29,685446500877492224,2503999452,Arnau Rios,"['New paper on #neutronstar pairing, a collaboration btn @WUSTLArtSci @ICC_UB @PhysicsatSurrey <LINK> <LINK>']",http://arxiv.org/abs/1601.01600,"Pairing gaps in neutron matter need to be computed in a wide range of densities to address open questions in neutron star phenomenology. Traditionally, the Bardeen-Cooper-Schrieffer approach has been used to compute gaps from bare nucleon-nucleon interactions. Here, we incorporate the influence of short- and long-range correlations in the pairing gaps. Short-range correlations are treated including the appropriate fragmentation of single-particle states, and substantially suppress the gaps. Long-range correlations dress the pairing interaction via density and spin modes, and provide a relatively small correction. We use different interactions, some with three-body forces, as a starting point to control for any systematic effects. Results are relevant for neutron-star cooling scenarios, in particular in view of the recent observational data on Cassiopeia A. ","Pairing in high-density neutron matter including short- and long-range
  correlations"
30,684761422623051777,11783582,Sarah Cobey,['Causal inference without models? Noisy nonequilibrium dynamics can really mess it up. Our new paper: <LINK>  @EdBaskerville'],http://arxiv.org/abs/1601.00716,"Infectious diseases are notorious for their complex dynamics, which make it difficult to fit models to test hypotheses. Methods based on state-space reconstruction have been proposed to infer causal interactions in noisy, nonlinear dynamical systems. These ""model-free"" methods are collectively known as convergent cross-mapping (CCM). Although CCM has theoretical support, natural systems routinely violate its assumptions. To identify the practical limits of causal inference under CCM, we simulated the dynamics of two pathogen strains with varying interaction strengths. The original method of CCM is extremely sensitive to periodic fluctuations, inferring interactions between independent strains that oscillate with similar frequencies. This sensitivity vanishes with alternative criteria for inferring causality. However, CCM remains sensitive to high levels of process noise and changes to the deterministic attractor. This sensitivity is problematic because it remains challenging to gauge noise and dynamical changes in natural systems, including the quality of reconstructed attractors that underlie cross-mapping. We illustrate these challenges by analyzing time series of reportable childhood infections in New York City and Chicago during the pre-vaccine era. We comment on the statistical and conceptual challenges that currently limit the use of state-space reconstruction in causal inference. ","Limits to causal inference with state-space reconstruction for
  infectious disease"
31,691275628683907073,46670048,David Siegel,['This new paper sums up why the 97% claim about global warming is so dangerous: <LINK> #climate'],https://arxiv.org/abs/1601.00900,"Is it possible for a large sequence of measurements or observations, which support a hypothesis, to counterintuitively decrease our confidence? Can unanimous support be too good to be true? The assumption of independence is often made in good faith, however rarely is consideration given to whether a systemic failure has occurred. Taking this into account can cause certainty in a hypothesis to decrease as the evidence for it becomes apparently stronger. We perform a probabilistic Bayesian analysis of this effect with examples based on (i) archaeological evidence, (ii) weighing of legal evidence, and (iii) cryptographic primality testing. We find that even with surprisingly low systemic failure rates high confidence is very difficult to achieve and in particular we find that certain analyses of cryptographically-important numerical tests are highly optimistic, underestimating their false-negative rate by as much as a factor of $2^{80}$. ",Too good to be true: when overwhelming evidence fails to convince
32,690958573384392704,46670048,David Siegel,['New paper on the surprising relationship between consensus and uncertainty: <LINK>'],https://arxiv.org/abs/1601.00900,"Is it possible for a large sequence of measurements or observations, which support a hypothesis, to counterintuitively decrease our confidence? Can unanimous support be too good to be true? The assumption of independence is often made in good faith, however rarely is consideration given to whether a systemic failure has occurred. Taking this into account can cause certainty in a hypothesis to decrease as the evidence for it becomes apparently stronger. We perform a probabilistic Bayesian analysis of this effect with examples based on (i) archaeological evidence, (ii) weighing of legal evidence, and (iii) cryptographic primality testing. We find that even with surprisingly low systemic failure rates high confidence is very difficult to achieve and in particular we find that certain analyses of cryptographically-important numerical tests are highly optimistic, underestimating their false-negative rate by as much as a factor of $2^{80}$. ",Too good to be true: when overwhelming evidence fails to convince
33,690154743759503360,46670048,David Siegel,['This new paper sums up why the 97% claim about global warming is so dangerous: <LINK>'],https://arxiv.org/abs/1601.00900,"Is it possible for a large sequence of measurements or observations, which support a hypothesis, to counterintuitively decrease our confidence? Can unanimous support be too good to be true? The assumption of independence is often made in good faith, however rarely is consideration given to whether a systemic failure has occurred. Taking this into account can cause certainty in a hypothesis to decrease as the evidence for it becomes apparently stronger. We perform a probabilistic Bayesian analysis of this effect with examples based on (i) archaeological evidence, (ii) weighing of legal evidence, and (iii) cryptographic primality testing. We find that even with surprisingly low systemic failure rates high confidence is very difficult to achieve and in particular we find that certain analyses of cryptographically-important numerical tests are highly optimistic, underestimating their false-negative rate by as much as a factor of $2^{80}$. ",Too good to be true: when overwhelming evidence fails to convince
