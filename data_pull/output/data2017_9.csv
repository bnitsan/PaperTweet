,TweetID,AuthorID,AuthorName,Tweets,arxiv_link,Abstract,Title
0,914657170792243201,140770306,Masafumi Oizumi,"['Our new paper ""Information Geometry Connecting Wasserstein Distance and Kullback-Leibler Divergence"" is available. <LINK>']",https://arxiv.org/abs/1709.10219,"Two geometrical structures have been extensively studied for a manifold of probability distributions. One is based on the Fisher information metric, which is invariant under reversible transformations of random variables, while the other is based on the Wasserstein distance of optimal transportation, which reflects the structure of the distance between random variables. Here, we propose a new information-geometrical theory that is a unified framework connecting the Wasserstein distance and Kullback-Leibler (KL) divergence. We primarily considered a discrete case consisting of $n$ elements and studied the geometry of the probability simplex $S_{n-1}$, which is the set of all probability distributions over $n$ elements. The Wasserstein distance was introduced in $S_{n-1}$ by the optimal transportation of commodities from distribution ${\mathbf{p}}$ to distribution ${\mathbf{q}}$, where ${\mathbf{p}}$, ${\mathbf{q}} \in S_{n-1}$. We relaxed the optimal transportation by using entropy, which was introduced by Cuturi. The optimal solution was called the entropy-relaxed stochastic transportation plan. The entropy-relaxed optimal cost $C({\mathbf{p}}, {\mathbf{q}})$ was computationally much less demanding than the original Wasserstein distance but does not define a distance because it is not minimized at ${\mathbf{p}}={\mathbf{q}}$. To define a proper divergence while retaining the computational advantage, we first introduced a divergence function in the manifold $S_{n-1} \times S_{n-1}$ of optimal transportation plans. We fully explored the information geometry of the manifold of the optimal transportation plans and subsequently constructed a new one-parameter family of divergences in $S_{n-1}$ that are related to both the Wasserstein distance and the KL-divergence. ","Information Geometry Connecting Wasserstein Distance and
  Kullback-Leibler Divergence via the Entropy-Relaxed Transportation Problem"
1,914359022496636928,731352704182669317,Fabian Jankowski,['I have a new paper in the arXiv! <LINK>'],https://arxiv.org/abs/1709.08864,"We present a study of the spectral properties of 441 pulsars observed with the Parkes radio telescope near the centre frequencies of 728, 1382 and 3100 MHz. The observations at 728 and 3100 MHz were conducted simultaneously using the dual-band 10-50cm receiver. These high-sensitivity, multi-frequency observations provide a systematic and uniform sample of pulsar flux densities. We combine our measurements with spectral data from the literature in order to derive the spectral properties of these pulsars. Using techniques from robust regression and information theory we classify the observed spectra in an objective, robust and unbiased way into five morphological classes: simple or broken power law, power law with either low or high-frequency cut-off and log-parabolic spectrum. While about $79 \%$ of the pulsars that could be classified have simple power law spectra, we find significant deviations in 73 pulsars, 35 of which have curved spectra, 25 with a spectral break and 10 with a low-frequency turn-over. We identify 11 gigahertz-peaked spectrum (GPS) pulsars, with 3 newly identified in this work and 8 confirmations of known GPS pulsars; 3 others show tentative evidence of GPS, but require further low-frequency measurements to support this classification. The weighted mean spectral index of all pulsars with simple power law spectra is $-1.60 \pm 0.03$. The observed spectral indices are well described by a shifted log-normal distribution. The strongest correlations of spectral index are with spin-down luminosity, magnetic field at the light-cylinder and spin-down rate. We also investigate the physical origin of the observed spectral features and determine emission altitudes for three pulsars. ",Spectral properties of 441 radio pulsars
2,914155676871651328,3301521293,Carlos Vega,"['I\'m glad to share our new paper: ""Diluting the Scalability Boundaries: Exploring the Use of Disaggregated Architectures for High-Level Network Data Analysis."" which I\'ll present during the HPCC 2017 conference in Bangkok, Thailand this December.\n<LINK>']",https://arxiv.org/abs/1709.06127,"Traditional data centers are designed with a rigid architecture of fit-for-purpose servers that provision resources beyond the average workload in order to deal with occasional peaks of data. Heterogeneous data centers are pushing towards more cost-efficient architectures with better resource provisioning. In this paper we study the feasibility of using disaggregated architectures for intensive data applications, in contrast to the monolithic approach of server-oriented architectures. Particularly, we have tested a proactive network analysis system in which the workload demands are highly variable. In the context of the dReDBox disaggregated architecture, the results show that the overhead caused by using remote memory resources is significant, between 66\% and 80\%, but we have also observed that the memory usage is one order of magnitude higher for the stress case with respect to average workloads. Therefore, dimensioning memory for the worst case in conventional systems will result in a notable waste of resources. Finally, we found that, for the selected use case, parallelism is limited by memory. Therefore, using a disaggregated architecture will allow for increased parallelism, which, at the same time, will mitigate the overhead caused by remote memory. ","Diluting the Scalability Boundaries: Exploring the Use of Disaggregated
  Architectures for High-Level Network Data Analysis"
3,913333810556792832,2427184074,Christopher Berry,"['New @LIGO/@ego_virgo paper (not #GW170814), search for non-tensorial gravitational waves from pulsars <LINK> #nondetection <LINK>', '@LIGO @ego_virgo Continuous gravitational waves from rotating neutron stars give a better insight into #GravitaitonalWave polarizations than short signals', '@LIGO @ego_virgo As the Earth rotates, the position of the source relative to the detector changes, giving us a way to look for different polarizations', '@LIGO @ego_virgo How a detector responds to a polarization depends upon where the source is (we call this the antenna pattern) https://t.co/UxAPaS8jik']",https://arxiv.org/abs/1709.09203,"We present results from the first directed search for nontensorial gravitational waves. While general relativity allows for tensorial (plus and cross) modes only, a generic metric theory may, in principle, predict waves with up to six different polarizations. This analysis is sensitive to continuous signals of scalar, vector or tensor polarizations, and does not rely on any specific theory of gravity. After searching data from the first observation run of the advanced LIGO detectors for signals at twice the rotational frequency of 200 known pulsars, we find no evidence of gravitational waves of any polarization. We report the first upper limits for scalar and vector strains, finding values comparable in magnitude to previously-published limits for tensor strain. Our results may be translated into constraints on specific alternative theories of gravity. ",First search for nontensorial gravitational waves from known pulsars
4,913283895466106880,523241142,Juste Raimbault,['New paper : Identification of Causalities in Spatio-temporal Data <LINK>'],https://arxiv.org/abs/1709.08684,"This paper contributes to the understanding of strongly coupled spatio-temporal processes by describing a generic method based on Granger causality. The method is validated by the robust identification of causality regimes and of their phase diagram for an urban morphogenesis model that couples network growth with density. The application to the real case study of Greater Paris transportation projects shows a link between territorial dynamics, more particularly of real estate and socio-economic, and the anticipated network growth. We finally discuss potential extensions to other temporal and spatial scales. ",Identification of Causalities in Spatio-temporal Data
5,912605706871869441,705339936514428928,Young-Ho Eom,['[My new paper on arVix!] Resilience of networks to environmental stress: from regular to random networks <LINK> <LINK>'],https://arxiv.org/abs/1709.08420,"Despite the huge interest in network resilience to stress, most of the studies have concentrated on internal stress damaging network structure (e.g., node removals). Here we study how networks respond to environmental stress deteriorating their external conditions. We show that, when regular networks gradually disintegrate as environmental stress increases, disordered networks can suddenly collapse at critical stress with hysteresis and vulnerability to perturbations. We demonstrate that this difference results from a trade-off between node resilience and network resilience to environmental stress. The nodes in the disordered networks can suppress their collapses due to the small-world topology of the networks but eventually collapse all together in return. Our findings indicate that some real networks can be highly resilient against environmental stress to a threshold yet extremely vulnerable to the stress above the threshold because of their small-world topology. ","Resilience of networks to environmental stress: From regular to random
  networks"
6,912544311782236161,51700215,Phil Bull,"['New paper: Galactic dust is complicated, and that spells trouble for future CMB experiments looking for B-modes <LINK>']",https://arxiv.org/abs/1709.07897,"Polarized Galactic foregrounds are one of the primary sources of systematic error in measurements of the B-mode polarization of the Cosmic Microwave Background (CMB). Experiments are becoming increasingly sensitive to complexities in the foreground frequency spectra that are not captured by standard parametric models, potentially affecting our ability to efficiently separate out these components. Employing a suite of dust models encompassing a variety of physical effects, we simulate observations of a future seven-band CMB experiment to assess the impact of these complexities on parametric component separation. We identify configurations of frequency bands that minimize the `model errors' caused by fitting simple parametric models to more complex `true' foreground spectra, which bias the inferred CMB signal. We find that: (a) fits employing a simple two parameter modified blackbody (MBB) dust model tend to produce significant bias in the recovered polarized CMB signal in the presence of physically realistic dust foregrounds; (b) generalized MBB models with three additional parameters reduce this bias in most cases, but non-negligible biases can remain, and can be hard to detect; and (c) line of sight effects, which give rise to frequency decorrelation, and the presence of iron grains are the most problematic complexities in the dust emission for recovering the true CMB signal. More sophisticated simulations will be needed to demonstrate that future CMB experiments can successfully mitigate these more physically realistic dust foregrounds. ","Mitigating Complex Dust Foregrounds in Future CMB Polarization
  Experiments"
7,912484053709856768,2337598033,Geraint F. Lewis,['New paper on the arxiv! <LINK> <LINK>'],https://arxiv.org/abs/1709.08010,"The planar arrangement of nearly half the satellite galaxies of M31 has been a source of mystery and speculation since it was discovered. With a growing number of other host galaxies showing these satellite galaxy planes, their stability and longevity have become central to the debate on whether the presence of satellite planes are a natural consequence of prevailing cosmological models, or represent a challenge. Given the dependence of their stability on host halo shape, we look into how a galaxy plane's dark matter environment influences its longevity. An increased number of dark matter subhalos results in increased interactions that hasten the deterioration of an already-formed plane of satellite galaxies in spherical dark halos. The role of total dark matter mass fraction held in subhalos in dispersing a plane of galaxies present non trivial effects on plane longevity as well. But any misalignments of plane inclines to major axes of flattened dark matter halos lead to their lifetimes being reduced to < 3 Gyrs. Distributing > 40% of total dark mass in subhalos in the overall dark matter distribution results in a plane of satellite galaxies that is prone to change through the 5 Gyr integration time period. ","Stability of Satellite Planes in M31 II: Effects of the Dark Subhalo
  Population"
8,912322803399036929,75249390,Axel Maas,"['We have published a new paper on what particles could be seen in experiments for different kind of theories: <LINK> #np3', 'The upshot is that traditional ways of enumerating may need some rethinking, which could change the landscape of plausible BSM scenarios']",https://arxiv.org/abs/1709.07477,"The physical, observable spectrum in gauge theories is made up from gauge-invariant states. The Fr\""ohlich-Morchio-Strocchi mechanism allows in the standard model to map these states to the gauge-dependent elementary $W$, $Z$ and Higgs states. This is no longer necessarily the case in theories with a more general gauge group and Higgs sector. We classify and predict the physical spectrum for a wide range of such theories, with special emphasis on GUT-like cases, and show that discrepancies between the spectrum of elementary fields and physical particles frequently arise. ",On the observable spectrum of theories with a Brout-Englert-Higgs effect
9,911276854383869952,2267596599,Prof. Gregory Rudnick,['Check out my other new paper on understanding gas accretion shut off in dense environments. <LINK> <LINK>'],http://arxiv.org/abs/1709.03691,"A major question in galaxy formation is how the gas supply that fuels activity in galaxies is modulated by their environment. We use spectroscopy of a set of well characterized clusters and groups at $0.4<z<0.8$ from the ESO Distant Cluster Survey (EDisCS) and compare it to identically selected field galaxies. Our spectroscopy allows us to isolate galaxies that are dominated by old stellar populations. Here we study a stellar-mass limited sample ($\log(M_*/M_\odot)>10.4$) of these old galaxies with weak [OII] emission. We use line ratios and compare to studies of local early type galaxies to conclude that this gas is likely excited by post-AGB stars and hence represents a diffuse gas component in the galaxies. For cluster and group galaxies the fraction with EW([OII])$>5$\AA\ is $f_{[OII]}=0.08^{+0.03}_{-0.02}$ and $f_{[OII]}=0.06^{+0.07}_{-0.04}$ respectively. For field galaxies we find $f_{[OII]}=0.27^{+0.07}_{-0.06}$, representing a 2.8$\sigma$ difference between the [OII] fractions for old galaxies between the different environments. We conclude that a population of old galaxies in all environments has ionized gas that likely stems from stellar mass loss. In the field galaxies also experience gas accretion from the cosmic web and in groups and clusters these galaxies have had their gas accretion shut off by their environment. Additionally, galaxies with emission preferentially avoid the virialized region of the cluster in position-velocity space. We discuss the implications of our results, among which is that gas accretion shutoff is likely effective at group halo masses (log~${\cal M}/$\msol$>12.8$) and that there are likely multiple gas removal processes happening in dense environments. ",Determining the Halo Mass Scale where Galaxies Lose Their Gas
10,911219389575450625,29405175,sylvain Gigan,"['new preprint from the team, 1st paper by Baptiste, in collaboration with IBENS and Laurent Bourdieu : <LINK>']",https://arxiv.org/abs/1709.07222,"We describe a fast closed-loop optimization wavefront shaping system able to focus light through dynamic scattering media. A MEMS-based spatial light modulator (SLM), a fast photodetector and FPGA electronics are combined to implement a closed-loop optimization of a wavefront with a single mode optimization rate of 4.1 kHz. The system performances are demonstrated by focusing light through colloidal solutions of TiO2 particles in glycerol with tunable temporal stability. ","Focusing light through dynamical samples using fast closed-loop
  wavefront optimization"
11,911119175585796096,54280236,Stuart Muldrew,['We have a new paper on galaxy evolution is protoclusters! Check it out here: <LINK> <LINK>'],https://arxiv.org/abs/1709.07009,"We investigate galaxy evolution in protoclusters using a semi-analytic model applied to the Millennium Simulation, scaled to a Planck cosmology. We show that the model reproduces the observed behaviour of the star formation history (SFH) both in protoclusters and the field. The rate of star formation peaks $\sim0.7\,{\rm Gyr}$ earlier in protoclusters than in the field and declines more rapidly afterwards. This results in protocluster galaxies forming significantly earlier: 80% of their stellar mass is already formed by $z=1.4$, but only 45% of the field stellar mass has formed by this time. The model predicts that field and protocluster galaxies have similar average specific star-formation rates (sSFR) at $z>3$, and we find evidence of an enhancement of star formation in the dense protoclusters at early times. At $z<3$, protoclusters have lower sSFRs, resulting in the disparity between the SFHs. We show that the stellar mass functions of protoclusters are top-heavy compared with the field due to the early formation of massive galaxies, and the disruption and merging of low-mass satellite galaxies in the main haloes. The fundamental cause of the different SFHs and mass functions is that dark matter haloes are biased tracers of the dark matter density field: the high density of haloes and the top-heavy halo mass function in protoclusters result in the early formation then rapid merging and quenching of galaxies. We compare our results with observations from the literature, and highlight which observables provide the most informative tests of galaxy formation. ",Galaxy evolution in protoclusters
12,911078677554782210,3145451345,m.onodera,['Our new paper about metals and ionization in strong oxygen line emitters just 2 billion years after the Big Bang.\n<LINK>'],https://arxiv.org/abs/1709.06731,"We present new results from near-infrared spectroscopy with Keck/MOSFIRE of [OIII]-selected galaxies at $z\sim3.2$. With our $H$ and $K$-band spectra, we investigate the interstellar medium (ISM) conditions, such as ionization states and gas metallicities. [OIII] emitters at $z\sim3.2$ show a typical gas metallicity of $\mathrm{12+log(O/H) = 8.07\pm0.07}$ at $\mathrm{log(M_*/M_\odot) \sim 9.0-9.2}$ and $\mathrm{12+log(O/H) = 8.31\pm0.04}$ at $\mathrm{log(M_*/M_\odot) \sim 9.7-10.2}$ when using the empirical calibration method. We compare the [OIII] emitters at $z\sim3.2$ with UV-selected galaxies and Ly$\alpha$ emitters at the same epoch and find that the [OIII]-based selection does not appear to show any systematic bias in the selection of star-forming galaxies. Moreover, comparing with star-forming galaxies at $z\sim2$ from literature, our samples show similar ionization parameters and gas metallicities as those obtained by the previous studies using the same calibration method. We find no strong redshift evolution in the ISM conditions between $z\sim3.2$ and $z\sim2$. Considering that the star formation rates at a fixed stellar mass also do not significantly change between the two epochs, our results support the idea that the stellar mass is the primary quantity to describe the evolutionary stages of individual galaxies at $z>2$. ","The interstellar medium in [OIII]-selected star-forming galaxies at
  $z\sim3.2$"
13,910834865712623616,882303076505456642,Timon Emken,['Light #DarkMatter can be accelerated in the Sun possibly increasing detection sensitivity. Our new paper:<LINK> @CP3Origins <LINK>'],https://arxiv.org/abs/1709.06573,Sub-GeV halo dark matter that enters the Sun can potentially scatter off hot solar nuclei and be ejected much faster than its incoming velocity. We derive an expression for the rate and velocity distribution of these reflected particles taking into account the Sun's temperature and opacity. We further demonstrate that future direct detection experiments could use these energetic reflected particles to probe light dark matter in parameter space that cannot be accessed via ordinary halo dark matter. ,The Sun as a sub-GeV Dark Matter Accelerator
14,910823712156524544,30775583,Dennis V. Perepelitsa 🇺🇦🇺🇲,"['Also new at #InitialStages2017: paper w/ global analysis of color fluctuation (""shrinking proton"") effect @ RHIC/LHC <LINK> <LINK>']",https://arxiv.org/abs/1709.04993,"We test the hypothesis that configurations of a proton with a large-$x$ parton, $x_p \gtrsim 0.1$, have a smaller than average size. The QCD $Q^2$ evolution equations suggest that these small configurations also have a significantly smaller interaction strength, which has observable consequences in collisions with nuclei. We perform a global analysis of jet production data in proton- and deuteron-nucleus collisions at RHIC and the LHC. Using a model which takes a distribution of interaction strengths into account, we quantitatively extract the $x_p$-dependence of the average interaction strength, $\sigma(x_p)$, over a wide kinematic range. By comparing the RHIC and LHC results, our analysis finds that the interaction strength for small configurations, while suppressed, grows faster with collision energy than does that for average configurations. We check that this energy dependence is consistent with the results of a method which, given $\sigma(x_p)$ at one energy, can be used to quantitatively predict that at another. This finding further suggests that at even lower energies, nucleons with a large-$x_p$ parton should interact much more weakly than those in an average configuration, a phenomenon in line with explanations of the EMC effect for large-$x_p$ quarks in nuclei based on color screening. ","Global analysis of color fluctuation effects in proton- and
  deuteron-nucleus collisions at RHIC and the LHC"
15,910672490250293248,706175245976248321,Oscar Viyuela,"['Our new paper on the arXiv: ""Localization and Oscillations in Majorana Fermions from d-Wave Superconductors"" :)\n<LINK>']",https://arxiv.org/abs/1709.06568,"We study the localization and oscillation properties of the Majorana fermions that arise in a two-dimensional electron gas (2DEG) with spin-orbit coupling (SOC) and a Zeeman field coupled with a d-wave superconductor. Despite the angular dependence of the d-wave pairing, localization and oscillation properties are found to be similar to the ones seen in conventional s-wave superconductors. In addition, we study a microscopic lattice version of the previous system that can be characterized by a topological invariant. We derive its real space representation that involves nearest and next-to-nearest-neighbors pairing. Finally, we show that the emerging chiral Majorana fermions are indeed robust against static disorder. This analysis has potential applications to quantum simulations and experiments in high-$T_c$ superconductors. ","Localization and oscillations of Majorana fermions in a two-dimensional
  electron gas coupled with $d$-wave superconductors"
16,910607870919458816,372689892,Marton Karsai,['Our new paper with @bolozna @JariSaramaki on representing temp nets as weighted DAGs is out! <LINK> and presented at #CCS17'],http://arxiv.org/abs/1709.05647,"Many processes of spreading and diffusion take place on temporal networks, and their outcomes are influenced by correlations in the times of contact. These correlations have a particularly strong influence on processes where the spreading agent has a limited lifetime at nodes: disease spreading (recovery time), diffusion of rumors (lifetime of information), and passenger routing (maximum acceptable time between transfers). Here, we introduce weighted event graphs as a powerful and fast framework for studying connectivity determined by time-respecting paths where the allowed waiting times between contacts have an upper limit. We study percolation on the weighted event graphs and in the underlying temporal networks, with simulated and real-world networks. We show that this type of temporal-network percolation is analogous to directed percolation, and that it can be characterized by multiple order parameters. ","Mapping temporal-network percolation to weighted, static event graphs"
17,910554878946054144,51700215,Phil Bull,['New paper: MeerKLASS survey will be a vital bridge between nascent radio + established optical cosmo communities  <LINK>'],https://arxiv.org/abs/1709.06099,"We discuss the ground-breaking science that will be possible with a wide area survey, using the MeerKAT telescope, known as MeerKLASS (MeerKAT Large Area Synoptic Survey). The current specifications of MeerKAT make it a great fit for science applications that require large survey speeds but not necessarily high angular resolutions. In particular, for cosmology, a large survey over $\sim 4,000 \, {\rm deg}^2$ for $\sim 4,000$ hours will potentially provide the first ever measurements of the baryon acoustic oscillations using the 21cm intensity mapping technique, with enough accuracy to impose constraints on the nature of dark energy. The combination with multi-wavelength data will give unique additional information, such as exquisite constraints on primordial non-Gaussianity using the multi-tracer technique, as well as a better handle on foregrounds and systematics. Such a wide survey with MeerKAT is also a great match for HI galaxy studies, providing unrivalled statistics in the pre-SKA era for galaxies resolved in the HI emission line beyond local structures at z > 0.01. It will also produce a large continuum galaxy sample down to a depth of about 5\,$\mu$Jy in L-band, which is quite unique over such large areas and will allow studies of the large-scale structure of the Universe out to high redshifts, complementing the galaxy HI survey to form a transformational multi-wavelength approach to study galaxy dynamics and evolution. Finally, the same survey will supply unique information for a range of other science applications, including a large statistical investigation of galaxy clusters as well as produce a rotation measure map across a huge swathe of the sky. The MeerKLASS survey will be a crucial step on the road to using SKA1-MID for cosmological applications and other commensal surveys, as described in the top priority SKA key science projects (abridged). ",MeerKLASS: MeerKAT Large Area Synoptic Survey
18,910551380128972801,167137258,Shoumik Palkar,['The Weld paper is now on Arxiv: <LINK>\nNew interfaces for data intensive applications can give order of magnitude speedups!'],https://arxiv.org/abs/1709.06416,"Data analytics applications combine multiple functions from different libraries and frameworks. Even when each function is optimized in isolation, the performance of the combined application can be an order of magnitude below hardware limits due to extensive data movement across these functions. To address this problem, we propose Weld, a new interface between data-intensive libraries that can optimize across disjoint libraries and functions. Weld exposes a lazily-evaluated API where diverse functions can submit their computations in a simple but general intermediate representation that captures their data-parallel structure. It then optimizes data movement across these functions and emits efficient code for diverse hardware. Weld can be integrated into existing frameworks such as Spark, TensorFlow, Pandas and NumPy without changing their user-facing APIs. We demonstrate that Weld can speed up applications using these frameworks by up to 29x. ",Weld: Rethinking the Interface Between Data-Intensive Applications
19,910548977745039360,3079023467,Dr. Emma Beasor,['Our new paper on the initial masses of the Red Supergiant progenitors to Type IIP SN <LINK>'],https://arxiv.org/abs/1709.06116,"There are a growing number of nearby SNe for which the progenitor star is detected in archival pre-explosion imaging. From these images it is possible to measure the progenitor's brightness a few years before explosion, and ultimately estimate its initial mass. Previous work has shown that II-P and II-L supernovae (SNe) have Red Supergiant (RSG) progenitors, and that the range of initial masses for these progenitors seems to be limited to $<$17M$_\odot$. This is in contrast with the cutoff of 25-30M$_\odot$ predicted by evolutionary models, a result which is termed the 'Red Supergiant Problem'. Here we investigate one particular source of systematic error present in converting pre-explosion photometry into an initial mass, that of the bolometric correction (BC) used to convert a single-band flux into a bolometric luminosity. We show, using star clusters, that RSGs evolve to later spectral types as they approach SN, which in turn causes the BC to become larger. Failure to account for this results in a systematic underestimate of a star's luminosity, and hence its initial mass. Using our empirically motivated BCs we reappraise the II-P and II-L SNe that have their progenitors detected in pre-explosion imaging. Fitting an initial mass function to these updated masses results in an increased upper mass cutoff of $M_{\rm hi}$=$19.0^{+2.5}_{-1.3}$M$_\odot$, with a 95% upper confidence limit of $<$27M$_\odot$. Accounting for finite sample size effects and systematic uncertainties in the mass-luminosity relationship raises the cutoff to $M_{\rm hi}$=25M$_\odot$ ($<$33M$_\odot$, 95% confidence). We therefore conclude that there is currently no strong evidence for `missing' high mass progenitors to core-collapse SNe. ","The Initial Masses of the Red Supergiant Progenitors to Type-II
  Supernovae"
20,910319860449648642,858881333052952576,Sungjoon,['Our recent paper about new sparse deep Q-learning is on <LINK> with full theoretical analysis! <LINK>'],https://arxiv.org/abs/1709.06293,"In this paper, a sparse Markov decision process (MDP) with novel causal sparse Tsallis entropy regularization is proposed.The proposed policy regularization induces a sparse and multi-modal optimal policy distribution of a sparse MDP. The full mathematical analysis of the proposed sparse MDP is provided.We first analyze the optimality condition of a sparse MDP. Then, we propose a sparse value iteration method which solves a sparse MDP and then prove the convergence and optimality of sparse value iteration using the Banach fixed point theorem. The proposed sparse MDP is compared to soft MDPs which utilize causal entropy regularization. We show that the performance error of a sparse MDP has a constant bound, while the error of a soft MDP increases logarithmically with respect to the number of actions, where this performance error is caused by the introduced regularization term. In experiments, we apply sparse MDPs to reinforcement learning problems. The proposed method outperforms existing methods in terms of the convergence speed and performance. ","Sparse Markov Decision Processes with Causal Sparse Tsallis Entropy
  Regularization for Reinforcement Learning"
21,910314713363365888,307826617,Kev Abazajian ⤷⏳🌎,['Where γ-ray blazar variability meets plasma astrophysics &amp; wakefield acceleration. New paper. <LINK>'],https://arxiv.org/abs/1709.06535,"Gamma-ray observations have revealed strong variability in blazar luminosities in the gamma-ray band over time scales as short as minutes. We show, for the first time, that the correlation of the spectrum with intensity is consistent with the behavior of the luminosity variation of blazar SEDs along a blazar sequence for low synchrotron peak blazars. We show that the observational signatures of variability with flux are consistent with wakefield acceleration of electrons initiated by instabilities in the blazar accretion disk. This mechanism reproduces the observed time variations as short as 100 seconds. The wakefield mechanism also predicts a reduction of the electron spectral index with increased gamma-ray luminosity, which could be detected in higher energy observations well above the inverse Compton peak. ","Observational Signatures of Gamma Rays from Bright Blazars and Wakefield
  Theory"
22,910187789634932736,12184622,Joshua Shaevitz,['Bacteria use active matter physics to aggregate when starved. Check out our new paper! <LINK> w/ @stpalli @cris_marchetti_'],http://arxiv.org/abs/1709.06012,"Combining high-resolution single cell tracking experiments with numerical simulations, we show that starvation-induced fruiting body (FB) formation in Myxococcus xanthus is a phase separation driven by cells that tune their motility over time. The phase separation can be understood in terms of cell density and a dimensionless Peclet number that captures cell motility through speed and reversal frequency. Our work suggests that M. xanthus take advantage of a self-driven non-equilibrium phase transition that can be controlled at the single cell level. ","A self-driven phase transition drives Myxococcus xanthus fruiting body
  formation"
23,910140684631511040,21820958,Michele Bannister,['For the morning folks: I talk about our new paper on this discovery in a distant Neptune resonance <LINK> <LINK>'],https://arxiv.org/abs/1709.05427,"We report the discovery of a $H_r = 3.4\pm0.1$ dwarf planet candidate by the Pan-STARRS Outer Solar System Survey. 2010 JO$_{179}$ is red with $(g-r)=0.88 \pm 0.21$, roughly round, and slowly rotating, with a period of $30.6$ hr. Estimates of its albedo imply a diameter of 600--900~km. Observations sampling the span between 2005--2016 provide an exceptionally well-determined orbit for 2010 JO$_{179}$, with a semi-major axis of $78.307\pm0.009$ au, distant orbits known to this precision are rare. We find that 2010 JO$_{179}$ librates securely within the 21:5 mean-motion resonance with Neptune on hundred-megayear time scales, joining the small but growing set of known distant dwarf planets on metastable resonant orbits. These imply a substantial trans-Neptunian population that shifts between stability in high-order resonances, the detached population, and the eroding population of the scattering disk. ",A dwarf planet class object in the 21:5 resonance with Neptune
24,910114375029215232,3317397493,Kelsey B. Hatzell,['New archived paper out - highlighting key mechanisms to electrochemical separation processes <LINK>'],https://arxiv.org/abs/1709.05925,"Over the past decade, capacitive deionization (CDI) has realized a surge in attention in the field of water desalination and can now be considered as an important technology class, along with reverse osmosis and electrodialysis. While many of the recently developed technologies no longer use a mechanism that follows the strict definition of the term ""capacitive"", these methods nevertheless share many common elements that encourage treating them with similar metrics and analyses. Specifically, they all involve electrically driven removal of ions from a feed stream, storage in an electrode (i.e., ion electrosorption) and release, in charge/discharge cycles. Grouping all these methods in the technology class of CDI makes it possible to treat evolving new technologies in standardized terms and compare them to other technologies in the same class. ",Capacitive Deionization -- defining a class of desalination technologies
25,909940244144955393,2377407248,Daniel Whiteson,['Fun new paper with @KyleCranmer <LINK>'],https://arxiv.org/abs/1709.05681,"We describe a procedure for constructing a model of a smooth data spectrum using Gaussian processes rather than the historical parametric description. This approach considers a fuller space of possible functions, is robust at increasing luminosity, and allows us to incorporate our understanding of the underlying physics. We demonstrate the application of this approach to modeling the background to searches for dijet resonances at the Large Hadron Collider and describe how the approach can be used in the search for generic localized signals. ","Modeling Smooth Backgrounds and Generic Localized Signals with Gaussian
  Processes"
26,909806724596473859,742149925,David Meyer,"['New paper w/Allen &amp; Bucicovschi, Entanglement Constraints on States Locally Connected to the GHZ State\n<LINK>']",https://arxiv.org/abs/1709.05004,"The multi-qubit GHZ state possesses tangles with elegant transformation properties under stochastic local operations and classical communication. Since almost all pure 3-qubit states are connected to the GHZ state via SLOCC, we derive a necessary and sufficient achievability inequality on arbitrary 3-qubit tangles, which is a strictly stronger constraint than both the monogamy inequality and the marginal eigenvalue inequality. We then show that entanglement shared with any single party in the n-qubit GHZ SLOCC equivalence class is precisely accounted for by the sum of its k-tangles, recently coined the strong monogamy equality, acknowledging competing but agreeing definitions of the k-tangle on this class, one of which is then computable for arbitrary mixed states. Strong monogamy is known to not hold arbitrarily, and so we introduce a unifying outlook on entanglement constraints in light of basic real algebraic geometry. ","Entanglement Constraints on States Locally Connected to the
  Greenberger-Horne-Zeilinger State"
27,909789293178171397,62604839,Paulo Simões,"['Our new paper, led by @EoinCarley, is out! We estimated the magnetic field of a CME using radio data <LINK>']",https://arxiv.org/abs/1709.05184,"Coronal mass ejections (CMEs) are large eruptions of plasma and magnetic field from the low solar corona into interplanetary space. These eruptions are often associated with the acceleration of energetic electrons which produce various sources of high intensity plasma emission. In relatively rare cases, the energetic electrons may also produce gyrosynchrotron emission from within the CME itself, allowing for a diagnostic of the CME magnetic field strength. Such a magnetic field diagnostic is important for evaluating the total magnetic energy content of the CME, which is ultimately what drives the eruption. Here we report on an unusually large source of gyrosynchrotron radiation in the form of a type IV radio burst associated with a CME occurring on 2014-September-01, observed using instrumentation from the Nan\c{c}ay Radio Astronomy Facility. A combination of spectral flux density measurements from the Nan\c{c}ay instruments and the Radio Solar Telescope Network (RSTN) from 300MHz to 5 GHz reveals a gyrosynchrotron spectrum with a peak flux density at $>$1 GHz. Using this radio analysis, a model for gyrosynchrotron radiation, a non-thermal electron density diagnostic using the Fermi Gamma Ray Burst Monitor (GBM) and images of the eruption from the GOES Soft X-ray Imager (SXI), we are able to calculate both the magnetic field strength and the properties of the X-ray and radio emitting energetic electrons within the CME. We find the radio emission is produced by non-thermal electrons of energies >1MeV with a spectral index of $\delta$$\sim$3 in a CME magnetic field of 4.4 G at a height of 1.3 R$_{\odot}$, while the X-ray emission is produced from a similar distribution of electrons but with much lower energies on the order of 10 keV. We conclude by comparing X-ray and radio-emitting electron distributions and how such an analysis can be used to define the plasma properties of a CME. ","Estimation of a Coronal Mass Ejection Magnetic Field Strength using
  Radio Observations of Gyrosynchrotron Radiation"
28,909775150144397312,15520108,Rudi Podgornik 岳儒迪,['Our new paper on the spontaneous symmetry breaking of charge-regulated surfaces. Another stab at the PB theory.\n\n <LINK>'],https://arxiv.org/abs/1709.05005,"The interaction between two chemically identical charge-regulated surfaces is studied using the classical density functional theory. In contrast to common expectations and assumptions, under certain realistic conditions we find a spontaneous emergence of disparate charge densities on the two surfaces. The surface charge densities can differ not only in their magnitude, but quite unexpectedly, even in their sign, implying that the electrostatic interaction between the two chemically identical surfaces can be attractive instead of repulsive. Moreover, an initial symmetry with equal charge densities on both surfaces can also be broken spontaneously upon decreasing the separation between the two surfaces. The origin of this phenomenon is a competition between the adsorption of ions from the solution to the surface and the interaction between the adsorbed ions already on the surface.These findings are fundamental for the understanding of the forces between colloidal objects and, in particular, they are bound to strongly influence the present picture of protein interaction. ",Spontaneous symmetry breaking of charge-regulated surfaces
29,909770747018485760,33113669,Tim Baldwin,['New paper on memory-enhanced CRFs: <LINK> w/ Felix Liu and Trevor Cohn #ijcnlp2017 #nlproc'],https://arxiv.org/abs/1709.03637,"Despite successful applications across a broad range of NLP tasks, conditional random fields (""CRFs""), in particular the linear-chain variant, are only able to model local features. While this has important benefits in terms of inference tractability, it limits the ability of the model to capture long-range dependencies between items. Attempts to extend CRFs to capture long-range dependencies have largely come at the cost of computational complexity and approximate inference. In this work, we propose an extension to CRFs by integrating external memory, taking inspiration from memory networks, thereby allowing CRFs to incorporate information far beyond neighbouring steps. Experiments across two tasks show substantial improvements over strong CRF and LSTM baselines. ","Capturing Long-range Contextual Dependencies with Memory-enhanced
  Conditional Random Fields"
30,908771014175313920,3405760034,Subhash Kak ☀️,['Let A &gt; B and C &gt; D then  A+C &gt; B+D.  Not always. WHY?  And has implications for reasoning. A new paper on this: <LINK>'],https://arxiv.org/abs/1709.04029,"Data based judgments go into artificial intelligence applications but they undergo paradoxical reversal when seemingly unnecessary additional data is provided. Examples of this are Simpson's reversal and the disjunction effect where the beliefs about the data change once it is presented or aggregated differently. Sometimes the significance of the difference can be evaluated using statistical tests such as Pearson's chi-squared or Fisher's exact test, but this may not be helpful in threshold-based decision systems that operate with incomplete information. To mitigate risks in the use of algorithms in decision-making, we consider the question of modeling of beliefs. We argue that evidence supports that beliefs are not classical statistical variables and they should, in the general case, be considered as superposition states of disjoint or polar outcomes. We analyze the disjunction effect from the perspective of the belief as a quantum vector. ",Probability Reversal and the Disjunction Effect in Reasoning Systems
31,908672672082644993,3816413361,Andrei Popescu-Belis,['New paper from our group on modulating attention to use wider context in neural MT <LINK> L.Miculicich @nik0spapp D.Ram'],https://arxiv.org/abs/1709.04849,"Neural sequence-to-sequence networks with attention have achieved remarkable performance for machine translation. One of the reasons for their effectiveness is their ability to capture relevant source-side contextual information at each time-step prediction through an attention mechanism. However, the target-side context is solely based on the sequence model which, in practice, is prone to a recency bias and lacks the ability to capture effectively non-sequential dependencies among words. To address this limitation, we propose a target-side-attentive residual recurrent network for decoding, where attention over previous words contributes directly to the prediction of the next word. The residual learning facilitates the flow of information from the distant past and is able to emphasize any of the previously translated words, hence it gains access to a wider context. The proposed model outperforms a neural MT baseline as well as a memory and self-attention network on three language pairs. The analysis of the attention learned by the decoder confirms that it emphasizes a wider context, and that it captures syntactic-like structures. ",Self-Attentive Residual Decoder for Neural Machine Translation
32,908541691120021504,289876736,Ali Pesaranghader,['My new paper on arXiv <LINK>\n#MachineLearning #DataStreamMining'],https://arxiv.org/abs/1709.02457,"The last decade has seen a surge of interest in adaptive learning algorithms for data stream classification, with applications ranging from predicting ozone level peaks, learning stock market indicators, to detecting computer security violations. In addition, a number of methods have been developed to detect concept drifts in these streams. Consider a scenario where we have a number of classifiers with diverse learning styles and different drift detectors. Intuitively, the current 'best' (classifier, detector) pair is application dependent and may change as a result of the stream evolution. Our research builds on this observation. We introduce the $\mbox{Tornado}$ framework that implements a reservoir of diverse classifiers, together with a variety of drift detection algorithms. In our framework, all (classifier, detector) pairs proceed, in parallel, to construct models against the evolving data streams. At any point in time, we select the pair which currently yields the best performance. We further incorporate two novel stacking-based drift detection methods, namely the $\mbox{FHDDMS}$ and $\mbox{FHDDMS}_{add}$ approaches. The experimental evaluation confirms that the current 'best' (classifier, detector) pair is not only heavily dependent on the characteristics of the stream, but also that this selection evolves as the stream flows. Further, our $\mbox{FHDDMS}$ variants detect concept drifts accurately in a timely fashion while outperforming the state-of-the-art. ","Reservoir of Diverse Adaptive Learners and Stacking Fast Hoeffding Drift
  Detection Methods for Evolving Data Streams"
33,908450907062497282,2862277847,Mark G. Bason,['Do physicists stop searches too early? The truth will astound you:\n<LINK> (our new paper) @aqsd_sussex'],https://arxiv.org/abs/1709.02230,"We introduce a novel remote interface to control and optimize the experimental production of Bose-Einstein condensates (BECs) and find improved solutions using two distinct implementations. First, a team of theoreticians employed a Remote version of their dCRAB optimization algorithm (RedCRAB), and second a gamified interface allowed 600 citizen scientists from around the world to participate in real-time optimization. Quantitative studies of player search behavior demonstrated that they collectively engage in a combination of local and global search. This form of adaptive search prevents premature convergence by the explorative behavior of low-performing players while high-performing players locally refine their solutions. In addition, many successful citizen science games have relied on a problem representation that directly engaged the visual or experiential intuition of the players. Here we demonstrate that citizen scientists can also be successful in an entirely abstract problem visualization. This gives encouragement that a much wider range of challenges could potentially be open to gamification in the future. ","Remote optimization of an ultra-cold atoms experiment by experts and
  citizen scientists"
34,908414106381647872,199688728,Sheldon Campbell,"['New paper today, analyzing the Galactic isotropic component of @NASAFermi-LAT gamma rays, w #darkmatter search. <LINK> 1/6', '@NASAFermi A dark matter signal from our Galactic halo is isotropic about Galactic center. But brightest gammas are from Galactic plane and points. 2/6 https://t.co/pJsHOQls6u', ""@NASAFermi We remove these brightest pixels until what's left is consistent with isotropic, and the galacto-isotropic background reveals itself. 3/6 https://t.co/IFHgkN5igh"", '@NASAFermi We check the data against a gamma-ray emission model previously used to analyze the Galactic center. The model deviated from the data… 4/6 https://t.co/gYMeNE8wDi', '@NASAFermi when over 20 deg from Galactic center, but the galacto-isotropic component is consistent with the model--deviations are from structure! 5/6 https://t.co/1vMrmakqY7', '@NASAFermi With proper understanding of galacto-isotropic profile uncertainty, dark matter constraints should be competitive with dwarf satellites. 6/6']",https://arxiv.org/abs/1709.04014,"We present an analysis of the radial angular profile of the galacto-isotropic (GI) $\gamma$-ray flux--the statistically uniform flux in circular annuli about the Galactic center. Two different approaches are used to measure the GI flux profile in 85 months of Fermi-LAT data: the BDS statistic method which identifies spatial correlations, and a new Poisson ordered-pixel method which identifies non-Poisson contributions. Both methods produce similar GI flux profiles. The GI flux profile is well-described by an existing model of bremsstrahlung, $\pi^0$ production, inverse Compton scattering, and the isotropic background. Discrepancies with data in our full-sky model are not present in the GI component, and are therefore due to mis-modeling of the non-GI emission. Dark matter annihilation constraints based solely on the observed GI profile are close to the thermal WIMP cross section below 100 GeV, for fixed models of the dark matter density profile and astrophysical $\gamma$-ray foregrounds. Refined measurements of the GI profile are expected to improve these constraints by a factor of a few. ","The Galactic Isotropic $\gamma$-ray Background and Implications for Dark
  Matter"
35,908348615914954752,20957355,Steven Tremblay,"['Like #pulsars explosions, or any highly energetic astronomical events? Read @AstroBradley new paper on Giant Pulses! <LINK>']",https://arxiv.org/abs/1709.03651,"We report on simultaneous wideband observations of Crab giant pulses with the Parkes radio telescope and the Murchison Widefield Array (MWA). The observations were conducted simultaneously at 732 and 3100 MHz with Parkes, and at 120.96, 165.76 and 210.56 MHz with the MWA. Flux density calibration of the MWA data was accomplished using a novel technique based on tied-array beam simulations. We detected between 90-648 giant pulses in the 120.96-210.56 MHz MWA subbands above a $ 5.5\sigma $ threshold while in the Parkes subbands we detected 6344 and 231 giant pulses above a threshold of $ 6\sigma $ at 732 and 3100 MHz, respectively. We show, for the first time over a wide frequency range, that the average spectrum of Crab giant pulses exhibits a significant flattening at low frequencies. The spectral index, $ \alpha $, for giant pulses evolves from a steep, narrow distribution with a mean $ \alpha=-2.6 $ and width $\sigma_\alpha=0.5 $ between 732 and 3100 MHz, to a wide, flat distribution of spectral indices with a mean $ \alpha=-0.7 $ and width $ \sigma_\alpha=1.4 $ between 120.96 and 165.76 MHz. We also comment on the plausibility of giant pulse models for Fast Radio Bursts based on this spectral information. ",Spectral Flattening at Low Frequencies in Crab Giant Pulses
36,908005369632276480,21611239,Sean Carroll,['New paper: thinking of de Sitter space (empty space with a positive cosmological constant) as a quantum circuit.\n<LINK>'],https://arxiv.org/abs/1709.03513,"We investigate the proposed connection between de Sitter spacetime and the MERA (Multiscale Entanglement Renormalization Ansatz) tensor network, and ask what can be learned via such a construction. We show that the quantum state obeys a cosmic no-hair theorem: the reduced density operator describing a causal patch of the MERA asymptotes to a fixed point of a quantum channel, just as spacetimes with a positive cosmological constant asymptote to de Sitter. The MERA is potentially compatible with a weak form of complementarity (local physics only describes single patches at a time, but the overall Hilbert space is infinite-dimensional) or, with certain specific modifications to the tensor structure, a strong form (the entire theory describes only a single patch plus its horizon, in a finite-dimensional Hilbert space). We also suggest that de Sitter evolution has an interpretation in terms of circuit complexity, as has been conjectured for anti-de Sitter space. ","De Sitter Space as a Tensor Network: Cosmic No-Hair, Complementarity,
  and Complexity"
37,907629768392232962,708465957690351616,Stuart Hadfield,"['New paper w/ #QuAIL @NASAAmes: ""From #Quantum Approximate Optimization Alg. to Q. Alternating Operator Ansatz"" <LINK> #qaoa', '@NASAAmes also at https://t.co/xOnvM9psGa\n#quantumComputing']",https://arxiv.org/abs/1709.03489,"The next few years will be exciting as prototype universal quantum processors emerge, enabling implementation of a wider variety of algorithms. Of particular interest are quantum heuristics, which require experimentation on quantum hardware for their evaluation, and which have the potential to significantly expand the breadth of quantum computing applications. A leading candidate is Farhi et al.'s Quantum Approximate Optimization Algorithm, which alternates between applying a cost-function-based Hamiltonian and a mixing Hamiltonian. Here, we extend this framework to allow alternation between more general families of operators. The essence of this extension, the Quantum Alternating Operator Ansatz, is the consideration of general parametrized families of unitaries rather than only those corresponding to the time-evolution under a fixed local Hamiltonian for a time specified by the parameter. This ansatz supports the representation of a larger, and potentially more useful, set of states than the original formulation, with potential long-term impact on a broad array of application areas. For cases that call for mixing only within a desired subspace, refocusing on unitaries rather than Hamiltonians enables more efficiently implementable mixers than was possible in the original framework. Such mixers are particularly useful for optimization problems with hard constraints that must always be satisfied, defining a feasible subspace, and soft constraints whose violation we wish to minimize. More efficient implementation enables earlier experimental exploration of an alternating operator approach to a wide variety of approximate optimization, exact optimization, and sampling problems. Here, we introduce the Quantum Alternating Operator Ansatz, lay out design criteria for mixing operators, detail mappings for eight problems, and provide brief descriptions of mappings for diverse problems. ","From the Quantum Approximate Optimization Algorithm to a Quantum
  Alternating Operator Ansatz"
38,907624023886110720,3276698761,Albert S. Berahas,"['New paper with Raghu, @StrongDuality &amp; Ermin: Balancing Communication and Computation in Distributed Optimization. <LINK>']",https://arxiv.org/abs/1709.02999,"Methods for distributed optimization have received significant attention in recent years owing to their wide applicability in various domains. A distributed optimization method typically consists of two key components: communication and computation. More specifically, at every iteration (or every several iterations) of a distributed algorithm, each node in the network requires some form of information exchange with its neighboring nodes (communication) and the computation step related to a (sub)-gradient (computation). The standard way of judging an algorithm via only the number of iterations overlooks the complexity associated with each iteration. Moreover, various applications deploying distributed methods may prefer a different composition of communication and computation. Motivated by this discrepancy, in this work we propose an adaptive cost framework which adjusts the cost measure depending on the features of various applications. We present a flexible algorithmic framework, where communication and computation steps are explicitly decomposed to enable algorithm customization for various applications. We apply this framework to the well-known distributed gradient descent (DGD) method, and show that the resulting customized algorithms, which we call DGD$^t$, NEAR-DGD$^t$ and NEAR-DGD$^+$, compare favorably to their base algorithms, both theoretically and empirically. The proposed NEAR-DGD$^+$ algorithm is an exact first-order method where the communication and computation steps are nested, and when the number of communication steps is adaptively increased, the method converges to the optimal solution. We test the performance and illustrate the flexibility of the methods, as well as practical variants, on quadratic functions and classification problems that arise in machine learning, in terms of iterations, gradient evaluations, communications and the proposed cost framework. ",Balancing Communication and Computation in Distributed Optimization
39,907324957654470656,14283504,Josh Bongard,"['Our new paper (w/ @MarkWagy, @bagrow &amp; @paulhinesuvm) on sourcing survey questions from the crowd:  <LINK> <LINK>']",https://arxiv.org/abs/1709.02739,"Crowdsourcing has been successfully applied in many domains including astronomy, cryptography and biology. In order to test its potential for useful application in a Smart Grid context, this paper investigates the extent to which a crowd can contribute predictive hypotheses to a model of residential electric energy consumption. In this experiment, the crowd generated hypotheses about factors that make one home different from another in terms of monthly energy usage. To implement this concept, we deployed a web-based system within which 627 residential electricity customers posed 632 questions that they thought predictive of energy usage. While this occurred, the same group provided 110,573 answers to these questions as they accumulated. Thus users both suggested the hypotheses that drive a predictive model and provided the data upon which the model is built. We used the resulting question and answer data to build a predictive model of monthly electric energy consumption, using random forest regression. Because of the sparse nature of the answer data, careful statistical work was needed to ensure that these models are valid. The results indicate that the crowd can generate useful hypotheses, despite the sparse nature of the dataset. ",Crowdsourcing Predictors of Residential Electric Energy Usage
40,907288752267042816,82008070,Dave Wecker,"['Our new paper ""Magic State Distillation at Intermediate Size"" is now available:<LINK> @Station_Q #QuArC']",https://arxiv.org/abs/1709.02789,"Recently we proposed a family of magic state distillation protocols that obtains asymptotic performance that is conjectured to be optimal. This family depends upon several codes, called ""inner codes"" and ""outer codes."" We presented some small examples of these codes as well as an analysis of codes in the asymptotic limit. Here, we analyze such protocols in an intermediate size regime, using hundreds to thousands of qubits. We use BCH inner codes, combined with various outer codes. We extend our protocols by adding error correction in some cases. We present a variety of protocols in various input error regimes; in many cases these protocols require significantly fewer input magic states to obtain a given output error than previous protocols. ",Magic State Distillation at Intermediate Size
41,905953790142013440,140770306,Masafumi Oizumi,"['Our new paper ""Geometry of Information Integration"" is available at <LINK>.']",https://arxiv.org/abs/1709.02050,"Information geometry is used to quantify the amount of information integration within multiple terminals of a causal dynamical system. Integrated information quantifies how much information is lost when a system is split into parts and information transmission between the parts is removed. Multiple measures have been proposed as a measure of integrated information. Here, we analyze four of the previously proposed measures and elucidate their relations from a viewpoint of information geometry. Two of them use dually flat manifolds and the other two use curved manifolds to define a split model. We show that there are hierarchical structures among the measures. We provide explicit expressions of these measures. ",Geometry of Information Integration
42,905478158174093312,3423739275,Felix Leditzky,"['New paper: approx. additivity of Holevo inf. -&gt; upper bounds on classical cap., with E. Kaur, N. Datta, @markwilde <LINK>', '@markwilde Ancillary files used to obtain numerical and some analytical results are available at https://t.co/wAcUbT1R2F']",https://arxiv.org/abs/1709.01111,"We study quantum channels that are close to another channel with weakly additive Holevo information and derive upper bounds on their classical capacity. Examples of channels with weakly additive Holevo information are entanglement-breaking channels, unital qubit channels, and Hadamard channels. Related to the method of approximate degradability, we define approximation parameters for each class above that measure how close an arbitrary channel is to satisfying the respective property. This gives us upper bounds on the classical capacity in terms of functions of the approximation parameters, as well as an outer bound on the dynamic capacity region of a quantum channel. Since these parameters are defined in terms of the diamond distance, the upper bounds can be computed efficiently using semidefinite programming (SDP). We exhibit the usefulness of our method with two example channels: a convex mixture of amplitude damping and depolarizing noise, and a composition of amplitude damping and dephasing noise. For both channels, our bounds perform well in certain regimes of the noise parameters in comparison to a recently derived SDP upper bound on the classical capacity. Along the way, we define the notion of a generalized channel divergence (which includes the diamond distance as an example), and we prove that for jointly covariant channels these quantities are maximized by purifications of a state invariant under the covariance group. This latter result may be of independent interest. ","Approaches for approximate additivity of the Holevo information of
  quantum channels"
43,905381605920919552,3084456430,Burkhard Morgenstern,['Our new paper on @arXiv:  <LINK>\nAlignment-free phylogeny reconstruction using k-mismatch common substrings'],https://arxiv.org/abs/1709.01371,"Various approaches to alignment-free sequence comparison are based on the length of exact or inexact word matches between two input sequences. Haubold {\em et al.} (2009) showed how the average number of substitutions between two DNA sequences can be estimated based on the average length of exact common substrings. In this paper, we study the length distribution of $k$-mismatch common substrings between two sequences. We show that the number of substitutions per position that have occurred since two sequences have evolved from their last common ancestor, can be estimated from the position of a local maximum in the length distribution of their $k$-mismatch common substrings. ","Estimating phylogenetic distances between genomic sequences based on the
  length distribution of k-mismatch common substrings"
44,905248975527174144,844960356,Ashmeet Singh,['New paper where @seanmcarroll and I bravely decimate quantum states in Hilbert space sans structure! <LINK>'],http://arxiv.org/abs/1709.01066,"We present a technique to coarse-grain quantum states in a finite-dimensional Hilbert space. Our method is distinguished from other approaches by not relying on structures such as a preferred factorization of Hilbert space or a preferred set of operators (local or otherwise) in an associated algebra. Rather, we use the data corresponding to a given set of states, either specified independently or constructed from a single state evolving in time. Our technique is based on principle component analysis (PCA), and the resulting coarse-grained quantum states live in a lower dimensional Hilbert space whose basis is defined using the underlying (isometric embedding) transformation of the set of fine-grained states we wish to coarse-grain. Physically, the transformation can be interpreted to be an ""entanglement coarse-graining"" scheme that retains most of the global, useful entanglement structure of each state, while needing fewer degrees of freedom for its reconstruction. This scheme could be useful for efficiently describing collections of states whose number is much smaller than the dimension of Hilbert space, or a single state evolving over time. ",Quantum Decimation in Hilbert Space: Coarse-Graining without Structure
45,904933011514429440,2203468841,Dr Jade Powell,['I have a new supernova paper on arXiv today 😁 <LINK>'],https://arxiv.org/abs/1709.00955,"A detection of a core-collapse supernova signal with an Advanced LIGO and Virgo gravitational-wave detector network will allow us to measure astrophysical parameters of the source. In real advanced gravitational-wave detector data there are transient noise artifacts that may mimic a true gravitational-wave signal. In this paper, we outline a procedure implemented in the Supernova Model Evidence Extractor (SMEE) that determines if a core-collapse supernova signal candidate is a noise artefact, a rapidly-rotating core-collapse supernova signal, or a neutrino explosion mechanism core-collapse supernova signal. Further to this, we use the latest available three-dimensional gravitational-wave core-collapse supernova simulations, and we outline a new procedure for the rejection of background noise transients when only one detector is operational. We find the minimum SNR needed to detect all waveforms is reduced when using three-dimensional waveforms as signal models. ","Inferring the core-collapse supernova explosion mechanism with
  three-dimensional gravitational-wave simulations"
46,904533535347933184,526115229,Kevin Heng,"['New WASP-12b retrieval paper by my student Maria Oreshenko:\n<LINK>', '@TroveMaster @ExoMol We definitely do! For the next set of models. Our outlook is long-term.']",https://arxiv.org/abs/1709.00338,"We analyze the emission spectrum of the hot Jupiter WASP-12b using our HELIOS-R retrieval code and HELIOS-K opacity calculator. When interpreting Hubble and Spitzer data, the retrieval outcomes are found to be prior-dominated. When the prior distributions of the molecular abundances are assumed to be log-uniform, the volume mixing ratio of HCN is found to be implausibly high. A VULCAN chemical kinetics model of WASP-12b suggests that chemical equilibrium is a reasonable assumption even when atmospheric mixing is implausibly rigorous. Guided by (exo)planet formation theory, we set Gaussian priors on the elemental abundances of carbon, oxygen and nitrogen with the Gaussian peaks being centered on the measured C/H, O/H and N/H values of the star. By enforcing chemical equilibrium, we find substellar O/H and stellar to slightly superstellar C/H for the dayside atmosphere of WASP-12b. The superstellar carbon-to-oxygen ratio is just above unity, regardless of whether clouds are included in the retrieval analysis, consistent with Madhusudhan et al. (2011). Furthermore, whether a temperature inversion exists in the atmosphere depends on one's assumption for the Gaussian width of the priors. Our retrieved posterior distributions are consistent with the formation of WASP-12b in a solar-composition protoplanetary disk, beyond the water iceline, via gravitational instability or pebble accretion (without core erosion) and migration inwards to its present orbital location via a disk-free mechanism, and are inconsistent with both in-situ formation and core accretion with disk migration, as predicted by Madhusudhan et al. (2017). We predict that the interpretation of James Webb Space Telescope WASP-12b data will not be prior-dominated. ","Retrieval Analysis of the Emission Spectrum of WASP-12b: Sensitivity of
  Outcomes to Prior Assumptions and Implications for Formation History"
47,904504261794344961,1576235694,Michael Brown,"['My new paper, ""Calibration of ultraviolet, mid-infrared and radio star formation rate indicators,"" is now on arxiv! <LINK>', 'Key results are 150 MHz &amp; mid-IR SFR indicator calibrations, including some significant revisions to mid-IR calibrations at 8 &amp; 12 microns. https://t.co/PJBzUHq6Gv']",https://arxiv.org/abs/1709.00183,"We present calibrations for star formation rate indicators in the ultraviolet, mid-infrared and radio continuum bands, including one of the first direct calibrations of 150 MHz as a star formation rate indicator. Our calibrations utilize 66 nearby star forming galaxies with Balmer decrement corrected H-alpha luminosities, which span 5 orders of magnitude in star formation rate and have absolute magnitudes of -24<M_r<-12. Most of our photometry and spectrophotometry is measured from the same region of each galaxy, and our spectrophotometry has been validated with SDSS photometry, so our random and systematic errors are small relative to the intrinsic scatter seen in star formation rate indicator calibrations. We find WISE W4 (22.8 micron), Spitzer 24 micron and 1.4 GHz have tight correlations with Balmer decrement corrected H-alpha luminosity, with scatter of only 0.2 dex. Our calibrations are comparable to those from the prior literature for L* galaxies, but for dwarf galaxies our calibrations can give star formation rates that are far greater than those derived from much of the prior literature. ","Calibration of ultraviolet, mid-infrared and radio star formation rate
  indicators"
48,910828077239894017,801449812486782976,Riashat Islam,"['Excited about our new paper ""Deep Reinforcement Learning that Matters"" with \n@rllabmcgill @MaluubaInc \n<LINK>']",https://arxiv.org/abs/1709.06560,"In recent years, significant progress has been made in solving challenging problems across various domains using deep reinforcement learning (RL). Reproducing existing work and accurately judging the improvements offered by novel methods is vital to sustaining this progress. Unfortunately, reproducing results for state-of-the-art deep RL methods is seldom straightforward. In particular, non-determinism in standard benchmark environments, combined with variance intrinsic to the methods, can make reported results tough to interpret. Without significance metrics and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the prior state-of-the-art are meaningful. In this paper, we investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures. We illustrate the variability in reported metrics and results when comparing against common baselines and suggest guidelines to make future results in deep RL more reproducible. We aim to spur discussion about how to ensure continued progress in the field by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted. ",Deep Reinforcement Learning that Matters
49,909826513956147200,1868950795,Ruth Misener,['New paper on approximation algorithms for designing heat recovery networks with Dimitris Letsios &amp; Georgia Kouyialis <LINK>'],https://arxiv.org/abs/1709.04688,"Heat exchanger network synthesis exploits excess heat by integrating process hot and cold streams and improves energy efficiency by reducing utility usage. Determining provably good solutions to the minimum number of matches is a bottleneck of designing a heat recovery network using the sequential method. This subproblem is an NP-hard mixed-integer linear program exhibiting combinatorial explosion in the possible hot and cold stream configurations. We explore this challenging optimization problem from a graph theoretic perspective and correlate it with other special optimization problems such as cost flow network and packing problems. In the case of a single temperature interval, we develop a new optimization formulation without problematic big-M parameters. We develop heuristic methods with performance guarantees using three approaches: (i) relaxation rounding, (ii) water filling, and (iii) greedy packing. Numerical results from a collection of 51 instances substantiate the strength of the methods. ","Heuristics with Performance Guarantees for the Minimum Number of Matches
  Problem in Heat Recovery Network Design"
50,905076598419988483,3225405682,Jack Bowden,['New paper on IV theory with important implications for two-sample summary data Mendelian randomization   <LINK>'],https://arxiv.org/abs/1709.00081,"Instrumental variable analysis is a widely used method to estimate causal effects in the presence of unmeasured confounding. When the instruments, exposure and outcome are not measured in the same sample, Angrist and Krueger (1992) suggested to use two-sample instrumental variable (TSIV) estimators that use sample moments from an instrument-exposure sample and an instrument-outcome sample. However, this method is biased if the two samples are from heterogeneous populations so that the distributions of the instruments are different. In linear structural equation models, we derive a new class of TSIV estimators that are robust to heterogeneous samples under the key assumption that the structural relations in the two samples are the same. The widely used two-sample two-stage least squares estimator belongs to this class. It is generally not asymptotically efficient, although we find that it performs similarly to the optimal TSIV estimator in most practical situations. We then attempt to relax the linearity assumption. We find that, unlike one-sample analyses, the TSIV estimator is not robust to misspecified exposure model. Additionally, to nonparametrically identify the magnitude of the causal effect, the noise in the exposure must have the same distributions in the two samples. However, this assumption is in general untestable because the exposure is not observed in one sample. Nonetheless, we may still identify the sign of the causal effect in the absence of homogeneity of the noise. ",Two-sample instrumental variable analyses using heterogeneous samples
51,914797486685990912,778200301,vinko zlatić ☮,['Here we find scaling relations for CAP and first hints of negative fractal dimension in  complex networks <LINK>'],https://arxiv.org/abs/1709.10366,"We study secure message-passing in the presence of multiple adversaries in modular networks. We assume a dominant fraction of nodes in each module have the same vulnerability, i.e., the same entity spying on them. We find both analytically and via simulations that the links between the modules (interlinks) have effects analogous to a magnetic field in a spin system in that for any amount of interlinks the system no longer undergoes a phase transition. We then define the exponents $\delta$, which relates the order parameter (the size of the giant secure component) at the critical point to the field strength (average number of interlinks per node), and $\gamma$, which describes the susceptibility near criticality. These are found to be $\delta=2$ and $\gamma=1$ (with the scaling of the order parameter near the critical point given by $\beta=1$). When two or more vulnerabilities are equally present in a module we find $\delta=1$ and $\gamma=0$ (with $\beta\geq2$). Apart from defining a previously unidentified universality class, these exponents show that increasing connections between modules is more beneficial for security than increasing connections within modules. We also measure the correlation critical exponent $\nu$, and the upper critical dimension $d_c$, finding that $\nu d_c=3$ as for ordinary percolation, suggesting that for secure message-passing $d_c =6$. These results provide an interesting analogy between secure message-passing in modular networks and the physics of magnetic spin-systems. ",Critical field-exponents for secure message-passing in modular networks
52,908494098012635138,29251447,Tuan Do,['Is S0-2 a binary star? We use 16 years of spectra from @keckobservatory to find out! <LINK> <LINK>'],https://arxiv.org/abs/1709.04890,"The star S0-2, which orbits the supermassive black hole (SMBH) in our Galaxy with a period of 16 years, provides the strongest constraint on both the mass of the SMBH and the distance to the Galactic center. S0-2 will soon provide the first measurement of relativistic effects near a SMBH. We report the first limits on the binarity of S0-2 from radial velocity monitoring, which has implications for both understanding its origin and robustness as a probe of the central gravitational field. With 87 radial velocity measurements, which include 12 new observations presented, we have the data set to look for radial velocity variations from S0-2's orbital model. Using a Lomb-Scargle analysis and orbit fitting for potential binaries, we detect no radial velocity variation beyond S0-2's orbital motion and do not find any significant periodic signal. The lack of a binary companion does not currently distinguish between different formation scenarios for S0-2. The upper limit on the mass of a companion star ($M_{\text{comp}}$) still allowed by our results has a median upper limit of $M_{\text{comp}}$ $\sin i \leq$ 1.6 M$_{\odot}$ for periods between 1 and 150 days, the longest period to avoid tidal break up of the binary. We also investigate the impact of the remaining allowed binary system on the measurement of the relativistic redshift at S0-2's closest approach in 2018. While binary star systems are important to consider for this experiment, we find plausible binaries for S0-2 will not alter a 5$\sigma$ detection of the relativistic redshift. ","Investigating the Binarity of S0-2: Implications for its Origins and
  Robustness as a Probe of the Laws of Gravity around a Supermassive Black Hole"
