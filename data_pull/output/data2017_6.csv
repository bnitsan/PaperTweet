,TweetID,AuthorID,AuthorName,Tweets,arxiv_link,Abstract,Title
0,882624443490619392,91634245,Brad Marston,['Our new paper on large deviation theory applied to an idealized model of a jet stream is out:  <LINK>'],https://arxiv.org/abs/1706.08810,"The Reynolds stress, or equivalently the average of the momentum flux, is key to understanding the statistical properties of turbulent flows. Both typical and rare fluctuations of the time averaged momentum flux are needed to fully characterize the slow flow evolution. The fluctuations are described by a large deviation rate function that may be calculated either from numerical simulation, or from theory. We show that, for parameter regimes in which a quasilinear approximation is accurate, the rate function can be found by solving a matrix Riccati equation. Using this tool we compute for the first time the large deviation rate function for the Reynolds stress of a turbulent flow. We study a barotropic flow on a rotating sphere, and show that the fluctuations are highly non-Gaussian. This work opens up new perspectives for the study of rare transitions between attractors in turbulent flows. ","Fluctuations and large deviations of Reynolds stresses in zonal jet
  dynamics"
1,882608633829314560,18870457,Timos Moraitis,['New paper! #unsupervised #learning from timed data with spiking #NeuralNetworks &amp; memristors <LINK> <LINK> <LINK>'],https://arxiv.org/abs/1706.05563,"Spiking neural networks (SNNs) could play a key role in unsupervised machine learning applications, by virtue of strengths related to learning from the fine temporal structure of event-based signals. However, some spike-timing-related strengths of SNNs are hindered by the sensitivity of spike-timing-dependent plasticity (STDP) rules to input spike rates, as fine temporal correlations may be obstructed by coarser correlations between firing rates. In this article, we propose a spike-timing-dependent learning rule that allows a neuron to learn from the temporally-coded information despite the presence of rate codes. Our long-term plasticity rule makes use of short-term synaptic fatigue dynamics. We show analytically that, in contrast to conventional STDP rules, our fatiguing STDP (FSTDP) helps learn the temporal code, and we derive the necessary conditions to optimize the learning process. We showcase the effectiveness of FSTDP in learning spike-timing correlations among processes of different rates in synthetic data. Finally, we use FSTDP to detect correlations in real-world weather data from the United States in an experimental realization of the algorithm that uses a neuromorphic hardware platform comprising phase-change memristive devices. Taken together, our analyses and demonstrations suggest that FSTDP paves the way for the exploitation of the spike-based strengths of SNNs in real-world applications. ","Fatiguing STDP: Learning from Spike-Timing Codes in the Presence of Rate
  Codes"
2,881680975775678465,16714100,Cayman Unterborn,"['New paper is up in which we play an exoplanetary scale game of ""Will it Float?"" Turns out, many things do. <LINK>']",https://arxiv.org/abs/1706.10282,"Earth's tectonic processes regulate the formation of continental crust, control its unique deep water and carbon cycles, and are vital to its surface habitability. A major driver of steady-state plate tectonics on Earth is the sinking of the cold subducting plate into the underlying mantle. This sinking is the result of the combined effects of the thermal contraction of the lithosphere and of metamorphic transitions within the basaltic oceanic crust and lithospheric mantle. The latter of these effects is dependent on the bulk composition of the planet, e.g., the major, terrestrial planet-building elements Mg, Si, Fe, Ca, Al, and Na, which vary in abundance across the Galaxy. We present thermodynamic phase-equilibria calculations of planetary differentiation to calculate both melt composition and mantle mineralogy, and show that a planet's refractory and moderately-volatile elemental abundances control a terrestrial planet's likelihood to produce mantle-derived, melt-extracted crusts that sink. Those planets forming with a higher concentration of Si and Na abundances are less likely to undergo sustained tectonics compared to the Earth. We find only 1/3 of the range of stellar compositions observed in the Galaxy is likely to host planets able to sustain density-driven tectonics compared to the Sun/Earth. Systems outside of this compositional range are less likely to produce planets able to tectonically regulate their climate and may be inhospitable to life as we know it. ",Stellar Chemical Clues As To The Rarity of Exoplanetary Tectonics
3,881133231973826560,809072402282016768,Daniel Jiwoong Im,['Our new paper : Neural Machine Translation with Gumbel-Greedy Decoding - improving argmax over the seq. x P(x|model) <LINK>'],https://arxiv.org/abs/1706.07518,"Previous neural machine translation models used some heuristic search algorithms (e.g., beam search) in order to avoid solving the maximum a posteriori problem over translation sentences at test time. In this paper, we propose the Gumbel-Greedy Decoding which trains a generative network to predict translation under a trained model. We solve such a problem using the Gumbel-Softmax reparameterization, which makes our generative network differentiable and trainable through standard stochastic gradient methods. We empirically demonstrate that our proposed model is effective for generating sequences of discrete words. ",Neural Machine Translation with Gumbel-Greedy Decoding
4,880740001235042304,62604839,Paulo Sim√µes,['Our new paper has been accepted! Formation of the thermal infrared continuum in solar flares <LINK> #solarflares'],https://arxiv.org/abs/1706.09867,"Observations of the Sun with the Atacama Large Millimeter Array have now started, and the thermal infrared will regularly be accessible from the NSF's Daniel K. Inouye Solar Telescope. Motivated by the prospect of these new data, and by recent flare observations in the mid infrared, we set out here to model and understand the source of the infrared continuum in flares, and to explore its diagnostic capability for the physical conditions in the flare atmosphere. We use the 1D radiation hydrodynamics code RADYN to calculate mid-infrared continuum emission from model atmospheres undergoing sudden deposition of energy by non-thermal electrons. We identify and characterise the main continuum thermal emission processes relevant to flare intensity enhancement in the mid- to far-infrared (2-200 $\mu$m) spectral range as free-free emission on neutrals and ions. We find that the infrared intensity evolution tracks the energy input to within a second, albeit with a lingering intensity enhancement, and provides a very direct indication of the evolution of the atmospheric ionization. The prediction of highly impulsive emission means that, on these timescales, the atmospheric hydrodynamics need not be considered in analysing the mid-IR signatures. ",Formation of the thermal infrared continuum in solar flares
5,880583040715546624,4750366201,Bryan Ostdiek,['<LINK> New paper on weakly supervised neural networks #MachineLearning #HighEnergyPhysics'],https://arxiv.org/abs/1706.09451,"Determining the best method for training a machine learning algorithm is critical to maximizing its ability to classify data. In this paper, we compare the standard ""fully supervised"" approach (that relies on knowledge of event-by-event truth-level labels) with a recent proposal that instead utilizes class ratios as the only discriminating information provided during training. This so-called ""weakly supervised"" technique has access to less information than the fully supervised method and yet is still able to yield impressive discriminating power. In addition, weak supervision seems particularly well suited to particle physics since quantum mechanics is incompatible with the notion of mapping an individual event onto any single Feynman diagram. We examine the technique in detail -- both analytically and numerically -- with a focus on the robustness to issues of mischaracterizing the training samples. Weakly supervised networks turn out to be remarkably insensitive to systematic mismodeling. Furthermore, we demonstrate that the event level outputs for weakly versus fully supervised networks are probing different kinematics, even though the numerical quality metrics are essentially identical. This implies that it should be possible to improve the overall classification ability by combining the output from the two types of networks. For concreteness, we apply this technology to a signature of beyond the Standard Model physics to demonstrate that all these impressive features continue to hold in a scenario of relevance to the LHC. ",(Machine) Learning to Do More with Less
6,880372720839659520,563821235,Verena Rieser,['check out our new paper on the #E2Enlg challenge (accepted for SigDial) <LINK>'],https://arxiv.org/abs/1706.09254,"This paper describes the E2E data, a new dataset for training end-to-end, data-driven natural language generation systems in the restaurant domain, which is ten times bigger than existing, frequently used datasets in this area. The E2E dataset poses new challenges: (1) its human reference texts show more lexical richness and syntactic variation, including discourse phenomena; (2) generating from this set requires content selection. As such, learning from this dataset promises more natural, varied and less template-like system utterances. We also establish a baseline on this dataset, which illustrates some of the difficulties associated with this data. ",The E2E Dataset: New Challenges For End-to-End Generation
7,880336783820677120,523241142,Juste Raimbault,['New paper with @a_bergeaud : The Cost of Transportation : Spatial Analysis of US Fuel Prices <LINK>'],http://arxiv.org/abs/1706.07467,"In this paper, we use a newly constructed dataset to study the geographic distribution of fuel price across the US at a very high resolution. We study the influence of socio-economic variables through different and complementary statistical methods. We highlight an optimal spatial range roughly corresponding to stationarity scale, and significant influence of variables such as median income, wage with a non-simple spatial behavior that confirms the importance of geographical particularities. On the other hand, multi-level modeling reveals a strong influence of the state in the level of price but also of some local characteristics including population density. Through the combination of such methods, we unveil the superposition of a governance process with a local socio-economical spatial process. The influence of population density on prices is furthermore consistent with a minimal theoretical model of competition between gas stations, that we introduce and solve numerically. We discuss developments and applications, including the elaboration of locally parametrized car-regulation policies. ","An empirical analysis of the spatial variability of fuel prices in the
  United States"
8,880336298988457984,523241142,Juste Raimbault,['New paper: An Applied Knowledge Framework to Study Complex Systems <LINK>'],http://arxiv.org/abs/1706.09244,"The complexity of knowledge production on complex systems is well-known, but there still lacks knowledge framework that would both account for a certain structure of knowledge production at an epistemological level and be directly applicable to the study and management of complex systems. We set a basis for such a framework, by first analyzing in detail a case study of the construction of a geographical theory of complex territorial systems, through mixed methods, namely qualitative interview analysis and quantitative citation network analysis. We can therethrough inductively build a framework that considers knowledge entreprises as perspectives, with co-evolving components within complementary knowledge domains. We finally discuss potential applications and developments. ",An Applied Knowledge Framework to Study Complex Systems
9,879972349625454592,87807273,David Barrett,"['Our new ICML paper on using cognitive psychology to interpret deep networks: <LINK> with S Ritter, @santoroai &amp; M Botvinik']",http://arxiv.org/abs/1706.08606,"Deep neural networks (DNNs) have achieved unprecedented performance on a wide range of complex tasks, rapidly outpacing our understanding of the nature of their solutions. This has caused a recent surge of interest in methods for rendering modern neural systems more interpretable. In this work, we propose to address the interpretability problem in modern DNNs using the rich history of problem descriptions, theories and experimental methods developed by cognitive psychologists to study the human mind. To explore the potential value of these tools, we chose a well-established analysis from developmental psychology that explains how children learn word labels for objects, and applied that analysis to DNNs. Using datasets of stimuli inspired by the original cognitive psychology experiments, we find that state-of-the-art one shot learning models trained on ImageNet exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color. The magnitude of this shape bias varies greatly among architecturally identical, but differently seeded models, and even fluctuates within seeds throughout training, despite nearly equivalent classification performance. These results demonstrate the capability of tools from cognitive psychology for exposing hidden computational properties of DNNs, while concurrently providing us with a computational model for human word learning. ",Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study
10,879950670681563136,733640801914343425,Adam Santoro,"['Our new paper uses methods from Cog. Psychology to probe the biases of neural networks. With @dgtbarrett and others: <LINK>', '@dgtbarrett The same net, same hyperparameters, trained on imagenet with a different random seed will develop a different qualitative bias.']",https://arxiv.org/abs/1706.08606,"Deep neural networks (DNNs) have achieved unprecedented performance on a wide range of complex tasks, rapidly outpacing our understanding of the nature of their solutions. This has caused a recent surge of interest in methods for rendering modern neural systems more interpretable. In this work, we propose to address the interpretability problem in modern DNNs using the rich history of problem descriptions, theories and experimental methods developed by cognitive psychologists to study the human mind. To explore the potential value of these tools, we chose a well-established analysis from developmental psychology that explains how children learn word labels for objects, and applied that analysis to DNNs. Using datasets of stimuli inspired by the original cognitive psychology experiments, we find that state-of-the-art one shot learning models trained on ImageNet exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color. The magnitude of this shape bias varies greatly among architecturally identical, but differently seeded models, and even fluctuates within seeds throughout training, despite nearly equivalent classification performance. These results demonstrate the capability of tools from cognitive psychology for exposing hidden computational properties of DNNs, while concurrently providing us with a computational model for human word learning. ",Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study
11,879862007796822017,4815574011,Dmitry Yu. Fedyanin,"['When u need to submit a new paper and cite the previous one,which is still under review after 6 months,ArXiv helps. <LINK>']",https://arxiv.org/abs/1706.08898,"Low-power, high-speed and bright electrically driven true single-photon sources, which are able to operate at room temperature, are vital for the practical realization of quantum communication networks and optical quantum computations. Color centers in semiconductors are currently the best candidates, however, in spite of their intensive study in the past decade, the behavior of color centers in electrically controlled systems is poorly understood. Here we present a physical model and establish a theoretical approach to address single-photon emission dynamics of electrically pumped color centers, which interprets experimental results. We support our analysis with self-consistent numerical simulations of a single-photon emitting diode based on a single nitrogen-vacancy center in diamond and predict the second-order autocorrelation function and other emission characteristics. Our theoretical findings demonstrate remarkable agreement with the experimental results and pave the way to the understanding of single-electron/single-photon processes in semiconductors. ","Dynamics of single-photon emission from electrically pumped color
  centers"
12,879857298402717696,101980926,Masahito Yamazaki,"['My new paper ""Pure Natural Inflation"" is now public!\n<LINK>']",https://arxiv.org/abs/1706.08522,We point out that a simple inflationary model in which the axionic inflaton couples to a pure Yang-Mills theory may give the scalar spectral index (n_s) and tensor-to-scalar ratio (r) in complete agreement with the current observational data. ,Pure Natural Inflation
13,879626775789281282,822867138,Bradley Kavanagh,"['Will upcoming direct detection experiments be able to tell Dirac from Majorana #DarkMatter? My new paper out today: <LINK>', 'Answer: yes, up to about 3œÉ significance, depending on the Dark Matter couplings, Œª https://t.co/igF4RTyrz3', 'But we can do even better (4-5œÉ) if we have targets with diverse neutron-to-proton ratios (e.g. using Xenon + Argon + Silicon): https://t.co/g6KFDidqzf']",https://arxiv.org/abs/1706.07819,"It was recently pointed out that direct detection signals from at least three different targets may be used to determine whether the Dark Matter (DM) particle is different from its antiparticle. In this work, we examine in detail the feasibility of this test under different conditions, motivated by proposals for future detectors. Specifically, we perform likelihood fits to mock data under the hypotheses that the DM particle is identical to or different from its antiparticle, and determine the significance with which the former can be rejected in favor of the latter. In our analysis, we consider 3 different values of the DM mass ($50$ GeV, $300$ GeV, $1$ TeV) and 4 different experimental ensembles, each consisting of at least 3 different targets -- Xe and Ar plus one among the following: Si, Ge, $\mathrm{CaWO_4}$, or Ge/$\mathrm{CaWO_4}$. For each of these experimental ensembles and each DM mass, the expected discrimination significance is calculated as a function of the DM-nucleon couplings. In the best case scenario, the discrimination significance can reach $\mathcal{O}(3\sigma)$ for three of the four ensembles considered, and $\mathcal{O}(5\sigma)$ for the ensemble including $\mathrm{Si}$, highlighting the need for a variety of experimental targets in order to determine the DM properties. These results show that future direct detection signals could be used to exclude, at a statistically significant level, a Majorana or a real DM particle, giving a critical clue about the identity of the Dark Matter. ","Prospects for determining the particle/antiparticle nature of WIMP dark
  matter with direct detection experiments"
14,879403974092140544,355626264,Aram Galstyan,"['New paper w/ @gesteller ""Low Complexity Gaussian Latent Factor Models and a Blessing of Dimensionality"" <LINK>']",http://arxiv.org/abs/1706.03353,"Estimating graphical model structure from high-dimensional and undersampled data is a fundamental problem in many scientific fields. Existing approaches, such as GLASSO, latent variable GLASSO, and latent tree models, suffer from high computational complexity and may impose unrealistic sparsity priors in some cases. We introduce a novel method that leverages a newly discovered connection between information-theoretic measures and structured latent factor models to derive an optimization objective which encourages modular structures where each observed variable has a single latent parent. The proposed method has linear stepwise computational complexity w.r.t. the number of observed variables. Our experiments on synthetic data demonstrate that our approach is the only method that recovers modular structure better as the dimensionality increases. We also use our approach for estimating covariance structure for a number of real-world datasets and show that it consistently outperforms state-of-the-art estimators at a fraction of the computational cost. Finally, we apply the proposed method to high-resolution fMRI data (with more than 10^5 voxels) and show that it is capable of extracting meaningful patterns. ",Fast structure learning with modular regularization
15,879318419325190144,1545756036,Mike Boylan-Kolchin,"['New paper from V. Robles on cores in dwarf galaxies: sensitive to feedback in CDM, robust to feedback in SIDM. <LINK> <LINK>', ""Although, https://t.co/13I0AGcDYJ (also out today) argues cores may be observational artifacts. Can't imagine that will be controversial...."", '@caprastro I like it! Having a few more comparable systems would be reassuring. Hard for me to believe that cores are all erroneous measurements. You?', '@caprastro Good to know, thanks. Do they have reasonably precise age estimates (say, w/i 2 Gyr)? Formation time seems to be important for core argument']",https://arxiv.org/abs/1706.07514v1,"We compare a suite of four simulated dwarf galaxies formed in 10$^{10} M_{\odot}$ haloes of collisionless Cold Dark Matter (CDM) with galaxies simulated in the same haloes with an identical galaxy formation model but a non-zero cross-section for dark matter self-interactions. These cosmological zoom-in simulations are part of the Feedback In Realistic Environments (FIRE) project and utilize the FIRE-2 model for hydrodynamics and galaxy formation physics. We find the stellar masses of the galaxies formed in Self-Interacting Dark Matter (SIDM) with $\sigma/m= 1\, cm^2/g$ are very similar to those in CDM (spanning $M_{\star} \approx 10^{5.7 - 7.0} M_{\odot}$) and all runs lie on a similar stellar mass -- size relation. The logarithmic dark matter density slope ($\alpha=d\log \rho / d\log r$) in the central $250-500$ pc remains steeper than $\alpha= -0.8$ for the CDM-Hydro simulations with stellar mass $M_{\star} \sim 10^{6.6} M_{\odot}$ and core-like in the most massive galaxy. In contrast, every SIDM hydrodynamic simulation yields a flatter profile, with $\alpha >-0.4$. Moreover, the central density profiles predicted in SIDM runs without baryons are similar to the SIDM runs that include FIRE-2 baryonic physics. Thus, SIDM appears to be much more robust to the inclusion of (potentially uncertain) baryonic physics than CDM on this mass scale, suggesting SIDM will be easier to falsify than CDM using low-mass galaxies. Our FIRE simulations predict that galaxies less massive than $M_{\star} < 3 \times 10^6 M_{\odot}$ provide potentially ideal targets for discriminating models, with SIDM producing substantial cores in such tiny galaxies and CDM producing cusps. ","] SIDM on FIRE: Hydrodynamical Self-Interacting Dark Matter simulations of
  low-mass dwarf galaxies"
16,879237553328730112,1281526188,Tobias Kuhn,['What is the nature of controversies and how can we analyze them? We have answers in our new paper: <LINK> @laroyo @8w'],https://arxiv.org/abs/1706.07643,"Climate change, vaccination, abortion, Trump: Many topics are surrounded by fierce controversies. The nature of such heated debates and their elements have been studied extensively in the social science literature. More recently, various computational approaches to controversy analysis have appeared, using new data sources such as Wikipedia, which help us now better understand these phenomena. However, compared to what social sciences have discovered about such debates, the existing computational approaches mostly focus on just a few of the many important aspects around the concept of controversies. In order to link the two strands, we provide and evaluate here a controversy model that is both, rooted in the findings of the social science literature and at the same time strongly linked to computational methods. We show how this model can lead to computational controversy analytics that have full coverage over all the crucial aspects that make up a controversy. ",Computational Controversy
17,878280257123500033,6334772,eytan bakshy,['New paper on how we use Bayesian optimization to run A/B tests at Facebook <LINK>'],https://arxiv.org/abs/1706.07094,"Randomized experiments are the gold standard for evaluating the effects of changes to real-world systems. Data in these tests may be difficult to collect and outcomes may have high variance, resulting in potentially large measurement error. Bayesian optimization is a promising technique for efficiently optimizing multiple continuous parameters, but existing approaches degrade in performance when the noise level is high, limiting its applicability to many randomized experiments. We derive an expression for expected improvement under greedy batch optimization with noisy observations and noisy constraints, and develop a quasi-Monte Carlo approximation that allows it to be efficiently optimized. Simulations with synthetic functions show that optimization performance on noisy, constrained problems outperforms existing methods. We further demonstrate the effectiveness of the method with two real-world experiments conducted at Facebook: optimizing a ranking system, and optimizing server compiler flags. ",Constrained Bayesian Optimization with Noisy Experiments
18,877988702760296449,2307019063,Jonathan Jogenfors,['New paper: Tight Bounds for the Pearle-Braunstein-Caves Chained Inequality Without the Fair-Coincidence Assumption\n<LINK>'],https://arxiv.org/abs/1706.06596,"In any Bell test, loopholes can cause issues in the interpretation of the results, since an apparent violation of the inequality may not correspond to a violation of local realism. An important example is the coincidence-time loophole that arises when detector settings might influence the time when detection will occur. This effect can be observed in many experiments where measurement outcomes are to be compared between remote stations because the interpretation of an ostensible Bell violation strongly depends on the method used to decide coincidence. The coincidence-time loophole has previously been studied for the Clauser-Horne-Shimony-Holt (CHSH) and Clauser-Horne (CH) inequalities, but recent experiments have shown the need for a generalization. Here, we study the generalized ""chained"" inequality by Pearle-Braunstein-Caves (PBC) with two or more settings per observer. This inequality has applications in, for instance, Quantum Key Distribution where it has been used to re-establish security. In this paper we give the minimum coincidence probability for the PBC inequality for all N and show that this bound is tight for a violation free of the fair-coincidence assumption. Thus, if an experiment has a coincidence probability exceeding the critical value derived here, the coincidence-time loophole is eliminated. ","Tight Bounds for the Pearle-Braunstein-Caves Chained Inequality Without
  the Fair-Coincidence Assumption"
19,877900308097097730,4758937001,Duncan Christie,"['New Paper: ""GMC Collisions As Triggers of Star Formation. IV. The Role of Ambipolar Diffusion""\n\nSubmitted to ApJ\n\n<LINK>']",https://arxiv.org/abs/1706.07032,"We investigate the role of ambipolar diffusion (AD) in collisions between magnetized giant molecular clouds (GMCs), which may be an important mechanism for triggering star cluster formation. Three dimensional simulations of GMC collisions are performed using a version of the Enzo magnetohydrodynamics code that has been extended to include AD. The resistivities are calculated using the 31-species chemical model of Wu et al. (2015). We find that in the weak-field, $10\:{\rm \mu G}$ case, AD has only a modest effect on the dynamical evolution during the collision. However, for the stronger-field, $30\:{\rm \mu G}$ case involving near-critical clouds, AD results in formation of dense cores in regions where collapse is otherwise inhibited. The overall efficiency of formation of cores with $n_{\rm H}\geq10^{6}\:{\rm cm}^{-3}$ in these simulations is increases from about 0.2% to 2% once AD is included, comparable to observed values in star-forming GMCs. The gas around these cores typically has relatively slow infall at speeds that are a modest fraction of the free-fall speed. ","GMC Collisions As Triggers of Star Formation. IV. The Role of Ambipolar
  Diffusion"
20,877877187856056320,1545756036,Mike Boylan-Kolchin,['New paper led by X. Ma on simulated reionization-era galaxies and predictions for @NASAWebb <LINK> @XSEDEscience'],https://arxiv.org/abs/1706.06605,"We present a suite of cosmological zoom-in simulations at z>5 from the Feedback In Realistic Environments project, spanning a halo mass range M_halo~10^8-10^12 M_sun at z=5. We predict the stellar mass-halo mass relation, stellar mass function, and luminosity function in several bands from z=5-12. The median stellar mass-halo mass relation does not evolve strongly at z=5-12. The faint-end slope of the luminosity function steepens with increasing redshift, as inherited from the halo mass function at these redshifts. Below z~6, the stellar mass function and ultraviolet (UV) luminosity function slightly flatten below M_star~10^4.5 M_sun (fainter than M_1500~-12), owing to the fact that star formation in low-mass halos is suppressed by the ionizing background by the end of reionization. Such flattening does not appear at higher redshifts. We provide redshift-dependent fitting functions for the SFR-M_halo, SFR-M_star, and broad-band magnitude-stellar mass relations. We derive the star formation rate density and stellar mass density at z=5-12 and show that the contribution from very faint galaxies becomes more important at z>8. Furthermore, we find that the decline in the z~6 UV luminosity function brighter than M_1500~-20 is largely due to dust attenuation. Approximately 37% (54%) of the UV luminosity from galaxies brighter than M_1500=-13 (-17) is obscured by dust at z~6. Our results broadly agree with current data and can be tested by future observations. ","Simulating galaxies in the reionization era with FIRE-2: galaxy scaling
  relations, stellar mass functions, and luminosity functions"
21,877721544981569537,4438354094,Tom Wong,['New paper showing that a lazy or lackadaisical quantum walk can speed up search on the 2D grid. <LINK> <LINK>'],https://arxiv.org/abs/1706.06939,"In the typical model, a discrete-time coined quantum walk searching the 2D grid for a marked vertex achieves a success probability of $O(1/\log N)$ in $O(\sqrt{N \log N})$ steps, which with amplitude amplification yields an overall runtime of $O(\sqrt{N} \log N)$. We show that making the quantum walk lackadaisical or lazy by adding a self-loop of weight $4/N$ to each vertex speeds up the search, causing the success probability to reach a constant near $1$ in $O(\sqrt{N \log N})$ steps, thus yielding an $O(\sqrt{\log N})$ improvement over the typical, loopless algorithm. This improved runtime matches the best known quantum algorithms for this search problem. Our results are based on numerical simulations since the algorithm is not an instance of the abstract search algorithm. ",Faster Search by Lackadaisical Quantum Walk
22,877615201658568704,17732007,N. Asokan,"[""My student Thomas' new @RAID_Conference  paper on #CFI with #TrustZone-M includes a quick primer on #TrustZone-M. <LINK>""]",https://arxiv.org/abs/1706.05715,"With the increasing scale of deployment of Internet of Things (IoT), concerns about IoT security have become more urgent. In particular, memory corruption attacks play a predominant role as they allow remote compromise of IoT devices. Control-flow integrity (CFI) is a promising and generic defense technique against these attacks. However, given the nature of IoT deployments, existing protection mechanisms for traditional computing environments (including CFI) need to be adapted to the IoT setting. In this paper, we describe the challenges of enabling CFI on microcontroller (MCU) based IoT devices. We then present CaRE, the first interrupt-aware CFI scheme for low-end MCUs. CaRE uses a novel way of protecting the CFI metadata by leveraging TrustZone-M security extensions introduced in the ARMv8-M architecture. Its binary instrumentation approach preserves the memory layout of the target MCU software, allowing pre-built bare-metal binary code to be protected by CaRE. We describe our implementation on a Cortex-M Prototyping System and demonstrate that CaRE is secure while imposing acceptable performance and memory impact. ","CFI CaRE: Hardware-supported Call and Return Enforcement for Commercial
  Microcontrollers"
23,877357236938473472,94309595,Konrad Tywoniuk,['Excited about our new paper on quenching of jet substructures #arxiv #QCD <LINK>'],https://arxiv.org/abs/1706.06047,"We compute the in-medium energy loss probability distribution of two neighboring subjets at leading order, in the large-$N_c$ approximation. Our result exhibits a gradual onset of color decoherence of the system and accounts for two expected limiting cases. When the angular separation is smaller than the characteristic angle for medium-induced radiation, the two-pronged substructure lose energy coherently as a single color charge, namely that of the parent parton. At large angular separation the two subjets lose energy independently. Our result is a first step towards quantifying effects of energy loss as a result of the fluctuation of the multi-parton jet substructure and therefore goes beyond the standard approach to jet quenching based on single parton energy loss. We briefly discuss applications to jet observables in heavy-ion collisions. ",Radiative energy loss of neighboring subjets
24,877280982855962624,2569631268,Daniel Huber,['Paper presenting our new K2 RGB planet led by @SKGrunblatt out today! <LINK> #KeplerSciCon'],https://arxiv.org/abs/1706.05865,"Despite more than 20 years since the discovery of the first gas giant planet with an anomalously large radius, the mechanism for planet inflation remains unknown. Here, we report the discovery of EPIC228754001.01, an inflated gas giant planet found with the NASA K2 Mission, and a revised mass for another inflated planet, K2-97b. These planets reside on ~9 day orbits around host stars which recently evolved into red giants. We constrain the irradiation history of these planets using models constrained by asteroseismology and Keck/HIRES spectroscopy and radial velocity measurements. We measure planet radii of 1.31 +\- 0.11 Rjup and and 1.30 +\- 0.07 Rjup, respectively. These radii are typical for planets receiving the current irradiation, but not the former, zero age main sequence irradiation of these planets. This suggests that the current sizes of these planets are directly correlated to their current irradiation. Our precise constraints of the masses and radii of the stars and planets in these systems allow us to constrain the planetary heating efficiency of both systems as 0.03% +0.03%/-0.02%. These results are consistent with a planet re-inflation scenario, but suggest the efficiency of planet re-inflation may be lower than previously theorized. Finally, we discuss the agreement within 10% of stellar masses and radii, and planet masses, radii, and orbital periods of both systems and speculate that this may be due to selection bias in searching for planets around evolved stars. ","Seeing double with K2: Testing re-inflation with two remarkably similar
  planets around red giant branch stars"
25,877270092425420802,21820958,Michele Bannister,"[""New paper: how @OSSOSurvey's exquisite calibration shows our 8 far TNOs can be plucked from an even spread of orbits <LINK> <LINK>""]",https://arxiv.org/abs/1706.05348,"The accumulating, but small, set of large semi-major axis trans-Neptunian objects (TNOs) shows an apparent clustering in the orientations of their orbits. This clustering must either be representative of the intrinsic distribution of these TNOs, or else arise as a result of observation biases and/or statistically expected variations for such a small set of detected objects. The clustered TNOs were detected across different and independent surveys, which has led to claims that the detections are therefore free of observational bias. This apparent clustering has led to the so-called ""Planet 9"" hypothesis that a super-Earth currently resides in the distant solar system and causes this clustering. The Outer Solar System Origins Survey (OSSOS) is a large program that ran on the Canada-France-Hawaii Telescope from 2013--2017, discovering more than 800 new TNOs. One of the primary design goals of OSSOS was the careful determination of observational biases that would manifest within the detected sample. We demonstrate the striking and non-intuitive biases that exist for the detection of TNOs with large semi-major axes. The eight large semi-major axis OSSOS detections are an independent dataset, of comparable size to the conglomerate samples used in previous studies. We conclude that the orbital distribution of the OSSOS sample is consistent with being detected from a uniform underlying angular distribution. ","OSSOS VI. Striking Biases in the detection of large semimajor axis
  Trans-Neptunian Objects"
26,877078311259734016,280083723,Yoh Tanimoto,['our new paper~ <LINK>'],https://arxiv.org/abs/1706.06070,"We apply the free product construction to various local algebras in algebraic quantum field theory. If we take the free product of infinitely many identical half-sided modular inclusions with ergodic canonical endomorphism, we obtain a half-sided modular inclusion with ergodic canonical endomorphism and trivial relative commutant. On the other hand, if we take M\""obius covariant nets with trace class property, we are able to construct an inclusion of free product von Neumann algebras with large relative commutant, by considering either a finite family of identical inclusions or an infinite family of inequivalent inclusions. In two dimensional spacetime, we construct Borchers triples with trivial relative commutant by taking free products of infinitely many, identical Borchers triples. Free products of finitely many Borchers triples are possibly associated with Haag-Kastler net having S-matrix which is nontrivial and non asymptotically complete, yet the nontriviality of double cone algebras remains open. ",Free products in AQFT
27,877070197626216448,721931072,Shimon Whiteson,['Our new paper on expected policy gradients: the benefits of deterministic policy gradients but for discrete actions. <LINK>'],https://arxiv.org/abs/1706.05374,"We propose expected policy gradients (EPG), which unify stochastic policy gradients (SPG) and deterministic policy gradients (DPG) for reinforcement learning. Inspired by expected sarsa, EPG integrates across the action when estimating the gradient, instead of relying only on the action in the sampled trajectory. We establish a new general policy gradient theorem, of which the stochastic and deterministic policy gradient theorems are special cases. We also prove that EPG reduces the variance of the gradient estimates without requiring deterministic policies and, for the Gaussian case, with no computational overhead. Finally, we show that it is optimal in a certain sense to explore with a Gaussian policy such that the covariance is proportional to the exponential of the scaled Hessian of the critic with respect to the actions. We present empirical results confirming that this new form of exploration substantially outperforms DPG with the Ornstein-Uhlenbeck heuristic in four challenging MuJoCo domains. ",Expected Policy Gradients
28,876979418559729665,791834604328001536,Katsuhito Sudoh,"['Our new paper is out on arXiv, ""An Empirical Study of Mini-Batch Creation Strategies for Neural Machine Translation""\n<LINK>', 'This is a comparative study in different mini-batching in NMT. It suggests an efficiency-oriented mini-batching is not always good...', 'This is a joint work with NAIST people when I was in NTT; the first author is now at NTT :-)']",https://arxiv.org/abs/1706.05765,"Training of neural machine translation (NMT) models usually uses mini-batches for efficiency purposes. During the mini-batched training process, it is necessary to pad shorter sentences in a mini-batch to be equal in length to the longest sentence therein for efficient computation. Previous work has noted that sorting the corpus based on the sentence length before making mini-batches reduces the amount of padding and increases the processing speed. However, despite the fact that mini-batch creation is an essential step in NMT training, widely used NMT toolkits implement disparate strategies for doing so, which have not been empirically validated or compared. This work investigates mini-batch creation strategies with experiments over two different datasets. Our results suggest that the choice of a mini-batch creation strategy has a large effect on NMT training and some length-based sorting strategies do not always work well compared with simple shuffling. ","An Empirical Study of Mini-Batch Creation Strategies for Neural Machine
  Translation"
29,876841267841204224,2918290813,Dr./Prof. Sam Lawler,"['New paper! With an independent survey (@OSSOSurvey), we find no evidence of orbit clustering needed for #planetnine\n<LINK>']",https://arxiv.org/abs/1706.05348,"The accumulating, but small, set of large semi-major axis trans-Neptunian objects (TNOs) shows an apparent clustering in the orientations of their orbits. This clustering must either be representative of the intrinsic distribution of these TNOs, or else arise as a result of observation biases and/or statistically expected variations for such a small set of detected objects. The clustered TNOs were detected across different and independent surveys, which has led to claims that the detections are therefore free of observational bias. This apparent clustering has led to the so-called ""Planet 9"" hypothesis that a super-Earth currently resides in the distant solar system and causes this clustering. The Outer Solar System Origins Survey (OSSOS) is a large program that ran on the Canada-France-Hawaii Telescope from 2013--2017, discovering more than 800 new TNOs. One of the primary design goals of OSSOS was the careful determination of observational biases that would manifest within the detected sample. We demonstrate the striking and non-intuitive biases that exist for the detection of TNOs with large semi-major axes. The eight large semi-major axis OSSOS detections are an independent dataset, of comparable size to the conglomerate samples used in previous studies. We conclude that the orbital distribution of the OSSOS sample is consistent with being detected from a uniform underlying angular distribution. ","OSSOS VI. Striking Biases in the detection of large semimajor axis
  Trans-Neptunian Objects"
30,876823959362314240,314014164,Adrian Price-Whelan,"[""New paper day by L. Anderson++! Fig 12 is one of the coolest CMD's I've ever seen!* <LINK>\n(*I haven't seen many CMD's) <LINK>""]",https://arxiv.org/abs/1706.05055,"Converting a noisy parallax measurement into a posterior belief over distance requires inference with a prior. Usually this prior represents beliefs about the stellar density distribution of the Milky Way. However, multi-band photometry exists for a large fraction of the \textsl{\small{Gaia}} \textsl{\small{TGAS}} Catalog and is incredibly informative about stellar distances. Here we use \textsl{\small{2MASS}} colors for 1.4 million \textsl{\small{TGAS}} stars to build a noise-deconvolved empirical prior distribution for stars in color--magnitude space. This model contains no knowledge of stellar astrophysics or the Milky Way, but is precise because it accurately generates a large number of noisy parallax measurements under an assumption of stationarity; that is, it is capable of combining the information from many stars. We use the Extreme Deconvolution (\textsl{\small{XD}}) algorithm---an Empirical Bayes approximation to a full hierarchical model of the true parallax and photometry of every star---to construct this prior. The prior is combined with a \textsl{\small{TGAS}} likelihood to infer a precise photometric parallax estimate and uncertainty (and full posterior) for every star. Our parallax estimates are more precise than the \textsl{\small{TGAS}} catalog entries by a median factor of 1.2 (14% are more precise by a factor >2) and are more precise than previous Bayesian distance estimates that use spatial priors. We validate our parallax inferences using members of the Milky Way star cluster M67, which is not visible as a cluster in the \textsl{\small{TGAS}} parallax estimates, but appears as a cluster in our posterior parallax estimates. Our results, including a parallax posterior pdf for each of 1.4 million \textsl{\small{TGAS}} stars, are available in companion electronic tables. ","Improving \textsl{Gaia} parallax precision with a data-driven model of
  stars"
31,876800263440539649,3209362451,Burton Lab,"['New paper from @burtonlab describing ""emergent bistability"" posted on the arxiv: <LINK>']",https://arxiv.org/abs/1706.04311,"Multistability is an inseparable feature of many physical, chemical and biological systems which are driven far from equilibrium. In these nonequilibrium systems, stochastic dynamics often induces switching between distinct states on emergent timescales, for example, bistable switching is a natural feature of noisy, spatially-extended systems that consist of bistable elements. Nevertheless, here we present experimental evidence that bistable elements are not required for the global bistability of a system. We observe temporal switching between a crystalline, condensed state and a gas-like, excited state in a spatially-extended, quasi-two-dimensional system of charged microparticles. Accompanying numerical simulations show that conservative forces, damping, and stochastic noise are sufficient to prevent steady-state equilibrium, leading to switching between the two states over a range of time scales, from seconds to hours. ",Emergent Bistability and Switching in a Nonequilibrium Crystal
32,876720843576967168,16174436,Sune Lehmann,['new paper on arXiv today! The Role of Gender in Social Network Organization <LINK>'],https://arxiv.org/abs/1706.05100,"The digital traces we leave behind when engaging with the modern world offer an interesting lens through which we study behavioral patterns as expression of gender. Although gender differentiation has been observed in a number of settings, the majority of studies focus on a single data stream in isolation. Here we use a dataset of high resolution data collected using mobile phones, as well as detailed questionnaires, to study gender differences in a large cohort. We consider mobility behavior and individual personality traits among a group of more than $800$ university students. We also investigate interactions among them expressed via person-to-person contacts, interactions on online social networks, and telecommunication. Thus, we are able to study the differences between male and female behavior captured through a multitude of channels for a single cohort. We find that while the two genders are similar in a number of aspects, there are robust deviations that include multiple facets of social interactions, suggesting the existence of inherent behavioral differences. Finally, we quantify how aspects of an individual's characteristics and social behavior reveals their gender by posing it as a classification problem. We ask: How well can we distinguish between male and female study participants based on behavior alone? Which behavioral features are most predictive? ",The Role of Gender in Social Network Organization
33,876645787148492800,231611786,Dr. Mike Alexandersen,"['New paper on arXiv by @Cory_Shankman, @jjkavelaars, @astrokiwi, @sundogplanets, @Mikea1985, @kat_volk et al. <LINK>']",https://arxiv.org/abs/1706.05348,"The accumulating, but small, set of large semi-major axis trans-Neptunian objects (TNOs) shows an apparent clustering in the orientations of their orbits. This clustering must either be representative of the intrinsic distribution of these TNOs, or else arise as a result of observation biases and/or statistically expected variations for such a small set of detected objects. The clustered TNOs were detected across different and independent surveys, which has led to claims that the detections are therefore free of observational bias. This apparent clustering has led to the so-called ""Planet 9"" hypothesis that a super-Earth currently resides in the distant solar system and causes this clustering. The Outer Solar System Origins Survey (OSSOS) is a large program that ran on the Canada-France-Hawaii Telescope from 2013--2017, discovering more than 800 new TNOs. One of the primary design goals of OSSOS was the careful determination of observational biases that would manifest within the detected sample. We demonstrate the striking and non-intuitive biases that exist for the detection of TNOs with large semi-major axes. The eight large semi-major axis OSSOS detections are an independent dataset, of comparable size to the conglomerate samples used in previous studies. We conclude that the orbital distribution of the OSSOS sample is consistent with being detected from a uniform underlying angular distribution. ","OSSOS VI. Striking Biases in the detection of large semimajor axis
  Trans-Neptunian Objects"
34,875710885930651648,353171647,Katelyn Allers,['Our new paper on bPic. Cool stuff on Li ages and completeness of the IMF...and the best ACRONYM ever! <LINK>'],https://arxiv.org/abs/1706.04556,"We confirm 66 low-mass stellar and brown dwarf systems (K7-M9) plus 19 visual or spectroscopic companions of the beta Pictoris Moving Group (BPMG). Of these, 41 are new discoveries, increasing the known low-mass members by 45%. We also add four objects to the 14 known with masses predicted to be less than 0.07 Msun. Our efficient photometric+kinematic selection process identified 104 low-mass candidates which we observed with ground-based spectroscopy. We collected infrared observations of the latest spectral types (>M5) to search for low gravity objects. These and all <M5 candidates were observed with high-resolution optical spectrographs to measure the radial velocities and youth indicators, such as lithium absorption and H-alpha emission, needed to confirm BPMG membership, achieving a 63% confirmation rate. We also compiled the most complete census of the BPMG membership with which we tested the efficiency and false-membership assignments using our selection and confirmation criteria. We assess a group age of 22 +/- 6 Myr using the new census, consistent with past estimates. With the now densely sampled lithium depletion boundary, we resolve the broadening of the boundary by either an age spread or astrophysical influences on lithium burning rates. We find that 69% of the now known members with AFGKM primaries are M stars, nearing the expected value of 75%. However, the new IMF for the BPMG shows a deficit of 0.2-0.3 Msun stars by a factor of approximately 2. We expect that the AFGK census of the BPMG is also incomplete, probably due to biases of searches towards the nearest stars. ","All-sky Co-moving Recovery Of Nearby Young Members. (ACRONYM) II: The
  Beta Pictoris Moving Group"
35,875287104288411648,1069568448,Steve Crawford,"['New paper by @solohery_astro on the arXiv today looking at the stellar to dynamical mass for LCBGs in clusters <LINK>', '@solohery_astro These star-bursting galaxies at intermediate redshift show smaller  dynamical to stellar mass ratio in galaxy clusters than the field https://t.co/ZIKVp08kXM']",https://arxiv.org/abs/1706.04534,"We investigate the stellar masses of the class of star-forming objects known as Luminous Compact Blue Galaxies (LCBGs) by studying a sample of galaxies in the distant cluster MS$~$0451.6-0305 at $z\approx0.54$ with ground-based multicolor imaging and spectroscopy. For a sample of 16 spectroscopically-confirmed cluster LCBGs (colour $B-V < 0.5$, surface brightness $\mu_B < 21$ mag arcsec$^{-2}$, and magnitude $M_B < -18.5$), we measure stellar masses by fitting spectral energy distribution (SED) models to multiband photometry, and compare with dynamical masses (determined from velocity dispersion between 10 $<$ $\sigma_v (\rm km~ s^{-1})$ $<$ 80), we previously obtained from their emission-line spectra. We compare two different stellar population models that measure stellar mass in star-bursting galaxies, indicating correlations between the stellar age, extinction, and stellar mass derived from the two different SED models. The stellar masses of cluster LCBGs are distributed similarly to those of field LCBGs, but the cluster LCBGs show lower dynamical-to-stellar mass ratios ($\rm M_{dyn}/M_{\ast} = 2.6$) than their field LCBG counterparts ($\rm M_{dyn}/M_{\ast}=4.8$), echoing trends noted previously in low-redshift dwarf elliptical galaxies. Within this limited sample, the specific star formation rate declines steeply with increasing mass, suggesting that these cluster LCBGs have undergone vigorous star formation. ","Star-forming Galaxies in Intermediate Redshift Clusters: Stellar vs.
  Dynamical Masses of Luminous Compact Blue Galaxies"
36,875255628838707201,622926125,Paul Barklem,['New paper - Inelastic e+Mg collision data and its impact on modelling stellar and supernova spectra <LINK>'],https://arxiv.org/abs/1706.03399,"Results of calculations for inelastic e+Mg effective collision strengths for the lowest 25 physical states of Mg I (up to 3s6p 1P), and thus 300 transitions, from the convergent close-coupling (CCC) and the B-spline R-matrix (BSR) methods are presented. At temperatures of interest, ~5000 K, the results of the two calculations differ on average by only 4%, with a scatter of 27%. As the methods are independent, this suggests that the calculations provide datasets for e+Mg collisions accurate to this level. Comparison with the commonly used dataset compiled by Mauas et al. (1988), covering 25 transitions among 12 states, suggests the Mauas et al. data are on average ~57% too low, and with a very large scatter of a factor of ~6.5. In particular the collision strength for the transition corresponding to the Mg I intercombination line at 457 nm is significantly underestimated by Mauas et al., which has consequences for models that employ this dataset. In giant stars the new data leads to a stronger line compared to previous non-LTE calculations, and thus a reduction in the non-LTE abundance correction by ~0.1 dex (~25%). A non-LTE calculation in a supernova ejecta model shows this line becomes significantly stronger, by a factor of around two, alleviating the discrepancy where the 457 nm line in typical models with Mg/O ratios close to solar tended to be too weak compared to observations. ","Inelastic e+Mg collision data and its impact on modelling stellar and
  supernova spectra"
37,874850102472572928,841499391508779008,Zico Kolter,['Our new paper (by @_vaishnavh): Gradient descent GAN optimization is locally stable\n\nPaper: <LINK> <LINK>'],https://arxiv.org/abs/1706.04156,"Despite the growing prominence of generative adversarial networks (GANs), optimization in GANs is still a poorly understood topic. In this paper, we analyze the ""gradient descent"" form of GAN optimization i.e., the natural setting where we simultaneously take small gradient steps in both generator and discriminator parameters. We show that even though GAN optimization does not correspond to a convex-concave game (even for simple parameterizations), under proper conditions, equilibrium points of this optimization procedure are still \emph{locally asymptotically stable} for the traditional GAN formulation. On the other hand, we show that the recently proposed Wasserstein GAN can have non-convergent limit cycles near equilibrium. Motivated by this stability analysis, we propose an additional regularization term for gradient descent GAN updates, which \emph{is} able to guarantee local stability for both the WGAN and the traditional GAN, and also shows practical promise in speeding up convergence and addressing mode collapse. ",Gradient descent GAN optimization is locally stable
38,874650865763848193,3108542843,Fran√ßois-Xavier Briol,"['New paper accepted at ICML: ""On the sampling problem for kernel quadrature"" <LINK>! @Chris_Oates @MarkGirolami']",https://arxiv.org/abs/1706.03369,"The standard Kernel Quadrature method for numerical integration with random point sets (also called Bayesian Monte Carlo) is known to converge in root mean square error at a rate determined by the ratio $s/d$, where $s$ and $d$ encode the smoothness and dimension of the integrand. However, an empirical investigation reveals that the rate constant $C$ is highly sensitive to the distribution of the random points. In contrast to standard Monte Carlo integration, for which optimal importance sampling is well-understood, the sampling distribution that minimises $C$ for Kernel Quadrature does not admit a closed form. This paper argues that the practical choice of sampling distribution is an important open problem. One solution is considered; a novel automatic approach based on adaptive tempering and sequential Monte Carlo. Empirical results demonstrate a dramatic reduction in integration error of up to 4 orders of magnitude can be achieved with the proposed method. ",On the Sampling Problem for Kernel Quadrature
39,874630249010655233,778228628601602048,BIGWaves,['New @LIGO &amp; @ego_virgo paper looking for continuous gravitational waves from Scorpius X-1 <LINK> #nondetection <LINK>'],https://arxiv.org/abs/1706.03119,"We present the results of a semicoherent search for continuous gravitational waves from the low-mass X-ray binary Scorpius X-1, using data from the first Advanced LIGO observing run. The search method uses details of the modelled, parametrized continuous signal to combine coherently data separated by less than a specified coherence time, which can be adjusted to trade off sensitivity against computational cost. A search was conducted over the frequency range from 25 Hz to 2000 Hz, spanning the current observationally-constrained range of the binary orbital parameters. No significant detection candidates were found, and frequency-dependent upper limits were set using a combination of sensitivity estimates and simulated signal injections. The most stringent upper limit was set at 175 Hz, with comparable limits set across the most sensitive frequency range from 100 Hz to 200 Hz. At this frequency, the 95 pct upper limit on signal amplitude h0 is 2.3e-25 marginalized over the unknown inclination angle of the neutron star's spin, and 8.03e-26 assuming the best orientation (which results in circularly polarized gravitational waves). These limits are a factor of 3-4 stronger than those set by other analyses of the same data, and a factor of about 7 stronger than the best upper limits set using initial LIGO data. In the vicinity of 100 Hz, the limits are a factor of between 1.2 and 3.5 above the predictions of the torque balance model, depending on inclination angle, if the most likely inclination angle of 44 degrees is assumed, they are within a factor of 1.7. ","Upper Limits on Gravitational Waves from Scorpius X-1 from a Model-Based
  Cross-Correlation Search in Advanced LIGO Data"
40,874060847944839168,68746721,Fran√ßois Chollet,"['Our new paper: state-of-the-art results in machine translation at a considerably reduced computational cost. <LINK>', 'Using SliceNet, a convolutional seq2seq model inspired by Xception and ByteNet. Depthwise separable convolutions are the future üìà https://t.co/NzeDxrTfr2']",https://arxiv.org/abs/1706.03059,"Depthwise separable convolutions reduce the number of parameters and computation used in convolutional operations while increasing representational efficiency. They have been shown to be successful in image classification models, both in obtaining better models than previously possible for a given parameter count (the Xception architecture) and considerably reducing the number of parameters required to perform at a given level (the MobileNets family of architectures). Recently, convolutional sequence-to-sequence networks have been applied to machine translation tasks with good results. In this work, we study how depthwise separable convolutions can be applied to neural machine translation. We introduce a new architecture inspired by Xception and ByteNet, called SliceNet, which enables a significant reduction of the parameter count and amount of computation needed to obtain results like ByteNet, and, with a similar parameter count, achieves new state-of-the-art results. In addition to showing that depthwise separable convolutions perform well for machine translation, we investigate the architectural changes that they enable: we observe that thanks to depthwise separability, we can increase the length of convolution windows, removing the need for filter dilation. We also introduce a new ""super-separable"" convolution operation that further reduces the number of parameters and computational cost for obtaining state-of-the-art results. ",Depthwise Separable Convolutions for Neural Machine Translation
41,873534051482841088,67258665,prashant pandey,['Our new paper on fast x86 implementation of Select operation is up --- <LINK>'],https://arxiv.org/abs/1706.00990,"Rank and select are fundamental operations in succinct data structures, that is, data structures whose space consumption approaches the information-theoretic optimal. The performance of these primitives is central to the overall performance of succinct data structures. Traditionally, the select operation is the harder to implement efficiently, and most prior implementations of select on machine words use 50--80 machine instructions. (In contrast, rank on machine words can be implemented in only a handful of instructions on machines that support POPCOUNT.) However, recently Pandey et al. gave a new implementation of machine-word select that uses only four x86 machine instructions; two of which were introduced in Intel's Haswell CPUs. In this paper, we investigate the impact of this new implementation of machine-word select on the performance of general bit-vector-select. We first compare Pandey et al.'s machine-word select to the state-of-the-art implementations of Zhou et al. (which is not specific to Haswell) and Gog et al. (which uses some Haswell-specific instructions). We exhibit a speedup of 2X to 4X. We then study the impact of plugging Pandey et al.'s machine-word select into two state-of-the-art bit-vector-select implementations. Both Zhou et al.'s and Gog et al.'s select implementations perform a single machine-word select operation for each bit-vector select. We replaced the machine-word select with the new implementation and compared performance. Even though there is only a single machine- word select operation, we still obtained speedups of 20% to 68%. We found that the new select not only reduced the number of instructions required for each bit-vector select, but also improved CPU instruction cache performance and memory-access parallelism. ",A Fast x86 Implementation of Select
42,872993986306297856,839913287240278020,Joey Rodriguez,"[""My student Jack's paper on a new bright M-M eclipsing Binary from KELT! <LINK>""]",https://arxiv.org/abs/1706.02401,"We report the discovery of KELT J041621-620046, a moderately bright (J$\sim$10.2) M dwarf eclipsing binary system at a distance of 39$\pm$3 pc. KELT J041621-620046 was first identified as an eclipsing binary using observations from the Kilodegree Extremely Little Telescope (KELT) survey. The system has a short orbital period of $\sim$1.11 days and consists of components with M$_1$ = $0.447^{-0.047}_{+0.052}\,M_\odot$ and M$_2$ = $0.399^{-0.042}_{+0.046}\,M_\odot$ in nearly circular orbits. The radii of the two stars are R$_1$ = $0.540^{-0.032}_{+0.034}\,R_\odot$ and R$_2$ = $0.453\pm0.017\,R_\odot$. Full system and orbital properties were determined (to $\sim$10% error) by conducting an EBOP global modeling of the high precision photometric and spectroscopic observations obtained by the KELT Follow-up Network. Each star is larger by 17-28% and cooler by 4-10% than predicted by standard (non-magnetic) stellar models. Strong H$\alpha$ emission indicates chromospheric activity in both stars. The observed radii and temperature discrepancies for both components are more consistent with those predicted by empirical relations that account for convective suppression due to magnetic activity. ","A Bright Short Period M-M Eclipsing Binary from the KELT Survey:
  Magnetic Activity and the Mass-Radius Relationship for M-dwarfs"
43,872609910999011328,349215461,Ken Shen,"['Check out our new paper on Type Ia supernovae from pure detonations of white dwarfs! @broxtonjmiles <LINK>', '@broxtonjmiles  https://t.co/UYa4uQULAs']",https://arxiv.org/abs/1706.01898,"The detonation of a sub-Chandrasekhar-mass white dwarf (WD) has emerged as one of the most promising Type Ia supernova (SN Ia) progenitor scenarios. Recent studies have suggested that the rapid transfer of a very small amount of helium from one WD to another is sufficient to ignite a helium shell detonation that subsequently triggers a carbon core detonation, yielding a ""dynamically-driven double degenerate double detonation"" SN Ia. Because the helium shell that surrounds the core explosion is so minimal, this scenario approaches the limiting case of a bare C/O WD detonation. Motivated by discrepancies in previous literature and by a recent need for detailed nucleosynthetic data, we revisit simulations of naked C/O WD detonations in this paper. We disagree to some extent with the nucleosynthetic results of previous work on sub-Chandrasekhar-mass bare C/O WD detonations; e.g., we find that a median-brightness SN Ia is produced by the detonation of a 1.0 Msol WD instead of a more massive and rarer 1.1 Msol WD. The neutron-rich nucleosynthesis in our simulations agrees broadly with some observational constraints, although tensions remain with others. There are also discrepancies related to the velocities of the outer ejecta and light curve shapes, but overall our synthetic light curves and spectra are roughly consistent with observations. We are hopeful that future multi-dimensional simulations will resolve these issues and further bolster the dynamically-driven double degenerate double detonation scenario's potential to explain most SNe Ia. ",Sub-Chandrasekhar-mass white dwarf detonations revisited
44,872339085951741956,3242991169,Bharath Ramsundar,"['Check out my new paper on seq2seq for chemical retrosynthesis with Bowen Liu, @vijaypande and others! <LINK>', '@vijaypande Edit: new paper with @liubowen16 and @vijaypande', '@olexandr @vijaypande We think of it as a new angle of attack on an old problem :). Expect future iterations to improve performance more']",https://arxiv.org/abs/1706.01643,"We describe a fully data driven model that learns to perform a retrosynthetic reaction prediction task, which is treated as a sequence-to-sequence mapping problem. The end-to-end trained model has an encoder-decoder architecture that consists of two recurrent neural networks, which has previously shown great success in solving other sequence-to-sequence prediction tasks such as machine translation. The model is trained on 50,000 experimental reaction examples from the United States patent literature, which span 10 broad reaction types that are commonly used by medicinal chemists. We find that our model performs comparably with a rule-based expert system baseline model, and also overcomes certain limitations associated with rule-based expert systems and with any machine learning approach that contains a rule-based expert system component. Our model provides an important first step towards solving the challenging problem of computational retrosynthetic analysis. ","Retrosynthetic reaction prediction using neural sequence-to-sequence
  models"
45,872079735689531392,337280454,Jana Rodriguez Hertz Ê±âÂ®ú,['New paper! Structure of accessibility classes\n<LINK>\njoint with Carlos H. V√°squez üë©\u200düéì'],https://arxiv.org/abs/1706.01156,"In this work we deal with partially hyperbolic diffeomorphisms whose central direction is two dimensional. We prove that in general the accessibility classes are immersed manifolds. If, furthermore, the diffeomorphism is dynamically coherent and satisfies certain bunching condition, then the accessibility classes are $C^{1}$ immersed manifolds. ",Structure of accessibility classes
46,871958489815543808,733640801914343425,Adam Santoro,"['Excited about our new paper on relational reasoning, with @dnraposo @PeterWBattaglia and others at DeepMind. <LINK>']",https://arxiv.org/abs/1706.01427,"Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Our work shows how a deep learning architecture equipped with an RN module can implicitly discover and learn to reason about entities and their relations. ",A simple neural network module for relational reasoning
47,871956234659934208,40639812,Colin Cotter,"['New paper with Rob Kirby and Jameson Graber on compatible FEM for barotropic tidal prediction. <LINK>', 'Jameson showed us how to extend the results of https://t.co/0EqJ3gE623 to the nonlinear damping case, which is used in practice.', 'We show that under quasiperiodic tidal forcing,  the FEM discretisation has a global attracting solution, which converges to the true one.']",https://arxiv.org/abs/1706.01352,"We study mixed finite element methods for the rotating shallow water equations with linearized momentum terms but nonlinear drag. By means of an equivalent second-order formulation, we prove long-time stability of the system without energy accumulation. We also give rates of damping in unforced systems and various continuous dependence results on initial conditions and forcing terms. \emph{A priori} error estimates for the momentum and free surface elevation are given in $L^2$ as well as for the time derivative and divergence of the momentum. Numerical results confirm the theoretical results regarding both energy damping and convergence rates. ",Mixed finite elements for global tide models with nonlinear damping
48,871809003004846080,1087183776,Jordan Ellenberg,['New paper w D. Hast:  hyperelliptic curves g&gt;1 over Q have only finitely many rational points (without Faltings) <LINK>'],https://arxiv.org/abs/1706.00525,"We study the Selmer varieties of smooth projective curves of genus at least two defined over $\mathbb{Q}$ which geometrically dominate a curve with CM Jacobian. We extend a result of Coates and Kim to show that Kim's non-abelian Chabauty method applies to such a curve. By combining this with results of Bogomolov-Tschinkel and Poonen on unramified correspondences, we deduce that any cover of $\mathbf{P}^1$ with solvable Galois group, and in particular any superelliptic curve over $\mathbb{Q}$, has only finitely many rational points over $\mathbb{Q}$. ","Rational points on solvable curves over $\mathbb{Q}$ via non-abelian
  Chabauty"
49,871573588272439297,822304279037784065,Terry Taewoong Um,"[""My new paper: Simple data augmentation method for wearable data. \nParkinson's motor symptom classification 77%-&gt;92%. <LINK> <LINK>""]",https://arxiv.org/abs/1706.00527,"While convolutional neural networks (CNNs) have been successfully applied to many challenging classification applications, they typically require large datasets for training. When the availability of labeled data is limited, data augmentation is a critical preprocessing step for CNNs. However, data augmentation for wearable sensor data has not been deeply investigated yet. In this paper, various data augmentation methods for wearable sensor data are proposed. The proposed methods and CNNs are applied to the classification of the motor state of Parkinson's Disease patients, which is challenging due to small dataset size, noisy labels, and large intra-class variability. Appropriate augmentation improves the classification performance from 77.54\% to 86.88\%. ","Data Augmentation of Wearable Sensor Data for Parkinson's Disease
  Monitoring using Convolutional Neural Networks"
50,871528322773245952,1276295754,Alireza Makhzani,"['Our new paper, ""PixelGAN autoencoders"": semi-supervised learning with GAN inference networks and PixelCNN decoders <LINK>']",http://arxiv.org/abs/1706.00531,"In this paper, we describe the ""PixelGAN autoencoder"", a generative autoencoder in which the generative path is a convolutional autoregressive neural network on pixels (PixelCNN) that is conditioned on a latent code, and the recognition path uses a generative adversarial network (GAN) to impose a prior distribution on the latent code. We show that different priors result in different decompositions of information between the latent code and the autoregressive decoder. For example, by imposing a Gaussian distribution as the prior, we can achieve a global vs. local decomposition, or by imposing a categorical distribution as the prior, we can disentangle the style and content information of images in an unsupervised fashion. We further show how the PixelGAN autoencoder with a categorical prior can be directly used in semi-supervised settings and achieve competitive semi-supervised classification results on the MNIST, SVHN and NORB datasets. ",PixelGAN Autoencoders
51,870622971894878210,232127461,Nikola Mrk≈°iƒá,['New TACL paper on semantic specialisation (<LINK>). SOTA SimLex on 6 languages + multilingual dialogue!  #nlproc #emnlp2017'],https://arxiv.org/abs/1706.00374,"We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialised cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct high-quality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource ones. The effectiveness of our approach is demonstrated with state-of-the-art results on semantic similarity datasets in six languages. We next show that Attract-Repel-specialised vectors boost performance in the downstream task of dialogue state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our algorithm facilitate the training of multilingual DST models, which brings further performance improvements. ","Semantic Specialisation of Distributional Word Vector Spaces using
  Monolingual and Cross-Lingual Constraints"
52,870554307803873280,40639812,Colin Cotter,"['New paper submitted with Georg Gottwald and Darryl Holm on deriving the stochastic fluid ansatz from homogenisation. <LINK>', ""... in which we find conditions to derive the basic assumption required for Darryl's stochastic GFD https://t.co/k9kuicKU5E"", 'Stochastic modification of the transport velocity can occur when there are fast fluctuations around a mean flow.']",https://arxiv.org/abs/1706.00287,"In {\em{Holm}, Proc. Roy. Soc. A 471 (2015)} stochastic fluid equations were derived by employing a variational principle with an assumed stochastic Lagrangian particle dynamics. Here we show that the same stochastic Lagrangian dynamics naturally arises in a multi-scale decomposition of the deterministic Lagrangian flow map into a slow large-scale mean and a rapidly fluctuating small scale map. We employ homogenization theory to derive effective slow stochastic particle dynamics for the resolved mean part, thereby justifying stochastic fluid partial equations in the Eulerian formulation. To justify the application of rigorous homogenization theory, we assume mildly chaotic fast small-scale dynamics, as well as a centering condition. The latter requires that the mean of the fluctuating deviations is small, when pulled back to the mean flow. ","Stochastic partial differential fluid equations as a diffusive limit of
  deterministic Lagrangian multi-time dynamics"
53,870549871442497537,131879500,John Ilee,"['Detect GI in solar analogues? ‚úÖ \nMeasure the disc mass? ‚ùå\nGreat new paper by Marc Evans out today: <LINK> <LINK>', ""@r_d_alexander This disc model was designed not to fragment, so it's not best suited to test that. We could certainly do it with Cass' models though...""]",http://arxiv.org/abs/1706.00254,"Gravitational instabilities (GIs) are most likely a fundamental process during the early stages of protoplanetary disc formation. Recently, there have been detections of spiral features in young, embedded objects that appear consistent with GI-driven structure. It is crucial to perform hydrodynamic and radiative transfer simulations of gravitationally unstable discs in order to assess the validity of GIs in such objects, and constrain optimal targets for future observations. We utilise the radiative transfer code LIME to produce continuum emission maps of a $0.17\,\mathrm{M}_{\odot}$ self-gravitating protosolar-like disc. We note the limitations of using LIME as is and explore methods to improve upon the default gridding. We use CASA to produce synthetic observations of 270 continuum emission maps generated across different frequencies, inclinations and dust opacities. We find that the spiral structure of our protosolar-like disc model is distinguishable across the majority of our parameter space after 1 hour of observation, and is especially prominent at 230$\,$GHz due to the favourable combination of angular resolution and sensitivity. Disc mass derived from the observations is sensitive to the assumed dust opacities and temperatures, and therefore can be underestimated by a factor of at least 30 at 850$\,$GHz and 2.5 at 90$\,$GHz. As a result, this effect could retrospectively validate GIs in discs previously thought not massive enough to be gravitationally unstable, which could have a significant impact on the understanding of the formation and evolution of protoplanetary discs. ","Gravitational instabilities in a protosolar-like disc II: continuum
  emission and mass estimates"
54,879737651728760832,2471998820,Omer Levy,"['1/3 New Paper with @seo_minjoon Eunsol @LukeZettlemoyer: Zero-Shot Relation Extraction via Reading Comprehension <LINK>', '@seo_minjoon @LukeZettlemoyer 2/3 We show that RE can be reduced to simple QA, which allows to generalize to unseen relations.', '@seo_minjoon @LukeZettlemoyer 3/3 Challenging dataset with over 30M examples is publicly available: https://t.co/KsdhXWrlvY']",https://arxiv.org/abs/1706.04115,"We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task. ",Zero-Shot Relation Extraction via Reading Comprehension
55,879476430240980992,1226577054,Kari Dalnoki-Veress,"['Our new paper by @AdamFortais on the arXiv ""...droplets on a free-standing glassy membrane..."" #physics #fluids\n<LINK>']",https://arxiv.org/abs/1706.07534,"In this study, micro-droplets are placed on thin, glassy, free-standing films where the Laplace pressure of the droplet deforms the free-standing film, creating a bulge. The film's tension is modulated by changing temperature continuously from well below the glass transition into the melt state of the film. The contact angle of the liquid droplet with the planar film as well as the angle of the bulge with the film are measured and found to be consistent with the contact angles predicted by a force balance at the contact line. ","Liquid droplets on a free-standing glassy membrane: deformation through
  the glass transition"
56,879427760401154048,863536820,Oliver Elbert,['New paper by Victor Robles is out now!  Dwarf galaxies (&lt;10^6.5 Msun) best place to test dark matter physics\n\n<LINK>'],https://arxiv.org/abs/1706.07514,"We compare a suite of four simulated dwarf galaxies formed in 10$^{10} M_{\odot}$ haloes of collisionless Cold Dark Matter (CDM) with galaxies simulated in the same haloes with an identical galaxy formation model but a non-zero cross-section for dark matter self-interactions. These cosmological zoom-in simulations are part of the Feedback In Realistic Environments (FIRE) project and utilize the FIRE-2 model for hydrodynamics and galaxy formation physics. We find the stellar masses of the galaxies formed in Self-Interacting Dark Matter (SIDM) with $\sigma/m= 1\, cm^2/g$ are very similar to those in CDM (spanning $M_{\star} \approx 10^{5.7 - 7.0} M_{\odot}$) and all runs lie on a similar stellar mass -- size relation. The logarithmic dark matter density slope ($\alpha=d\log \rho / d\log r$) in the central $250-500$ pc remains steeper than $\alpha= -0.8$ for the CDM-Hydro simulations with stellar mass $M_{\star} \sim 10^{6.6} M_{\odot}$ and core-like in the most massive galaxy. In contrast, every SIDM hydrodynamic simulation yields a flatter profile, with $\alpha >-0.4$. Moreover, the central density profiles predicted in SIDM runs without baryons are similar to the SIDM runs that include FIRE-2 baryonic physics. Thus, SIDM appears to be much more robust to the inclusion of (potentially uncertain) baryonic physics than CDM on this mass scale, suggesting SIDM will be easier to falsify than CDM using low-mass galaxies. Our FIRE simulations predict that galaxies less massive than $M_{\star} < 3 \times 10^6 M_{\odot}$ provide potentially ideal targets for discriminating models, with SIDM producing substantial cores in such tiny galaxies and CDM producing cusps. ","SIDM on FIRE: Hydrodynamical Self-Interacting Dark Matter simulations of
  low-mass dwarf galaxies"
57,878218902655729665,14283504,Josh Bongard,"[""Our new paper on 'EvoDevoSoRo': evolving developing soft #robots (to appear at @GECCO2017). <LINK> <LINK>""]",https://arxiv.org/abs/1706.07296,"Different subsystems of organisms adapt over many time scales, such as rapid changes in the nervous system (learning), slower morphological and neurological change over the lifetime of the organism (postnatal development), and change over many generations (evolution). Much work has focused on instantiating learning or evolution in robots, but relatively little on development. Although many theories have been forwarded as to how development can aid evolution, it is difficult to isolate each such proposed mechanism. Thus, here we introduce a minimal yet embodied model of development: the body of the robot changes over its lifetime, yet growth is not influenced by the environment. We show that even this simple developmental model confers evolvability because it allows evolution to sweep over a larger range of body plans than an equivalent non-developmental system, and subsequent heterochronic mutations 'lock in' this body plan in more morphologically-static descendants. Future work will involve gradually complexifying the developmental model to determine when and how such added complexity increases evolvability. ",A Minimal Developmental Model Can Increase Evolvability in Soft Robots
58,878053269876035584,133148364,Devendra Chaplot,['New paper on Task-oriented Language Grounding with @kanthashree @RamK1729 @dheerajgopal @rsalakhu\n<LINK> <LINK>'],https://arxiv.org/abs/1706.07230,"To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called task-oriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states. ",Gated-Attention Architectures for Task-Oriented Language Grounding
59,876852043117240320,287550507,Cory Shankman,['New science: We find no evidence of orbit clustering needed for #planetnine in the fully independent @OSSOSurvey <LINK>'],https://arxiv.org/abs/1706.05348,"The accumulating, but small, set of large semi-major axis trans-Neptunian objects (TNOs) shows an apparent clustering in the orientations of their orbits. This clustering must either be representative of the intrinsic distribution of these TNOs, or else arise as a result of observation biases and/or statistically expected variations for such a small set of detected objects. The clustered TNOs were detected across different and independent surveys, which has led to claims that the detections are therefore free of observational bias. This apparent clustering has led to the so-called ""Planet 9"" hypothesis that a super-Earth currently resides in the distant solar system and causes this clustering. The Outer Solar System Origins Survey (OSSOS) is a large program that ran on the Canada-France-Hawaii Telescope from 2013--2017, discovering more than 800 new TNOs. One of the primary design goals of OSSOS was the careful determination of observational biases that would manifest within the detected sample. We demonstrate the striking and non-intuitive biases that exist for the detection of TNOs with large semi-major axes. The eight large semi-major axis OSSOS detections are an independent dataset, of comparable size to the conglomerate samples used in previous studies. We conclude that the orbital distribution of the OSSOS sample is consistent with being detected from a uniform underlying angular distribution. ","OSSOS VI. Striking Biases in the detection of large semimajor axis
  Trans-Neptunian Objects"
60,876841267841204224,2918290813,Dr./Prof. Sam Lawler,"['New paper! With an independent survey (@OSSOSurvey), we find no evidence of orbit clustering needed for #planetnine\n<LINK>']",https://arxiv.org/abs/1706.05348,"The accumulating, but small, set of large semi-major axis trans-Neptunian objects (TNOs) shows an apparent clustering in the orientations of their orbits. This clustering must either be representative of the intrinsic distribution of these TNOs, or else arise as a result of observation biases and/or statistically expected variations for such a small set of detected objects. The clustered TNOs were detected across different and independent surveys, which has led to claims that the detections are therefore free of observational bias. This apparent clustering has led to the so-called ""Planet 9"" hypothesis that a super-Earth currently resides in the distant solar system and causes this clustering. The Outer Solar System Origins Survey (OSSOS) is a large program that ran on the Canada-France-Hawaii Telescope from 2013--2017, discovering more than 800 new TNOs. One of the primary design goals of OSSOS was the careful determination of observational biases that would manifest within the detected sample. We demonstrate the striking and non-intuitive biases that exist for the detection of TNOs with large semi-major axes. The eight large semi-major axis OSSOS detections are an independent dataset, of comparable size to the conglomerate samples used in previous studies. We conclude that the orbital distribution of the OSSOS sample is consistent with being detected from a uniform underlying angular distribution. ","OSSOS VI. Striking Biases in the detection of large semimajor axis
  Trans-Neptunian Objects"
