,TweetID,AuthorID,AuthorName,Tweets,arxiv_link,Abstract,Title
0,727115431425806336,797433864,Danilo J. Rezende,['Checkout our new paper on convolutional DRAW and image compression\n<LINK>'],http://arxiv.org/abs/1604.08772,"We introduce a simple recurrent variational auto-encoder architecture that significantly improves image modeling. The system represents the state-of-the-art in latent variable models for both the ImageNet and Omniglot datasets. We show that it naturally separates global conceptual information from lower level details, thus addressing one of the fundamentally desired properties of unsupervised learning. Furthermore, the possibility of restricting ourselves to storing only global information about an image allows us to achieve high quality 'conceptual compression'. ",Towards Conceptual Compression
1,725569264770551808,267958924,Christian Ott,"['Explosion: 3D GR Radiation-Hydrodynamics Simulations of Core-Collapse Supernovae -- New paper w/Luke Roberts+, <LINK>']",https://arxiv.org/abs/1604.07848,"We report on a set of long-term general-relativistic three-dimensional (3D) multi-group (energy-dependent) neutrino-radiation hydrodynamics simulations of core-collapse supernovae. We employ a full 3D two-moment scheme with the local M1 closure, three neutrino species, and 12 energy groups per species. With this, we follow the post-core-bounce evolution of the core of a nonrotating $27$-$M_\odot$ progenitor in full unconstrained 3D and in octant symmetry for $\gtrsim$$ 380\,\mathrm{ms}$. We find the development of an asymmetric runaway explosion in our unconstrained simulation. We test the resolution dependence of our results and, in agreement with previous work, find that low resolution artificially aids explosion and leads to an earlier runaway expansion of the shock. At low resolution, the octant and full 3D dynamics are qualitatively very similar, but at high resolution, only the full 3D simulation exhibits the onset of explosion. ","General Relativistic Three-Dimensional Multi-Group Neutrino
  Radiation-Hydrodynamics Simulations of Core-Collapse Supernovae"
2,725131036108197888,405482317,Prof. Lisa Harvey-Smith,['My new paper on constraining the mass of a supermassive black hole using @CSIRO_ATNF telescopes is now available: <LINK>'],http://arxiv.org/abs/1604.07537,"We report the discovery of new, high-velocity narrow-line components of the OH megamaser in IRAS 20100-4156. Results from the Australian Square Kilometre Array Pathfinder (ASKAP)'s Boolardy Engineering Test Array (BETA) and the Australia Telescope Compact Array (ATCA) provide two independent measurements of the OH megamaser spectrum. We found evidence for OH megamaser clumps at $-$409 and $-$562 km/s (blue-shifted) from the systemic velocity of the galaxy, in addition to the lines previously known. The presence of such high velocities in the molecular emission from IRAS 20100$-$4156 could be explained by a ~50 pc molecular ring enclosing an approximately 3.8 billion solar mass black hole. We also discuss two alternatives, i.e. that the narrow-line masers are dynamically coupled to the wind driven by the active galactic nucleus or they are associated with two separate galactic nuclei. The comparison between the BETA and ATCA spectra provides another scientific verification of ASKAP's BETA. Our data, combined with previous measurements of the source enabled us to study the variability of the source over a twenty-six year period. The flux density of the brightest OH maser components has reduced by more than a factor of two between 1988 and 2015, whereas a secondary narrow-line component has more than doubled in the same time. Plans for high-resolution VLBI follow-up of this source are discussed, as are prospects for discovering new OH megamasers during the ASKAP early science program. ","High-velocity OH megamasers in IRAS 20100-4156: Evidence for a
  Supermassive Black Hole"
3,725120805059723264,2337598033,Geraint F. Lewis,"['A new paper with @lukebarnes83 &amp; Rajesh Kaushik <LINK> - cold water on simmering universes! <LINK>', '@qraal @lukebarnes83 we look forward it.']",https://arxiv.org/abs/1604.07460,"Primordial nucleosynthesis is rightly hailed as one of the great successes of the standard cosmological model. Here we consider the initial forging of elements in the recently proposed Rh = ct universe, a cosmology that demands linear evolution of the scale factor. Such a universe cools extremely slowly compared to standard cosmologies, considerably depleting the available neutrons during nucleosynthesis; this has significant implications for the resultant primordial abundances of elements, predicting a minuscule quantity of helium which is profoundly at odds with observations. The production of helium can be enhanced in such a ""simmering universe"" by boosting the baryon to photon ratio, although more than an order of magnitude increase is required to bring the helium mass fraction into accordance with observations. However, in this scenario, the prolonged period of nucleosynthesis results of the efficient cooking of lighter into heavier elements, impacting the resultant abundances of all elements so that, other than hydrogen and helium, there are virtually no light elements present in the universe. Without the addition of substantial new physics in the early universe, it is difficult to see how the Rh = ct universe can be considered a viable cosmological model. ","Primordial Nucleosynthesis in the Rh = ct cosmology: Pouring cold water
  on the Simmering Universe"
4,724887516021706752,41117987,Dr Michelle Collins,"[""New paper from @KarinaVoggel on the kinematics of Crater using MUSE! Analysis suggests it's a globular cluster <LINK>""]",https://arxiv.org/abs/1604.06806,"We present MUSE observations of the debated ultra faint stellar system Crater. We spectroscopically confirm 26 member stars of this system via radial velocity measurements. We derive the systematic instrumental velocity uncertainty of MUSE spectra to be 2.27$\rm \,km\,s^{-1}$. This new dataset increases the confirmed member stars of Crater by a factor of 3. One out of three bright blue stars and a fainter blue star just above the main-sequence-turn-off are also found to be likely members of the system. The observations reveal that Crater has a systemic radial velocity of $v_{\rm sys}=148.18^{\rm +1.08}_{\rm -1.15}\rm \,km\,s^{-1}$, whereas the most likely velocity dispersion of this system is $\sigma_{\rm v}=2.04^{\rm +2.19}_{\rm -1.06} \rm \,km\,s^{-1}$. The total dynamical mass of the system, assuming dynamical equilibrium is then $M_{\rm tot}=1.50^{+4.9}_{-1.2}\cdot 10^{\rm 5}M_{\odot}$ implying a mass-to-light ratio of M/L$_{\rm V}$=8.52$^{+28.0}_{-6.5}\, M_{\odot}/L_{\odot}$, which is consistent with a purely baryonic stellar population within its errors and no significant evidence for the presence dark matter was found. We also find evidence for a velocity gradient in the radial velocity distribution. We conclude that our findings strongly support that Crater is a faint intermediate-age outer halo globular cluster and not a dwarf galaxy. ","Probing the boundary between star clusters and dwarf galaxies: A MUSE
  view on the dynamics of Crater/Laevens I"
5,723001334908100608,56872711,Tejas Kulkarni,"['check our new paper on - Hierarchical Deep RL: Integrating temporal abstraction and intrinsic motivation"" <LINK>', '@iandanforth agreed re saliency. Ext rewards have always bothered me. But they seem appropriate to represent unalterable rewards w.r.t agent', '@Miles_Brundage if you chop top layer, model becomes DQN. Need flexible memory and qnet to learn objecty things to exploit top layer']",https://arxiv.org/abs/1604.06057,"Learning goal-directed behavior in environments with sparse feedback is a major challenge for reinforcement learning algorithms. The primary difficulty arises due to insufficient exploration, resulting in an agent being unable to learn robust value functions. Intrinsically motivated agents can explore new behavior for its own sake rather than to directly solve problems. Such intrinsic behaviors could eventually help the agent solve tasks posed by the environment. We present hierarchical-DQN (h-DQN), a framework to integrate hierarchical value functions, operating at different temporal scales, with intrinsically motivated deep reinforcement learning. A top-level value function learns a policy over intrinsic goals, and a lower-level function learns a policy over atomic actions to satisfy the given goals. h-DQN allows for flexible goal specifications, such as functions over entities and relations. This provides an efficient space for exploration in complicated environments. We demonstrate the strength of our approach on two problems with very sparse, delayed feedback: (1) a complex discrete stochastic decision process, and (2) the classic ATARI game `Montezuma's Revenge'. ","Hierarchical Deep Reinforcement Learning: Integrating Temporal
  Abstraction and Intrinsic Motivation"
6,722709494367707136,38640273,Davide Cellai,"['New paper, with @dorogovtsev and Bianconi. General theory for percolation on multiplex networks with edge overlap: <LINK>']",http://arxiv.org/abs/1604.05175,"Multiplex networks describe a large variety of complex systems including infrastructures, transportation networks and biological systems. Most of these networks feature a significant link overlap. It is therefore of particular importance to characterize the mutually connected giant component in these networks. Here we provide a message passing theory for characterizing the percolation transition in multiplex networks with link overlap and an arbitrary number of layers $M$. Specifically we propose and compare two message passing algorithms, that generalize the algorithm widely used to study the percolation transition in multiplex networks without link overlap. The first algorithm describes a directed percolation transition and admits an epidemic spreading interpretation. The second algorithm describes the emergence of the mutually connected giant component, that is the percolation transition, but does not preserve the epidemic spreading interpretation. We obtain the phase diagrams for the percolation and directed percolation transition in simple representative cases. We demonstrate that for the same multiplex network structure, in which the directed percolation transition has non-trivial tricritical points, the percolation transition has a discontinuous phase transition, with the exception of the trivial case in which all the layers completely overlap. ","Message passing theory for percolation models on multiplex networks with
  link overlap"
7,722427063475408896,171674815,Mark Marley,"['Our new paper on exomoon detection utilizing polarization variations. <LINK>', ""@astromarkmarley We are getting a lot of complaints in email we didn't include an intro review of all the other methods of moon detection"", '@astromarkmarley Certainly was not our intention to neglect anyone but rather paper very narrowly focuses on one additional method.', '@astromarkmarley One example of earlier thinking on other moon detection methods is this paper by J. Schneider https://t.co/Ym0jBQJ6lE']",http://arxiv.org/abs/1604.04773,"Many of the directly imaged self-luminous gas giant exoplanets have been found to have cloudy atmospheres. Scattering of the emergent thermal radiation from these planets by the dust grains in their atmospheres should locally give rise to significant linear polarization of the emitted radiation. However, the observable disk averaged polarization should be zero if the planet is spherically symmetric. Rotation-induced oblateness may yield a net non-zero disk averaged polarization if the planets have sufficiently high spin rotation velocity. On the other hand, when a large natural satellite or exomoon transits a planet with cloudy atmosphere along the line of sight, the asymmetry induced during the transit should give rise to a net non-zero, time resolved linear polarization signal. The peak amplitude of such time dependent polarization may be detectable even for slowly rotating exoplanets. Therefore, we suggest that large exomoons around directly imaged self-luminous exoplanets may be detectable through time resolved imaging polarimetry. Adopting detailed atmospheric models for several values of effective temperature and surface gravity which are appropriate for self-luminous exoplanets, we present the polarization profiles of these objects in the infrared during transit phase and estimate the peak amplitude of polarization that occurs during the inner contacts of the transit ingress/egress phase. The peak polarization is predicted to range between 0.1 and 0.3 % in the infrared. ","Detecting Exomoons Around Self-luminous Giant Exoplanets Through
  Polarization"
8,722335333149503488,3031179074,Michael Hippke,['Our new paper shows TTV/TDV patterns of exoplanets with multiple exomoons. Very cool plots.!\n<LINK> <LINK>'],http://arxiv.org/abs/1604.05094,"We present new ways to identify single and multiple moons around extrasolar planets using planetary transit timing variations (TTVs) and transit duration variations (TDVs). For planets with one moon, measurements from successive transits exhibit a hitherto undescribed pattern in the TTV-TDV diagram, originating from the stroboscopic sampling of the planet's orbit around the planet-moon barycenter. This pattern is fully determined and analytically predictable after three consecutive transits. The more measurements become available, the more the TTV-TDV diagram approaches an ellipse. For planets with multiple moons in orbital mean motion resonance (MMR), like the Galilean moons, the pattern is much more complex and addressed numerically in this report. Exomoons in MMR can also form closed, predictable TTV-TDV figures if the drift of the moons' pericenters is sufficiently slow. We find that MMR exomoons produce loops in the TTV-TDV diagram and that the number of these loops is equal to the order of the MMR, or the largest integer in the MMR ratio. We use a Bayesian model and Monte Carlo simulations to test the discoverability of exomoons using TTV-TDV diagrams with current and near-future technology. In a blind test, two of us (BP, DA) successfully retrieved a large moon from simulated TTV-TDV by co-authors MH and RH, which resembled data from a known Kepler planet candidate. Single exomoons with a 10% moon-to-planet mass ratio, like to Pluto-Charon binary, can be detectable in the archival data of the Kepler primary mission. Multi-exomoon systems, however, require either larger telescopes or brighter target stars. Complementary detection methods invoking a moon's own photometric transit or its orbital sampling effect can be used for validation or falsification. A combination of TESS, CHEOPS, and PLATO data would offer a compelling opportunity for exomoon discoveries around bright stars. ","Predictable patterns in planetary transit timing variations and transit
  duration variations due to exomoons"
9,722319821791109120,158659687,Sibylle Anderl,"[""My new paper with the CALYPSO group: if you've always wanted to learn about protostellar snow lines... ;) <LINK>""]",http://arxiv.org/abs/1604.05121,"Context. ""Snow lines"", marking regions where abundant volatiles freeze out onto the surface of dust grains, play an important role for planet growth and bulk composition in protoplanetary disks. They can already be observed in the envelopes of the much younger, low-mass Class 0 protostars that are still in their early phase of heavy accretion. Aims. We aim at using the information on the sublimation regions of different kinds of ices to understand the chemistry of the envelope, its temperature and density structure, and the history of the accretion process. Methods. As part of the CALYPSO IRAM Large Program, we have obtained observations of C$^{18}$O, N$_2$H$^+$ and CH$_3$OH towards nearby Class 0 protostars with the IRAM Plateau de Bure interferometer at sub-arcsecond resolution. For four of these sources we have modeled the emission using a chemical code coupled with a radiative transfer module. Results. We observe an anti-correlation of C$^{18}$O and N$_2$H$^+$ in NGC 1333-IRAS4A, NGC 1333-IRAS4B, L1157, and L1448C, with N$_2$H$^+$ forming a ring around the centrally peaked C$^{18}$O emission due to N$_2$H$^+$ being chemically destroyed by CO. The emission regions of models and observations match for a CO binding energy of 1200 K, which is higher than the binding energy of pure CO ices ($\sim$855 K). Furthermore, we find very low CO abundances inside the snow lines in our sources, about an order of magnitude lower than the total CO abundance observed in the gas on large scales in molecular clouds before depletion sets in. Conclusions. The high CO binding energy may hint at CO being frozen out in a polar ice environment like amorphous water ice or in non-polar CO$_2$-rich ice. The low CO abundances are comparable to values found in protoplanetary disks, which may indicate an evolutionary scenario where these low values are already established in the protostellar phase. (Abbr. Version) ","Probing the CO and methanol snow lines in young protostars. Results from
  the CALYPSO IRAM-PdBI survey"
10,720057047514030080,2878552400,Tanmoy Chakraborty,"['Check our recent IEEE TKDE paper on ""GenPerm"", a new metric for community analysis <LINK> @cnerg @gangulyniloy']",http://arxiv.org/abs/1604.03454,"Detection of non-overlapping and overlapping communities are essentially the same problem. However, current algorithms focus either on finding overlapping or non-overlapping communities. We present a generalized framework that can identify both non-overlapping and overlapping communities, without any prior input about the network or its community distribution. To do so, we introduce a vertex-based metric, GenPerm, that quantifies by how much a vertex belongs to each of its constituent communities. Our community detection algorithm is based on maximizing the GenPerm over all the vertices in the network. We demonstrate, through experiments over synthetic and real-world networks, that GenPerm is more effective than other metrics in evaluating community structure. Further, we show that due to its vertex-centric property, GenPerm can be used to unfold several inferences beyond community detection, such as core-periphery analysis and message spreading. Our algorithm for maximizing GenPerm outperforms six state-of-the-art algorithms in accurately predicting the ground-truth labels. Finally, we discuss the problem of resolution limit in overlapping communities and demonstrate that maximizing GenPerm can mitigate this problem. ","GenPerm: A Unified Method for Detecting Non-overlapping and Overlapping
  Communities"
11,719685586697596928,275529122,Michael Greenberg,"['New draft: ""Space-Efficient Latent Contracts"" <LINK>; simpler than the POPL 2015 paper and goes further']",http://arxiv.org/abs/1604.02474,"Standard higher-order contract monitoring breaks tail recursion and leads to space leaks that can change a program's asymptotic complexity; space-efficiency restores tail recursion and bounds the amount of space used by contracts. Space-efficient contract monitoring for contracts enforcing simple type disciplines (a/k/a gradual typing) is well studied. Prior work establishes a space-efficient semantics for manifest contracts without dependency (Greenberg 2015); we adapt that work to a latent calculus with dependency. We guarantee space efficiency when no dependency is used; we cannot generally guarantee space efficiency when dependency is used, but instead offer a framework for making such programs space efficient on a case-by-case basis. ",Space-Efficient Latent Contracts
12,718393636724031488,90258002,Santa Fe Institute,"[""3 days, 1 house, 15 PhDs, 1 new paper...congrats to SFI's postdocs for 72-Hour Science <LINK> <LINK>""]",https://arxiv.org/abs/1604.02096,"Pathogens can spread epidemically through populations. Beneficial contagions, such as viruses that enhance host survival or technological innovations that improve quality of life, also have the potential to spread epidemically. How do the dynamics of beneficial biological and social epidemics differ from those of detrimental epidemics? We investigate this question using three theoretical approaches. First, in the context of population genetics, we show that a horizontally-transmissible element that increases fitness, such as viral DNA, spreads superexponentially through a population, more quickly than a beneficial mutation. Second, in the context of behavioral epidemiology, we show that infections that cause increased connectivity lead to superexponential fixation in the population. Third, in the context of dynamic social networks, we find that preferences for increased global infection accelerate spread and produce superexponential fixation, but preferences for local assortativity halt epidemics by disconnecting the infected from the susceptible. We conclude that the dynamics of beneficial biological and social epidemics are characterized by the rapid spread of beneficial elements, which is facilitated in biological systems by horizontal transmission and in social systems by active spreading behavior of infected individuals. ",Dynamics of beneficial epidemics
13,718352506640801793,716239728077578244,Jordi Grau-Moya,['New paper!:  Planning with Information-Processing Constraints and Model Uncertainty  in Markov Decision Processes\n<LINK>'],http://arxiv.org/abs/1604.02080,"Information-theoretic principles for learning and acting have been proposed to solve particular classes of Markov Decision Problems. Mathematically, such approaches are governed by a variational free energy principle and allow solving MDP planning problems with information-processing constraints expressed in terms of a Kullback-Leibler divergence with respect to a reference distribution. Here we consider a generalization of such MDP planners by taking model uncertainty into account. As model uncertainty can also be formalized as an information-processing constraint, we can derive a unified solution from a single generalized variational principle. We provide a generalized value iteration scheme together with a convergence proof. As limit cases, this generalized scheme includes standard value iteration with a known model, Bayesian MDP planning, and robust planning. We demonstrate the benefits of this approach in a grid world simulation. ","Planning with Information-Processing Constraints and Model Uncertainty
  in Markov Decision Processes"
14,718188141190848513,17241004,"Jonathan Chang, PhD",['Our new paper (with lead author Erik Gjesfjeld) on the evolution of American automobiles is now online in the arXiv: <LINK>'],http://arxiv.org/abs/1604.00055,"One of the most remarkable aspects of our species is that while we show surprisingly little genetic diversity, we demonstrate astonishing amounts of cultural diversity. Perhaps most impressive is the diversity of our technologies, broadly defined as all the physical objects we produce and the skills we use to produce them. Despite considerable focus on the evolution of technology by social scientists and philosophers, there have been few attempts to systematically quantify technological diversity and therefore the dynamics of technological change remain poorly understood. Here we show a novel Bayesian model for examining technological diversification adopted from paleontological analysis of occurrence data. We use this framework to estimate the tempo of diversification in American car and truck models produced between 1896 and 2014 and to test the relative importance of competition and extrinsic factors in shaping changes in macroevolutionary rates. Our results identify a four-fold decrease in the origination and extinction rates of car models and a negative net diversification rate over the last thirty years. We also demonstrate that competition played a more significant role in car model diversification than either changes in oil prices or gross domestic product. Together our analyses provide a set of tools that can enhance current research on technological and cultural evolution by providing a flexible and quantitative framework for exploring the dynamics of diversification. ","Competition and extinction explain the evolution of diversity in
  American automobiles"
15,717965638669447168,51700215,Phil Bull,"[""New paper: Measuring the spatial curvature of the Universe? There's much still to be done <LINK>""]",http://arxiv.org/abs/1604.01410,"Current constraints on spatial curvature show that it is dynamically negligible: $|\Omega_{\rm K}| \lesssim 5 \times 10^{-3}$ (95% CL). Neglecting it as a cosmological parameter would be premature however, as more stringent constraints on $\Omega_{\rm K}$ at around the $10^{-4}$ level would offer valuable tests of eternal inflation models and probe novel large-scale structure phenomena. This precision also represents the ""curvature floor"", beyond which constraints cannot be meaningfully improved due to the cosmic variance of horizon-scale perturbations. In this paper, we discuss what future experiments will need to do in order to measure spatial curvature to this maximum accuracy. Our conservative forecasts show that the curvature floor is unreachable - by an order of magnitude - even with Stage IV experiments, unless strong assumptions are made about dark energy evolution and the $\Lambda$CDM parameter values. We also discuss some of the novel problems that arise when attempting to constrain a global cosmological parameter like $\Omega_{\rm K}$ with such high precision. Measuring curvature down to this level would be an important validation of systematics characterisation in high-precision cosmological analyses. ",Spatial curvature endgame: Reaching the limit of curvature determination
16,717536672376684544,51700215,Phil Bull,['New paper: in which we try to beat the kinetic SZ effect into a competitive cosmological observable <LINK>'],http://arxiv.org/abs/1604.01382,"Future ground-based CMB experiments will generate competitive large-scale structure datasets by precisely characterizing CMB secondary anisotropies over a large fraction of the sky. We describe a method for constraining the growth rate of structure to sub-1% precision out to $z\approx 1$, using a combination of galaxy cluster peculiar velocities measured using the kinetic Sunyaev-Zel'dovich (kSZ) effect, and the velocity field reconstructed from galaxy redshift surveys. We consider only thermal SZ-selected cluster samples, which will consist of $\mathcal{O}(10^4-10^5)$ sources for Stage 3 and 4 CMB experiments respectively. Three different methods for separating the kSZ effect from the primary CMB are compared, including a novel blind ""constrained realization"" method that improves signal-to-noise by a factor of $\sim 2$ over a commonly-used aperture photometry technique. Measurements of the integrated tSZ $y$-parameter are used to break the kSZ velocity-optical depth degeneracy, and the effects of including CMB polarization and SZ profile uncertainties are also considered. A combination of future Stage 4 experiments should be able to measure the product of the growth and expansion rates, $\alpha\equiv f H$, to better than 1% in bins of $\Delta z = 0.1$ out to $z \approx 1$ -- competitive with contemporary redshift-space distortion constraints from galaxy surveys. ","Reconstructing cosmic growth with kSZ observations in the era of Stage
  IV experiments"
17,717347889463357440,311823090,Matthew Beck,['New paper up on the arXiv. Proud to be a part of the X-Ray work on this one. Another paper should hit web in \n&lt;1 mo.\n<LINK>'],http://arxiv.org/abs/1604.00877,"Magnetic flux noise is a dominant source of dephasing and energy relaxation in superconducting qubits. The noise power spectral density varies with frequency as $1/f^\alpha$ with $\alpha \sim 1$ and spans 13 orders of magnitude. Recent work indicates that the noise is from unpaired magnetic defects on the surfaces of the superconducting devices. Here, we demonstrate that adsorbed molecular O$_2$ is the dominant contributor to magnetism in superconducting thin films. We show that this magnetism can be suppressed by appropriate surface treatment or improvement in the sample vacuum environment. We observe a suppression of static spin susceptibility by more than an order of magnitude and a suppression of $1/f$ magnetic flux noise power spectral density by more than a factor of 5. These advances open the door to realization of superconducting qubits with improved quantum coherence. ",Origin and Suppression of $1/f$ Magnetic Flux Noise
18,717165974642798594,267958924,Christian Ott,"['So happy today:new paper w/@RolandHaas5+,<LINK>, Double Neutron Star Mergers with SpEC - so many many years in the making!!']",http://arxiv.org/abs/1604.00782,"We present results on the inspiral, merger, and post-merger evolution of a neutron star - neutron star (NSNS) system. Our results are obtained using the hybrid pseudospectral-finite volume Spectral Einstein Code (SpEC). To test our numerical methods, we evolve an equal-mass system for $\approx 22$ orbits before merger. This waveform is the longest waveform obtained from fully general-relativistic simulations for NSNSs to date. Such long (and accurate) numerical waveforms are required to further improve semi-analytical models used in gravitational wave data analysis, for example the effective one body models. We discuss in detail the improvements to SpEC's ability to simulate NSNS mergers, in particular mesh refined grids to better resolve the merger and post-merger phases. We provide a set of consistency checks and compare our results to NSNS merger simulations with the independent BAM code. We find agreement between them, which increases confidence in results obtained with either code. This work paves the way for future studies using long waveforms and more complex microphysical descriptions of neutron star matter in SpEC. ","Simulations of inspiraling and merging double neutron stars using the
  Spectral Einstein Code"
19,716824243275710464,3031289872,Stephen Plaza,['My new paper with Stuart Berg on large-scale image segmentation with Spark: <LINK>'],http://arxiv.org/abs/1604.00385,"The emerging field of connectomics aims to unlock the mysteries of the brain by understanding the connectivity between neurons. To map this connectivity, we acquire thousands of electron microscopy (EM) images with nanometer-scale resolution. After aligning these images, the resulting dataset has the potential to reveal the shapes of neurons and the synaptic connections between them. However, imaging the brain of even a tiny organism like the fruit fly yields terabytes of data. It can take years of manual effort to examine such image volumes and trace their neuronal connections. One solution is to apply image segmentation algorithms to help automate the tracing tasks. In this paper, we propose a novel strategy to apply such segmentation on very large datasets that exceed the capacity of a single machine. Our solution is robust to potential segmentation errors which could otherwise severely compromise the quality of the overall segmentation, for example those due to poor classifier generalizability or anomalies in the image dataset. We implement our algorithms in a Spark application which minimizes disk I/O, and apply them to a few large EM datasets, revealing both their effectiveness and scalability. We hope this work will encourage external contributions to EM segmentation by providing 1) a flexible plugin architecture that deploys easily on different cluster environments and 2) an in-memory representation of segmentation that could be conducive to new advances. ",Large-Scale Electron Microscopy Image Segmentation in Spark
20,717438521749938176,20810416,Dr. Roman Yampolskiy,"['New Arxiv paper on ""The AGI Containment Problem""\n\nAbstract\nThere is considerable uncertainty about what... <LINK>']",https://arxiv.org/abs/1604.00545,"There is considerable uncertainty about what properties, capabilities and motivations future AGIs will have. In some plausible scenarios, AGIs may pose security risks arising from accidents and defects. In order to mitigate these risks, prudent early AGI research teams will perform significant testing on their creations before use. Unfortunately, if an AGI has human-level or greater intelligence, testing itself may not be safe; some natural AGI goal systems create emergent incentives for AGIs to tamper with their test environments, make copies of themselves on the internet, or convince developers and operators to do dangerous things. In this paper, we survey the AGI containment problem - the question of how to build a container in which tests can be conducted safely and reliably, even on AGIs with unknown motivations and capabilities that could be dangerous. We identify requirements for AGI containers, available mechanisms, and weaknesses that need to be addressed. ",The AGI Containment Problem
21,720181040585842689,1665414144,David Wilson,"[""Our paper is out today! We looked for planets made of diamond, but couldn't find any :( <LINK>"", '@jotajotahermes thanks! I was worried about readability, as the referee asked for a lot more of the technical details than we initially had']",http://arxiv.org/abs/1604.03104,"Observations of small extrasolar planets with a wide range of densities imply a variety of planetary compositions and structures. Currently, the only technique to measure the bulk composition of extrasolar planetary systems is the analysis of planetary debris accreting onto white dwarfs, analogous to abundance studies of meteorites. We present measurements of the carbon and oxygen abundances in the debris of planetesimals at ten white dwarfs observed with the Hubble Space Telescope, along with C/O ratios of debris in six systems with previously reported abundances. We find no evidence for carbon-rich planetesimals, with C/O<0.8 by number in all 16 systems. Our results place an upper limit on the occurrence of carbon-rich systems at <17 percent with a 2 sigma confidence level. The range of C/O of the planetesimals is consistent with that found in the Solar System, and appears to follow a bimodal distribution: a group similar to the CI chondrites, with log(<C/O>)=-0.92, and oxygen-rich objects with C/O less than or equal to that of the bulk Earth. The latter group may have a higher mass fraction of water than the Earth, increasing their relative oxygen abundance. ",Carbon to oxygen ratios in extrasolar planetesimals
