,TweetID,AuthorID,AuthorName,Tweets,arxiv_link,Abstract,Title
0,705105062792564736,95065949,Thiago S Gonçalves,"['New paper out, congrats to Marco Grossi!\nEverything you wanted to know about star-forming dwarf galaxies in the... <LINK>']",https://arxiv.org/abs/1602.09077,"We present $^{12}$CO(1-0) and $^{12}$CO(2-1) observations of a sample of 20 star-forming dwarfs selected from the Herschel Virgo Cluster Survey, with oxygen abundances ranging from 12 + log(O/H) ~ 8.1 to 8.8. CO emission is observed in ten galaxies and marginally detected in another one. CO fluxes correlate with the FIR 250 $\mu$m emission, and the dwarfs follow the same linear relation that holds for more massive spiral galaxies extended to a wider dynamical range. We compare different methods to estimate H2 molecular masses, namely a metallicity-dependent CO-to-H2 conversion factor and one dependent on H-band luminosity. The molecular-to-stellar mass ratio remains nearly constant at stellar masses <~ 10$^9$ M$_{\odot}$, contrary to the atomic hydrogen fraction, M$_{HI}$/M$_*$, which increases inversely with M$_*$. The flattening of the M$_{H_2}$/M$_*$ ratio at low stellar masses does not seem to be related to the effects of the cluster environment because it occurs for both HI-deficient and HI-normal dwarfs. The molecular-to-atomic ratio is more tightly correlated with stellar surface density than metallicity, confirming that the interstellar gas pressure plays a key role in determining the balance between the two gaseous components of the interstellar medium. Virgo dwarfs follow the same linear trend between molecular gas mass and star formation rate as more massive spirals, but gas depletion timescales, $\tau_{dep}$, are not constant and range between 100 Myr and 6 Gyr. The interaction with the Virgo cluster environment is removing the atomic gas and dust components of the dwarfs, but the molecular gas appears to be less affected at the current stage of evolution within the cluster. However, the correlation between HI deficiency and the molecular gas depletion time suggests that the lack of gas replenishment from the outer regions of the disc is lowering the star formation activity. ","Star-forming dwarf galaxies in the Virgo cluster: the link between
  molecular gas, atomic gas, and dust"
1,704723374644322304,2249688711,Kevin M Moermⓐn,['Our new paper on transtibial residuum viscoelastic behaviour <LINK> (or 10.1016/j.jmbbm.2016.02.020) @dsengeh'],http://arxiv.org/abs/1602.08956,"Although the socket is critical in a prosthetic system for a person with limb amputation, the methods of its design are largely artisanal. A roadblock for a repeatable and quantitative socket design process is the lack of predictive and patient specific biomechanical models of the residuum. This study presents the evaluation of such a model using a combined experimental-numerical approach. The model geometry and tissue boundaries are derived from MRI. The soft tissue non-linear elastic and viscoelastic mechanical behavior was evaluated using inverse finite element analysis (FEA) of in-vivo indentation experiments. A custom designed robotic in-vivo indentation system was used to provide a rich experimental data set of force versus time at 18 sites across a limb. During FEA, the tissues were represented by two layers, namely the skin-adipose layer and an underlying muscle-soft tissue complex. The non-linear elastic behavior was modeled using 2nd order Ogden hyperelastic formulations, and viscoelasticity was modeled using the quasi-linear theory of viscoelasticity. To determine the material parameters for each tissue, an inverse FEA based optimization routine was used that minimizes the combined mean of the squared force differences between the numerical and experimental force-time curves for indentations at 4 distinct anatomical regions on the residuum. The optimization provided the following material parameters for the skin-adipose layer: c=5.22 kPa, m=4.79, gamma=3.57 MPa, tau=0.32 s and for the muscle-soft tissue complex: c=5.20 kPa, m=4.78, gamma=3.47 MPa, tau=0.34 s. These parameters were evaluated to predict the force-time curves for the remaining 14 anatomical locations. The mean percentage error (mean absolute error/ maximum experimental force) for these predictions was 7 +/- 3%. The mean percentage error at the 4 sites used for the optimization was 4%. ","Multi-Material 3-D Viscoelastic Model of a Transtibial Residuum from
  In-vivo Indentation and MRI Data"
2,704677210578411520,2956121356,Russ Salakhutdinov,"['New paper on Architectural Complexity Measures of Recurrent Neural Networks by Saizheng Zhang, Tony Wu, et.al.\n<LINK>']",http://arxiv.org/abs/1602.08210,"In this paper, we systematically analyze the connecting architectures of recurrent neural networks (RNNs). Our main contribution is twofold: first, we present a rigorous graph-theoretic framework describing the connecting architectures of RNNs in general. Second, we propose three architecture complexity measures of RNNs: (a) the recurrent depth, which captures the RNN's over-time nonlinear complexity, (b) the feedforward depth, which captures the local input-output nonlinearity (similar to the ""depth"" in feedforward neural networks (FNNs)), and (c) the recurrent skip coefficient which captures how rapidly the information propagates over time. We rigorously prove each measure's existence and computability. Our experimental results show that RNNs might benefit from larger recurrent depth and feedforward depth. We further demonstrate that increasing recurrent skip coefficient offers performance boosts on long term dependency problems. ",Architectural Complexity Measures of Recurrent Neural Networks
3,704608384188858368,2427184074,Christopher Berry,['Updated GW150914 blog <LINK> with new @LIGO electromagnetic follow-up paper <LINK> <LINK>'],http://arxiv.org/abs/1602.08492,"A gravitational-wave (GW) transient was identified in data recorded by the Advanced Laser Interferometer Gravitational-wave Observatory (LIGO) detectors on 2015 September 14. The event, initially designated G184098 and later given the name GW150914, is described in detail elsewhere. By prior arrangement, preliminary estimates of the time, significance, and sky location of the event were shared with 63 teams of observers covering radio, optical, near-infrared, X-ray, and gamma-ray wavelengths with ground- and space-based facilities. In this Letter we describe the low-latency analysis of the GW data and present the sky localization of the first observed compact binary merger. We summarize the follow-up observations reported by 25 teams via private Gamma-ray Coordinates Network circulars, giving an overview of the participating facilities, the GW sky localization coverage, the timeline and depth of the observations. As this event turned out to be a binary black hole merger, there is little expectation of a detectable electromagnetic (EM) signature. Nevertheless, this first broadband campaign to search for a counterpart of an Advanced LIGO source represents a milestone and highlights the broad capabilities of the transient astronomy community and the observing strategies that have been developed to pursue neutron star binary merger events. Detailed investigations of the EM data and results of the EM follow-up campaign are being disseminated in papers by the individual teams. ","Localization and broadband follow-up of the gravitational-wave transient
  GW150914"
4,703077005244420096,479672092,Constantine Dovrolis,"['New paper: ""From spatio-temporal data to a weighted and lagged network between functional domains""   -- <LINK>']",https://arxiv.org/abs/1602.07249,"We propose {\delta}-MAPS, a method that analyzes spatio-temporal data to first identify the distinct spatial components of the underlying system, referred to as ""domains"", and second to infer the connections between them. A domain is a spatially contiguous region of highly correlated temporal activity. The core of a domain is a point or subregion at which a metric of local homogeneity is maximum across the entire domain. We compute a domain as the maximum-sized set of spatially contiguous cells that include the detected core and satisfy a homogeneity constraint, expressed in terms of the average pairwise cross-correlation across all cells in the domain. Domains may be spatially overlapping. Different domains may have correlated activity, potentially at a lag, because of direct or indirect interactions. The proposed edge inference method examines the statistical significance of each lagged cross-correlation between two domains, infers a range of lag values for each edge, and assigns a weight to each edge based on the covariance of the two domains. We illustrate the application of {\delta}-MAPS on data from two domains: climate science and neuroscience. ","{\delta}-MAPS: From spatio-temporal data to a weighted and lagged
  network between functional domains"
5,702391752016142336,15254510,Tobias Weyand,['My new paper: PlaNet - Photo Geolocation with Convolutional Neural Networks <LINK>'],http://arxiv.org/abs/1602.05314,"Is it possible to build a system to determine the location where a photo was taken using just its pixels? In general, the problem seems exceptionally difficult: it is trivial to construct situations where no location can be inferred. Yet images often contain informative cues such as landmarks, weather patterns, vegetation, road markings, and architectural details, which in combination may allow one to determine an approximate location and occasionally an exact location. Websites such as GeoGuessr and View from your Window suggest that humans are relatively good at integrating these cues to geolocate images, especially en-masse. In computer vision, the photo geolocation problem is usually approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. While previous approaches only recognize landmarks or perform approximate matching using global image descriptors, our model is able to use and integrate multiple visible cues. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman levels of accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, we demonstrate that this model achieves a 50% performance improvement over the single-image model. ",PlaNet - Photo Geolocation with Convolutional Neural Networks
6,702328012453183488,267958924,Christian Ott,['New paper w/ Davide Gerosa &amp; Uli Sperhake: Core Collapse in Scalar Tensor Theory. <LINK> Movies: <LINK>'],http://arxiv.org/abs/1602.06952,"We present numerical-relativity simulations of spherically symmetric core collapse and compact-object formation in scalar-tensor theories of gravity. The additional scalar degree of freedom introduces a propagating monopole gravitational-wave mode. Detection of monopole scalar waves with current and future gravitational-wave experiments may constitute smoking gun evidence for strong-field modifications of General Relativity. We collapse both polytropic and more realistic pre-supernova profiles using a high-resolution shock-capturing scheme and an approximate prescription for the nuclear equation of state. The most promising sources of scalar radiation are protoneutron stars collapsing to black holes. In case of a Galactic core collapse event forming a black hole, Advanced LIGO may be able to place independent constraints on the parameters of the theory at a level comparable to current Solar-System and binary-pulsar measurements. In the region of the parameter space admitting spontaneously scalarised stars, transition to configurations with prominent scalar hair before black-hole formation further enhances the emitted signal. Although a more realistic treatment of the microphysics is necessary to fully investigate the occurrence of spontaneous scalarisation of neutron star remnants, we speculate that formation of such objects could constrain the parameters of the theory beyond the current bounds obtained with Solar-System and binary-pulsar experiments. ","Numerical simulations of stellar collapse in scalar-tensor theories of
  gravity"
7,702148450696175617,2601869406,Michael A Osborne,"[""What's even nicer than a kernel matrix? A *pre-conditioned* kernel matrix: our new paper up on the arXiv: <LINK>""]",http://arxiv.org/abs/1602.06693,"The computational and storage complexity of kernel machines presents the primary barrier to their scaling to large, modern, datasets. A common way to tackle the scalability issue is to use the conjugate gradient algorithm, which relieves the constraints on both storage (the kernel matrix need not be stored) and computation (both stochastic gradients and parallelization can be used). Even so, conjugate gradient is not without its own issues: the conditioning of kernel matrices is often such that conjugate gradients will have poor convergence in practice. Preconditioning is a common approach to alleviating this issue. Here we propose preconditioned conjugate gradients for kernel machines, and develop a broad range of preconditioners particularly useful for kernel matrices. We describe a scalable approach to both solving kernel machines and learning their hyperparameters. We show this approach is exact in the limit of iterations and outperforms state-of-the-art approximations for a given computational budget. ",Preconditioning Kernel Matrices
8,702146648483491840,479672092,Constantine Dovrolis,"['New paper - ""Lexis: An Optimization Framework for Discovering the Hierarchical Structure of Sequential Data"" <LINK>']",http://arxiv.org/abs/1602.05561,"Data represented as strings abounds in biology, linguistics, document mining, web search and many other fields. Such data often have a hierarchical structure, either because they were artificially designed and composed in a hierarchical manner or because there is an underlying evolutionary process that creates repeatedly more complex strings from simpler substrings. We propose a framework, referred to as ""Lexis"", that produces an optimized hierarchical representation of a given set of ""target"" strings. The resulting hierarchy, ""Lexis-DAG"", shows how to construct each target through the concatenation of intermediate substrings, minimizing the total number of such concatenations or DAG edges. The Lexis optimization problem is related to the smallest grammar problem. After we prove its NP-Hardness for two cost formulations, we propose an efficient greedy algorithm for the construction of Lexis-DAGs. We also consider the problem of identifying the set of intermediate nodes (substrings) that collectively form the ""core"" of a Lexis-DAG, which is important in the analysis of Lexis-DAGs. We show that the Lexis framework can be applied in diverse applications such as optimized synthesis of DNA fragments in genomic libraries, hierarchical structure discovery in protein sequences, dictionary-based text compression, and feature extraction from a set of documents. ","Lexis: An Optimization Framework for Discovering the Hierarchical
  Structure of Sequential Data"
9,702072555167993856,1860949428,David Sing,['New paper <LINK> by T. Kataria using circulation models on the #hjsurvey exoplanets. Highly irradiated planets are not 1D'],http://arxiv.org/abs/1602.06733,"We present results from an atmospheric circulation study of nine hot Jupiters that comprise a large transmission spectral survey using the Hubble and Spitzer Space Telescopes. These observations exhibit a range of spectral behavior over optical and infrared wavelengths which suggest diverse cloud and haze properties in their atmospheres. By utilizing the specific system parameters for each planet, we naturally probe a wide phase space in planet radius, gravity, orbital period, and equilibrium temperature. First, we show that our model ""grid"" recovers trends shown in traditional parametric studies of hot Jupiters, particularly equatorial superrotation and increased day-night temperature contrast with increasing equilibrium temperature. We show how spatial temperature variations, particularly between the dayside and nightside and west and east terminators, can vary by hundreds of K, which could imply large variations in Na, K, CO and CH4 abundances in those regions. These chemical variations can be large enough to be observed in transmission with high-resolution spectrographs, such as ESPRESSO on VLT, METIS on the E-ELT, or with MIRI and NIRSpec aboard JWST. We also compare theoretical emission spectra generated from our models to available Spitzer eclipse depths for each planet, and find that the outputs from our solar-metallicity, cloud-free models generally provide a good match to many of the datasets, even without additional model tuning. Although these models are cloud-free, we can use their results to understand the chemistry and dynamics that drive cloud formation in their atmospheres. ","The atmospheric circulation of a nine-hot Jupiter sample: Probing
  circulation and chemistry over a wide phase space"
10,701731319945027585,2861255332,Jozsef Vinko,['Our new paper dealing with Type IIb/IIP SNe has been accepted in A&amp;A\n<LINK>'],http://arxiv.org/abs/1602.04001,"We present an improved version of a light curve model, which is able to estimate the physical properties of different types of core-collapse supernovae having double-peaked light curves, in a quick and efficient way. The model is based on a two-component configuration consisting of a dense, inner region and an extended, low-mass envelope. Using this configuration, we estimate the initial parameters of the progenitor via fitting the shape of the quasi-bolometric light curves of 10 SNe, including Type IIP and IIb events, with model light curves. In each case we compare the fitting results with available hydrodynamic calculations, and also match the derived expansion velocities with the observed ones. Furthermore, we also compare our calculations with hydrodynamic models derived by the SNEC code, and examine the uncertainties of the estimated physical parameters caused by the assumption of constant opacity and the inaccurate knowledge of the moment of explosion. ","A two-component model for fitting light-curves of core-collapse
  supernovae"
11,700743979952955393,2503999452,Arnau Rios,"['Di-neutrons in #neutronstars? Find out more in a new paper, work with the #nuclearphysics group @uchile <LINK>']",http://arxiv.org/abs/1602.05234,"We investigate the appearance of di-neutron bound states in pure neutron matter within the Brueckner-Hartree-Fock approach at zero temperature. We consider Argonne $v_{18}$ and Paris bare interactions as well as chiral two- and three-nucleon forces. Self-consistent single-particle potentials are calculated controlling explicitly singularities in the $g$ matrix associated with bound states. Di-neutrons are loosely bound, with binding energies below $1$ MeV, but are unambiguously present for Fermi momenta below $1$ fm$^{-1}$ for all interactions. Within the same framework we are able to calculate and characterize di-neutron bound states, obtaining mean radii as high as $\sim 110$ fm. The resulting equations of state and mass-radius relations for pure neutron stars are analyzed including di-neutron contributions. ",Di-neutrons in neutron matter within Brueckner-Hartree-Fock approach
12,700649207237980164,19330436,Marco Bardoscia,['New paper out: Pathways towards instability in financial networks <LINK> @GuidoCaldarelli @zbattiz'],http://arxiv.org/abs/1602.05883,"Following the financial crisis of 2007-2008, a deep analogy between the origins of instability in financial systems and complex ecosystems has been pointed out: in both cases, topological features of network structures influence how easily distress can spread within the system. However, in financial network models, the details of how financial institutions interact typically play a decisive role, and a general understanding of precisely how network topology creates instability remains lacking. Here we show how processes that are widely believed to stabilise the financial system, i.e. market integration and diversification, can actually drive it towards instability, as they contribute to create cyclical structures which tend to amplify financial distress, thereby undermining systemic stability and making large crises more likely. This result holds irrespective of the details of how institutions interact, showing that policy-relevant analysis of the factors affecting financial stability can be carried out while abstracting away from such details. ",Pathways towards instability in financial networks
13,700504138526789632,173878568,Scott Purdy,['New paper - Encoding Data for HTM Systems - <LINK>'],http://arxiv.org/abs/1602.05925,"Hierarchical Temporal Memory (HTM) is a biologically inspired machine intelligence technology that mimics the architecture and processes of the neocortex. In this white paper we describe how to encode data as Sparse Distributed Representations (SDRs) for use in HTM systems. We explain several existing encoders, which are available through the open source project called NuPIC, and we discuss requirements for creating encoders for new types of data. ",Encoding Data for HTM Systems
14,700499737028358144,489705756,Reina Maruyama,['A new paper on DM-Ice! <LINK>'],http://arxiv.org/abs/1602.05939,"We present the first search for a dark matter annual modulation signal in the Southern Hemisphere conducted with NaI(Tl) detectors, performed by the DM-Ice17 experiment. Nuclear recoils from dark matter interactions are expected to yield an annually modulated signal independent of location within the Earth's hemispheres. DM-Ice17, the first step in the DM-Ice experimental program, consists of 17 kg of NaI(Tl) located at the South Pole under 2200 m.w.e. overburden of Antarctic glacial ice. Taken over 3.6 years for a total exposure of 60.8 kg yr, DM-Ice17 data are consistent with no modulation in the energy range of 4-20 keV, providing the strongest limits on weakly interacting massive particle dark matter from a direct detection experiment located in the Southern Hemisphere. The successful deployment and stable long-term operation of DM-Ice17 establishes the South Pole ice as a viable location for future dark matter searches and in particular for a high-sensitivity NaI(Tl) dark matter experiment to directly test the DAMA/LIBRA claim of the observation of dark matter. ","First search for a dark matter annual modulation signal with NaI(Tl) in
  the Southern Hemisphere by DM-Ice17"
15,700341544381878272,3885912072,Marshall Johnson,"['New paper <LINK> in which we analyze 27 years of radial velocity data on HD 219134 from @mcdonaldobs &amp; @keckobservatory', 'HD 219134 is a nearby star (21 light years away) which was found to have several planets by Motalebi et al. (2015) and Vogt et al. (2015).', ""We monitored the stellar activity, and found an 11.7 year activity cycle, similar to the Sun's 11 year cycle. https://t.co/LsXaZ66bDN"", 'We found an activity signal due to stellar rotation at 22.8 days (same period as planet f), suggesting this planet may be a false positive.']",http://arxiv.org/abs/1602.05200,"The nearby (6.5 pc) star HD 219134 was recently shown by Motalebi et al. (2015) and Vogt et al. (2015) to host several planets, the innermost of which is transiting. We present twenty-seven years of radial velocity observations of this star from the McDonald Observatory Planet Search program, and nineteen years of stellar activity data. We detect a long-period activity cycle measured in the Ca II $S_{HK}$ index, with a period of $4230 \pm 100$ days (11.7 years), very similar to the 11-year Solar activity cycle. Although the period of the Saturn-mass planet HD 219134 h is close to half that of the activity cycle, we argue that it is not an artifact due to stellar activity. We also find a significant periodicity in the $S_{HK}$ data due to stellar rotation with a period of 22.8 days. This is identical to the period of planet f identified by Vogt et al. (2015), suggesting that this radial velocity signal might be caused by rotational modulation of stellar activity rather than a planet. Analysis of our radial velocities allows us to detect the long-period planet HD 219134 h and the transiting super-Earth HD 219134 b. Finally, we use our long time baseline to constrain the presence of longer-period planets in the system, excluding to $1\sigma$ objects with $M\sin i>0.36 M_J$ at 12 years (corresponding to the orbital period of Jupiter) and $M\sin i>0.72 M_J$ at a period of 16.4 years (assuming a circular orbit for an outer companion). ",A 12-Year Activity Cycle for HD 219134
16,700303353113403392,320688727,Arnaud Browet,['new paper on «\xa0cell segmentation with Random ferns and graph cuts\xa0» is available on arXiv: <LINK>'],http://arxiv.org/abs/1602.05439,"The progress in imaging techniques have allowed the study of various aspect of cellular mechanisms. To isolate individual cells in live imaging data, we introduce an elegant image segmentation framework that effectively extracts cell boundaries, even in the presence of poor edge details. Our approach works in two stages. First, we estimate pixel interior/border/exterior class probabilities using random ferns. Then, we use an energy minimization framework to compute boundaries whose localization is compliant with the pixel class probabilities. We validate our approach on a manually annotated dataset. ",Cell segmentation with random ferns and graph-cuts
17,699894256350162944,1601296094,David Bowler,['New paper on Ti interstitials on the charge density wave in TiSe2 with Swiss colleagues (submitted to PRL) <LINK>'],http://arxiv.org/abs/1602.04972,The impact of variable Ti self-doping on the 1T-TiSe2 charge density wave (CDW) is studied by scanning tunneling microscopy. Supported by density functional theory we show that agglomeration of intercalated-Ti atoms acts as preferential nucleation centers for the CDW that breaks up in phaseshifted CDW domains whose size directly depends on the intercalated-Ti concentration and which are separated by atomically-sharp phase boundaries. The close relationship between the diminution of the CDW domain size and the disappearance of the anomalous peak in the temperature dependent resistivity allows to draw a coherent picture of the 1T-TiSe2 CDW phase transition and its relation to excitons. ,"Short-range phase coherence and origin of the 1T-TiSe2 charge density
  wave"
18,699866162285453312,2333045815,Christian A Naesseth,"['Check out our new paper introducing the ""Interacting Particle MCMC"" method, PMCMC for parallel/distributed computing <LINK>']",http://arxiv.org/abs/1602.05128,"We introduce interacting particle Markov chain Monte Carlo (iPMCMC), a PMCMC method based on an interacting pool of standard and conditional sequential Monte Carlo samplers. Like related methods, iPMCMC is a Markov chain Monte Carlo sampler on an extended space. We present empirical results that show significant improvements in mixing rates relative to both non-interacting PMCMC samplers, and a single PMCMC sampler with an equivalent memory and computational budget. An additional advantage of the iPMCMC method is that it is suitable for distributed and multi-core architectures. ",Interacting Particle Markov Chain Monte Carlo
19,699446075640451072,3199605543,Afonso S. Bandeira,['New paper on guarantees for the Burer-Monteiro approach for SDPs arising in synchronization and community detection <LINK>'],http://arxiv.org/abs/1602.04426,"To address difficult optimization problems, convex relaxations based on semidefinite programming are now common place in many fields. Although solvable in polynomial time, large semidefinite programs tend to be computationally challenging. Over a decade ago, exploiting the fact that in many applications of interest the desired solutions are low rank, Burer and Monteiro proposed a heuristic to solve such semidefinite programs by restricting the search space to low-rank matrices. The accompanying theory does not explain the extent of the empirical success. We focus on Synchronization and Community Detection problems and provide theoretical guarantees shedding light on the remarkable efficiency of this heuristic. ","On the low-rank approach for semidefinite programs arising in
  synchronization and community detection"
20,699293401162870785,618466970,Damiano Brigo (Prof),['New paper (pure maths): Coordinate-free Stochastic Differential Equations as Jets. Joint work with John Armstrong. <LINK>'],http://arxiv.org/abs/1602.03931,"We explain how It\^o Stochastic Differential Equations (SDEs) on manifolds may be defined using 2-jets of smooth functions. We show how this relationship can be interpreted in terms of a convergent numerical scheme. We show how jets can be used to derive graphical representations of It\^o SDEs. We show how jets can be used to derive the differential operators associated with SDEs in a coordinate free manner. We relate jets to vector flows, giving a geometric interpretation of the It\^o--Stratonovich transformation. We show how percentiles can be used to give an alternative coordinate free interpretation of the coefficients of one dimensional SDEs. We relate this to the jet approach. This allows us to interpret the coefficients of SDEs in terms of ""fan diagrams"". In particular the median of a SDE solution is associated to the drift of the SDE in Stratonovich form for small times. ",Coordinate-free Stochastic Differential Equations as Jets
21,698918597826125824,21815759,Charles Sutton,"['New paper: Neural networks, attention mechanisms, and summarizing computer programs. <LINK>', '@daniel_bilar @IgorCarron Great story! I recall similar story re Victor Hugo. Just after Les Mis published, VH telegram: ""?"" Publisher: ""!""']",http://arxiv.org/abs/1602.03001,"Attention mechanisms in neural networks have proved useful for problems in which the input and output do not have fixed dimension. Often there exist features that are locally translation invariant and would be valuable for directing the model's attention, but previous attentional architectures are not constructed to learn such features specifically. We introduce an attentional neural network that employs convolution on the input tokens to detect local time-invariant and long-range topical attention features in a context-dependent way. We apply this architecture to the problem of extreme summarization of source code snippets into short, descriptive function name-like summaries. Using those features, the model sequentially generates a summary by marginalizing over two attention mechanisms: one that predicts the next summary token based on the attention weights of the input tokens and another that is able to copy a code token as-is directly into the summary. We demonstrate our convolutional attention neural network's performance on 10 popular Java projects showing that it achieves better performance compared to previous attentional mechanisms. ","A Convolutional Attention Network for Extreme Summarization of Source
  Code"
22,697490179221753857,77316078,Arthur Gretton,['New kernel goodness-of-fit test: <LINK> using the Stein method of <LINK> with an RKHS function class.'],http://arxiv.org/abs/1602.02964,"We propose a nonparametric statistical test for goodness-of-fit: given a set of samples, the test determines how likely it is that these were generated from a target density function. The measure of goodness-of-fit is a divergence constructed via Stein's method using functions from a Reproducing Kernel Hilbert Space. Our test statistic is based on an empirical estimate of this divergence, taking the form of a V-statistic in terms of the log gradients of the target density and the kernel. We derive a statistical test, both for i.i.d. and non-i.i.d. samples, where we estimate the null distribution quantiles using a wild bootstrap procedure. We apply our test to quantifying convergence of approximate Markov Chain Monte Carlo methods, statistical model criticism, and evaluating quality of fit vs model complexity in nonparametric density estimation. ",A Kernel Test of Goodness of Fit
23,697326381525569536,3145451345,m.onodera,['Our new paper used spectra taken with the MOSFIRE instrument at @keckobservatory <LINK>'],http://arxiv.org/abs/1602.02779,"We study the relationship between stellar mass, star formation rate (SFR),ionization state, and gas-phase metallicity for a sample of 41 normal star-forming galaxies at $3 \lesssim z \lesssim 3.7$. The gas-phase oxygen abundance, ionization parameter, and electron density of ionized gas are derived from rest-frame optical strong emission lines measured on near-infrared spectra obtained with Keck/MOSFIRE. We remove the effect of these strong emission lines in the broad-band fluxes to compute stellar masses via spectral energy distribution fitting, while the SFR is derived from the dust-corrected ultraviolet luminosity. The ionization parameter is weakly correlated with the specific SFR, but otherwise the ionization parameter and electron density do not correlate with other global galaxy properties such as stellar mass, SFR, and metallicity. The mass-metallicity relation (MZR) at $z\simeq3.3$ shows lower metallicity by $\simeq 0.7$ dex than that at $z=0$ at the same stellar mass. Our sample shows an offset by $\simeq 0.3$ dex from the locally defined mass-metallicity-SFR relation, indicating that simply extrapolating such relation to higher redshift may predict an incorrect evolution of MZR. Furthermore, within the uncertainties we find no SFR-metallicity correlation, suggesting a less important role of SFR in controlling the metallicity at high redshift. We finally investigate the redshift evolution of the MZR by using the model by Lilly et al. (2013), finding that the observed evolution from $z=0$ to $z\simeq3.3$ can be accounted for by the model assuming a weak redshift evolution of the star formation efficiency. ","ISM excitation and metallicity of star-forming galaxies at z~3.3 from
  near-IR spectroscopy"
24,697326137660276736,3145451345,m.onodera,['want to know about ionized gas properties especially metallicity of normal galaxies at z~3.3? Look at our new paper <LINK>'],http://arxiv.org/abs/1602.02779,"We study the relationship between stellar mass, star formation rate (SFR),ionization state, and gas-phase metallicity for a sample of 41 normal star-forming galaxies at $3 \lesssim z \lesssim 3.7$. The gas-phase oxygen abundance, ionization parameter, and electron density of ionized gas are derived from rest-frame optical strong emission lines measured on near-infrared spectra obtained with Keck/MOSFIRE. We remove the effect of these strong emission lines in the broad-band fluxes to compute stellar masses via spectral energy distribution fitting, while the SFR is derived from the dust-corrected ultraviolet luminosity. The ionization parameter is weakly correlated with the specific SFR, but otherwise the ionization parameter and electron density do not correlate with other global galaxy properties such as stellar mass, SFR, and metallicity. The mass-metallicity relation (MZR) at $z\simeq3.3$ shows lower metallicity by $\simeq 0.7$ dex than that at $z=0$ at the same stellar mass. Our sample shows an offset by $\simeq 0.3$ dex from the locally defined mass-metallicity-SFR relation, indicating that simply extrapolating such relation to higher redshift may predict an incorrect evolution of MZR. Furthermore, within the uncertainties we find no SFR-metallicity correlation, suggesting a less important role of SFR in controlling the metallicity at high redshift. We finally investigate the redshift evolution of the MZR by using the model by Lilly et al. (2013), finding that the observed evolution from $z=0$ to $z\simeq3.3$ can be accounted for by the model assuming a weak redshift evolution of the star formation efficiency. ","ISM excitation and metallicity of star-forming galaxies at z~3.3 from
  near-IR spectroscopy"
25,697086966001704960,14697496,Thomas Steiner,['New paper “Wikipedia Tools for Google Spreadsheets” <LINK> Add some =WIKI* magic to your sheets. <LINK>'],http://arxiv.org/abs/1602.02506,"In this paper, we introduce the Wikipedia Tools for Google Spreadsheets. Google Spreadsheets is part of a free, Web-based software office suite offered by Google within its Google Docs service. It allows users to create and edit spreadsheets online, while collaborating with other users in realtime. Wikipedia is a free-access, free-content Internet encyclopedia, whose content and data is available, among other means, through an API. With the Wikipedia Tools for Google Spreadsheets, we have created a toolkit that facilitates working with Wikipedia data from within a spreadsheet context. We make these tools available as open-source on GitHub [this https URL], released under the permissive Apache 2.0 license. ",Wikipedia Tools for Google Spreadsheets
26,697078702006472704,3918111614,Oriol Vinyals,"['Our new Language Modeling paper: <LINK> With a single RNNLM (no ensembling), we reduce perplexity from ~50 down to 30.0!']",http://arxiv.org/abs/1602.02410,"In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon. ",Exploring the Limits of Language Modeling
27,696880445443567616,4253020032,sashank,"['#Privacy Preserving Architectures for Collaborative Intrusion Detection #ids #security our new paper, <LINK>']",http://arxiv.org/abs/1602.02452,"Collaboration among multiple organizations is imperative for contemporary intrusion detection. As modern threats become well sophisticated it is difficult for organizations to defend with threat context local to their networks alone. Availability of global \emph{threat intelligence} is must for organizations to defend against modern advanced persistent threats (APTs). In order to benefit from such global context of attacks, privacy concerns continue to be of major hindrance. In this position paper we identify real world privacy problems as precise use cases, relevant cryptographic technologies and discuss privacy preserving architectures for collaborative intrusion detection. ",Privacy Preserving Architectures for Collaborative Intrusion Detection
28,696662599375708160,561899047,Aki Vehtari,"['New paper Weber et al ""Hierarchical expectation propagation for Bayesian aggregation of average data"" <LINK>']",http://arxiv.org/abs/1602.02055,"Throughout the different phases of a drug development program, randomized trials are used to establish the tolerability, safety, and efficacy of a candidate drug. At each stage one aims to optimize the design of future studies by extrapolation from the available evidence at the time. This includes collected trial data and relevant external data. However, relevant external data are typically available as averages only, for example from trials on alternative treatments reported in the literature. Here we report on such an example from a drug development for wet age-related macular degeneration. This disease is the leading cause of severe vision loss in the elderly. While current treatment options are efficacious, they are also a substantial burden for the patient. Hence, new treatments are under development which need to be compared against existing treatments. The general statistical problem this leads to is meta-analysis, which addresses the question of how we can combine datasets collected under different conditions. Bayesian methods have long been used to achieve partial pooling. Here we consider the challenge when the model of interest is complex (hierarchical and nonlinear) and one dataset is given as raw data while the second dataset is given as averages only. In such a situation, common meta-analytic methods can only be applied when the model is sufficiently simple for analytic approaches. When the model is too complex, for example nonlinear, an analytic approach is not possible. We provide a Bayesian solution by using simulation to approximately reconstruct the likelihood of the external summary and allowing the parameters in the model to vary under the different conditions. We first evaluate our approach using fake-data simulations and then report results for the drug development program that motivated this research. ",Bayesian aggregation of average data: An application in drug development
29,695561415801901056,479680089,Quentin Riffard,['New paper-constraints from direct searches of SUSY DM in the light of null results from the LHC in the squark sector <LINK>'],http://arxiv.org/abs/1602.01030,"The comparison of the results of direct detection of Dark Matter, obtained with various target nuclei, requires model-dependent, or even arbitrary, assumptions. Indeed, to draw conclusions either the spin-dependent (SD) or the spin-independent (SI) interaction has to be neglected. In the light of the null results from supersymmetry searches at the LHC, the squark sector is pushed to high masses. We show that for a squark sector at the TeV scale, the framework used to extract contraints from direct detection searches can be redefined as the number of free parameters is reduced. Moreover, the correlation observed between SI and SD proton cross sections constitutes a key issue for the development of the next generation of Dark Matter detectors. ","Extracting constraints from direct detection searches of supersymmetric
  dark matter in the light of null results from the LHC in the squark sector"
30,695560822941212672,479680089,Quentin Riffard,['New MIMAC paper about experimental electron/recoil discrimination posted on arXiv : <LINK>'],http://arxiv.org/abs/1602.01738,"MIMAC (MIcro-TPC MAtrix of Chambers) is a directional WIMP Dark Matter detector project. Direct dark matter experiments need a high level of electron/recoil discrimination to search for nuclear recoils produced by WIMP-nucleus elastic scattering. In this paper, we proposed an original method for electron event rejection based on a multivariate analysis applied to experimental data acquired using monochromatic neutron fields. This analysis shows that a $10^5$ rejection power is reachable for electron/recoil discrimination. Moreover, the efficiency was estimated by a Monte-Carlo simulation showing that a 105 electron rejection power is reached with a $86.49\pm 0.17$\% nuclear recoil efficiency considering the full energy range and $94.67\pm0.19$\% considering a 5~keV lower threshold. ","MIMAC low energy electron-recoil discrimination measured with fast
  neutrons"
31,695054118394556416,1580357558,Rebecca Davies,['Can the merger stages of galaxies be inferred from the ages of their star clusters? We discuss this in our new paper <LINK>'],https://arxiv.org/abs/1602.01097,"We present near infrared imaging and integral field spectroscopy of the centre of the dusty luminous infrared galaxy merger MCG+08-11-002, taken using the Near InfraRed Camera 2 (NIRC2) and the OH-Suppressing InfraRed Imaging Spectrograph (OSIRIS) on Keck II. We achieve a spatial resolution of ~25 pc in the K band, allowing us to resolve 41 star clusters in the NIRC2 images. We calculate the ages of 22/25 star clusters within the OSIRIS field using the equivalent widths of the CO 2.3$\mu$m absorption feature and the Br$\gamma$ nebular emission line. The star cluster age distribution has a clear peak at ages < 20 Myr, indicative of current starburst activity associated with the final coalescence of the progenitor galaxies. There is a possible second peak at ~65 Myr which may be a product of the previous close passage of the galaxy nuclei. We fit single and double starburst models to the star cluster age distribution and use Monte Carlo sampling combined with two-sided K-S tests to calculate the probability that the observed data are drawn from each of the best fit distributions. There is a >90 per cent chance that the data are drawn from either a single or double starburst star formation history, but stochastic sampling prevents us from distinguishing between the two scenarios. Our analysis of MCG+08-11-002 indicates that star cluster age distributions provide valuable insights into the timelines of galaxy interactions and may therefore play an important role in the future development of precise merger stage classification systems. ","Reconstructing Merger Timelines Using Star Cluster Age Distributions:
  the Case of MCG+08-11-002"
32,694346679311466496,282227303,Dane Wilburne,['New paper: On the Geometry and Extremal Properties of the Edge-Degeneracy Model <LINK>'],https://arxiv.org/abs/1602.00180,"The edge-degeneracy model is an exponential random graph model that uses the graph degeneracy, a measure of the graph's connection density, and number of edges in a graph as its sufficient statistics. We show this model is relatively well-behaved by studying the statistical degeneracy of this model through the geometry of the associated polytope. ",On the Geometry and Extremal Properties of the Edge-Degeneracy Model
