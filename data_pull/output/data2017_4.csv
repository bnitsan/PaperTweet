,TweetID,AuthorID,AuthorName,Tweets,arxiv_link,Abstract,Title
0,859417596076183554,53931217,Tom Barclay,['In my new paper we predict @NASAWFIRST will find a dozen Mars-mass free-floating planets but no Earth-mass ones. <LINK>'],https://arxiv.org/abs/1704.08749,"Planets are thought to form via accretion from a remnant disk of gas and solids around a newly formed star. During this process material in the disk either remains bound to the star as part of either a planet, a smaller celestial body, or makes up part of the interplanetary medium; falls into the star; or is ejected from the system. Herein we use dynamical models to probe the abundance and properties of ejected material during late-stage planet formation and estimate their contribution to the free-floating planet population. We present 300 N-body simulations of terrestrial planet formation around a solar-type star, with and without giant planets present, using a model that accounts for collisional fragmentation. In simulations with Jupiter and Saturn analogs, about one-third of the initial (~5 Mearth) disk mass is ejected, about half in planets more massive than Mercury but less than 0.3 Mearth, and the remainder in smaller bodies. Most ejections occur within 25 Myr, which is shorter than the timescale typically required for Earth-mass planets to grow (30-100 Myr). When giant planets are omitted from our simulations, almost no material is ejected within 200 Myr and only about 1% of the initial disk is ejected by 2 Gyr. We show that about 2.5 terrestrial-mass planets are ejected per star in the Galaxy. We predict that the space-borne microlensing search for free-floating planets from the Wide-Field Infra-Red Space Telescope (WFIRST) will discover up to 15 Mars-mass planets, but few free-floating Earth-mass planets. ","The Demographics of Rocky Free-Floating Planets and their Detectability
  by WFIRST"
1,858843635915386880,53931217,Tom Barclay,"['I have a new paper: The Demographics of Rocky Free-Floating Planets and Their Detectability by WFIRST <LINK>', 'With big contributions from @elsisrad, @sraymond_astro and @emptypenny.']",https://arxiv.org/abs/1704.08749,"Planets are thought to form via accretion from a remnant disk of gas and solids around a newly formed star. During this process material in the disk either remains bound to the star as part of either a planet, a smaller celestial body, or makes up part of the interplanetary medium; falls into the star; or is ejected from the system. Herein we use dynamical models to probe the abundance and properties of ejected material during late-stage planet formation and estimate their contribution to the free-floating planet population. We present 300 N-body simulations of terrestrial planet formation around a solar-type star, with and without giant planets present, using a model that accounts for collisional fragmentation. In simulations with Jupiter and Saturn analogs, about one-third of the initial (~5 Mearth) disk mass is ejected, about half in planets more massive than Mercury but less than 0.3 Mearth, and the remainder in smaller bodies. Most ejections occur within 25 Myr, which is shorter than the timescale typically required for Earth-mass planets to grow (30-100 Myr). When giant planets are omitted from our simulations, almost no material is ejected within 200 Myr and only about 1% of the initial disk is ejected by 2 Gyr. We show that about 2.5 terrestrial-mass planets are ejected per star in the Galaxy. We predict that the space-borne microlensing search for free-floating planets from the Wide-Field Infra-Red Space Telescope (WFIRST) will discover up to 15 Mars-mass planets, but few free-floating Earth-mass planets. ","The Demographics of Rocky Free-Floating Planets and their Detectability
  by WFIRST"
2,858046901576491008,2800204849,Andrew Gordon Wilson,"['""Multimodal Word Distributions""\nOur new ACL 2017 paper, with code!\n<LINK>\nA distribution is worth aleph-1 word embeddings! <LINK>']",https://arxiv.org/abs/1704.08424,"Word embeddings provide point representations of words containing useful semantic information. We introduce multimodal word distributions formed from Gaussian mixtures, for multiple word meanings, entailment, and rich uncertainty information. To learn these distributions, we propose an energy-based max-margin objective. We show that the resulting approach captures uniquely expressive semantic information, and outperforms alternatives, such as word2vec skip-grams, and Gaussian embeddings, on benchmark datasets such as word similarity and entailment. ",Multimodal Word Distributions
3,857921379999633408,1937581884,Matthias KÃ¼mmerer,"['How to make saliency benchmarking consistent by separating models, maps and metrics. Our new paper is on arXiv!  <LINK> <LINK>']",https://arxiv.org/abs/1704.08615,"Dozens of new models on fixation prediction are published every year and compared on open benchmarks such as MIT300 and LSUN. However, progress in the field can be difficult to judge because models are compared using a variety of inconsistent metrics. Here we show that no single saliency map can perform well under all metrics. Instead, we propose a principled approach to solve the benchmarking problem by separating the notions of saliency models, maps and metrics. Inspired by Bayesian decision theory, we define a saliency model to be a probabilistic model of fixation density prediction and a saliency map to be a metric-specific prediction derived from the model density which maximizes the expected performance on that metric given the model density. We derive these optimal saliency maps for the most commonly used saliency metrics (AUC, sAUC, NSS, CC, SIM, KL-Div) and show that they can be computed analytically or approximated with high precision. We show that this leads to consistent rankings in all metrics and avoids the penalties of using one saliency map for all metrics. Our method allows researchers to have their model compete on many different metrics with state-of-the-art in those metrics: ""good"" models will perform well in all metrics. ","Saliency Benchmarking Made Easy: Separating Models, Maps and Metrics"
4,857901064594620418,267958924,Christian Ott,"[""New movie for J. Fedrow's binary black holes in stars paper (<LINK>). Now with density contours: <LINK>""]",https://arxiv.org/abs/1704.07383,"We present results from a controlled numerical experiment investigating the effect of stellar density gas on the coalescence of binary black holes (BBHs) and the resulting gravitational waves (GWs). This investigation is motivated by the proposed stellar core fragmentation scenario for BBH formation and the associated possibility of an electromagnetic counterpart to a BBH GW event. We employ full numerical relativity coupled with general-relativistic hydrodynamics and set up a $30 + 30 M_\odot$ BBH (motivated by GW150914) inside gas with realistic stellar densities. Our results show that at densities $\rho \gtrsim 10^6 - 10^7 \, \mathrm{g \, cm}^{-3}$ dynamical friction between the BHs and gas changes the coalescence dynamics and the GW signal in an unmistakable way. We show that for GW150914, LIGO observations conclusively rule out BBH coalescence inside stellar gas of $\rho \gtrsim 10^7 \, \mathrm{g\,cm}^{-3}$. Typical densities in the collapsing cores of massive stars are in excess of this density. This excludes the fragmentation scenario for the formation of GW150914. ",Gravitational Waves from Binary Black Hole Mergers Inside of Stars
5,857892308284563456,53888261,Dominic Horsman,['New paper dance! A graphical compiler language for lattice surgery on the surface code (with bonus category theory) <LINK>'],https://arxiv.org/abs/1704.08670,"A leading choice of error correction for scalable quantum computing is the surface code with lattice surgery. The basic lattice surgery operations, the merging and splitting of logical qubits, act non-unitarily on the logical states and are not easily captured by standard circuit notation. This raises the question of how best to design, verify, and optimise protocols that use lattice surgery, in particular in architectures with complex resource management issues. In this paper we demonstrate that the operations of the ZX calculus -- a form of quantum diagrammatic reasoning based on bialgebras -- match exactly the operations of lattice surgery. Red and green ""spider"" nodes match rough and smooth merges and splits, and follow the axioms of a dagger special associative Frobenius algebra. Some lattice surgery operations require non-trivial correction operations, which are captured natively in the use of the ZX calculus in the form of ensembles of diagrams. We give a first taste of the power of the calculus as a language for lattice surgery by considering two operations (T gates and producing a CNOT ) and show how ZX diagram re-write rules give lattice surgery procedures for these operations that are novel, efficient, and highly configurable. ",The ZX calculus is a language for surface code lattice surgery
6,857522221790658560,595554321,Jason D Lotay,['Hot off the press: my new paper with Tommaso Pacini on uniqueness and persistence of minimal Lagrangian submanifolds <LINK>'],https://arxiv.org/abs/1704.08226,"Given a minimal Lagrangian submanifold L in a negative Kaehler--Einstein manifold M, we show that any small Kaehler--Einstein perturbation of M induces a deformation of L which is minimal Lagrangian with respect to the new structure. This provides a new source of examples of minimal Lagrangians. More generally, the same is true for the larger class of totally real J-minimal submanifolds in Kaehler manifolds with negative definite Ricci curvature. ","From minimal Lagrangian to J-minimal submanifolds: persistence and
  uniqueness"
7,857498072280170496,512563003,Greig Cowan,['New paper from the @LHCbExperiment - observation of Î›0bâ†’Ï‡cJpKâˆ’ decays <LINK>. Next step: search for #pentaquarks <LINK>'],https://arxiv.org/abs/1704.07900,"The first observation of the decays $\Lambda_b^0 \to \chi_{c1} p K^-$ and $\Lambda_b^0 \to \chi_{c2} p K^-$ is reported using a data sample corresponding to an integrated luminosity of $3.0$ fb$^{-1}$, collected by the LHCb experiment in $pp$ collisions at centre-of-mass energies of 7 and 8 TeV. The following ratios of branching fractions are measured \begin{eqnarray*} \frac{{\cal B}(\Lambda_b^0 \to \chi_{c1} p K^-)}{{\cal B}(\Lambda_b^0 \to J/\psi p K^-)} = 0.242 \pm 0.014 \pm 0.013 \pm 0.009, \frac{{\cal B}(\Lambda_b^0 \to \chi_{c2} p K^-)}{{\cal B}(\Lambda_b^0 \to J/\psi p K^-)} = 0.248 \pm 0.020 \pm 0.014 \pm 0.009, \frac{{\cal B}(\Lambda_b^0 \to \chi_{c2} p K^-)}{{\cal B}(\Lambda_b^0 \to \chi_{c1} p K^-)} = 1.02 \pm 0.10 \pm 0.02 \pm 0.05, \end{eqnarray*} where the first uncertainty is statistical, the second systematic and the third due to the uncertainty on the branching fractions of the $\chi_{c1}\to J/\psi\gamma$ and $\chi_{c2} \to J/\psi\gamma$ decays. Using both decay modes, the mass of the $\Lambda_b^0$ baryon is also measured to be $m_{\Lambda_b^0} = 5619.44 \pm 0.28 \pm 0.26$ MeV/$c^2$, where the first and second uncertainties are statistical and systematic, respectively. ","Observation of the decays $\Lambda_b^0 \to \chi_{c1} p K^-$ and
  $\Lambda_b^0 \to \chi_{c2} p K^-$"
8,857487339874136064,339322327,Sebastian Neubert,['New paper! Observation of the decays $\\Lambda_b^0 \\to \\chi_{c1} p K^-$ and $\\Lambda_b^0 \\to \\chi_{c2} p K^-$. <LINK>'],http://arxiv.org/abs/1704.07900,"The first observation of the decays $\Lambda_b^0 \to \chi_{c1} p K^-$ and $\Lambda_b^0 \to \chi_{c2} p K^-$ is reported using a data sample corresponding to an integrated luminosity of $3.0$ fb$^{-1}$, collected by the LHCb experiment in $pp$ collisions at centre-of-mass energies of 7 and 8 TeV. The following ratios of branching fractions are measured \begin{eqnarray*} \frac{{\cal B}(\Lambda_b^0 \to \chi_{c1} p K^-)}{{\cal B}(\Lambda_b^0 \to J/\psi p K^-)} = 0.242 \pm 0.014 \pm 0.013 \pm 0.009, \frac{{\cal B}(\Lambda_b^0 \to \chi_{c2} p K^-)}{{\cal B}(\Lambda_b^0 \to J/\psi p K^-)} = 0.248 \pm 0.020 \pm 0.014 \pm 0.009, \frac{{\cal B}(\Lambda_b^0 \to \chi_{c2} p K^-)}{{\cal B}(\Lambda_b^0 \to \chi_{c1} p K^-)} = 1.02 \pm 0.10 \pm 0.02 \pm 0.05, \end{eqnarray*} where the first uncertainty is statistical, the second systematic and the third due to the uncertainty on the branching fractions of the $\chi_{c1}\to J/\psi\gamma$ and $\chi_{c2} \to J/\psi\gamma$ decays. Using both decay modes, the mass of the $\Lambda_b^0$ baryon is also measured to be $m_{\Lambda_b^0} = 5619.44 \pm 0.28 \pm 0.26$ MeV/$c^2$, where the first and second uncertainties are statistical and systematic, respectively. ","Observation of the decays $\Lambda_b^0 \to \chi_{c1} p K^-$ and
  $\Lambda_b^0 \to \chi_{c2} p K^-$"
9,856694300750495744,2210861,Jacob Andreas,"['New paper: ""translating"" hidden states of multiagent deep policies into English without parallel training data <LINK>', 'or, ""what do RNNs say to each other when nobody else is listening?""']",https://arxiv.org/abs/1704.06960,"Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents' messages by translating them. Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener. We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language. ",Translating Neuralese
10,856671180647833600,436376442,Mahdi Zarei,['My new paper  :)\nFeature selection algorithm .... to improve the performance of regression analysis\n<LINK>'],https://arxiv.org/abs/1704.06656,"In this paper we introduce a new feature selection algorithm to remove the irrelevant or redundant features in the data sets. In this algorithm the importance of a feature is based on its fitting to the Catastrophe model. Akaike information crite- rion value is used for ranking the features in the data set. The proposed algorithm is compared with well-known RELIEF feature selection algorithm. Breast Cancer, Parkinson Telemonitoring data and Slice locality data sets are used to evaluate the model. ","Feature selection algorithm based on Catastrophe model to improve the
  performance of regression analysis"
11,856666347555737605,48856249,Alex Wozniakowski,['New paper on the Covert Quantum Internet with Bradler and @gsiopsis <LINK> #QuantumInternet <LINK>'],https://arxiv.org/abs/1704.07281,"We apply covert quantum communication based on entanglement generated from the Minkowski vacuum to the setting of quantum computation and quantum networks. Our approach hides the generation and distribution of entanglement in quantum networks by taking advantage of relativistic quantum effects. We devise a suite of covert quantum teleportation protocols that utilize the shared entanglement, local operations, and covert classical communication to transfer or process quantum information in stealth. As an application of our covert suite, we construct two prominent examples of measurement-based quantum computation, namely the teleportation-based quantum computer and the one-way quantum computer. In the latter case we explore the covert generation of graph states, and subsequently outline a protocol for the covert implementation of universal blind quantum computation. ",Covert Quantum Internet
12,856644516975185920,2448147960,Jannes Gladrow ðŸ’‰ðŸ’‰ ðŸ’‰,['new paper on non-eq fluctuations of polymers &amp; how to identify them on @arxiv <LINK> #physics'],https://arxiv.org/abs/1704.06243,"Active dynamic processes of cells are largely driven by the cytoskeleton, a complex and adaptable semiflexible polymer network, motorized by mechanoenzymes. Small dimensions, confined geome- tries and hierarchical structures make it challenging to probe dynamics and mechanical response of such networks. Embedded semiflexible probe polymers can serve as non-perturbing multi-scale probes to detect force distributions in active polymer networks. We show here that motor-induced forces transmitted to the probe polymers are reflected in non-equilibrium bending dynamics, which we analyze in terms of spatial eigenmodes of an elastic beam. We demonstrate how these active forces induce correlations among these mode amplitudes, which furthermore break time-reversal symmetry. This leads to a breaking of detailed balance in this mode space. We derive analytical predictions for the magnitude of resulting probability currents in mode space in the white-noise limit of motor activity. We relate the structure of these currents to the spatial profile of motor- induced forces along the probe polymers and provide a general relation for observable currents on two-dimensional hyperplanes. ",Nonequilibrium dynamics of probe filaments in actin-myosin networks
13,855866051493605378,108821335,Jeff Brock,['New paper with Martin Bridgeman and Ken Bromberg. <LINK>'],https://arxiv.org/abs/1704.06021,"To a complex projective structure $\Sigma$ on a surface, Thurston associates a locally convex pleated surface. We derive bounds on the geometry of both in terms of the norms $\|\phi_\Sigma\|_\infty$ and $\|\phi_\Sigma\|_2$ of the quadratic differential $\phi_\Sigma$ of $\Sigma$ given by the Schwarzian derivative of the associated locally univalent map. We show that these give a unifying approach that generalizes a number of important, well known results for convex cocompact hyperbolic structures on 3-manifolds, including bounds on the Lipschitz constant for the nearest-point retraction and the length of the bending lamination. We then use these bounds to begin a study of the Weil-Petersson gradient flow of renormalized volume on the space $CC(N)$ of convex cocompact hyperbolic structures on a compact manifold $N$ with incompressible boundary, leading to a proof of the conjecture that the renormalized volume has infimum given by one-half the simplicial volume of $DN$, the double of $N$. ","Schwarzian derivatives, projective structures, and the Weil-Petersson
  gradient flow for renormalized volume"
14,855848707954286593,3433220662,Anthony Bonato,['Our new (old) paper on vertex pursuit games: Characterizations and algorithms for generalized Cops and Robbers games <LINK>'],https://arxiv.org/abs/1704.05655,"We propose a definition of generalized Cops and Robbers games where there are two players, the Pursuer and the Evader, who each move via prescribed rules. If the Pursuer can ensure that the game enters into a fixed set of final positions, then the Pursuer wins; otherwise, the Evader wins. A relational characterization of the games where the Pursuer wins is provided. A precise formula is given for the length of the game, along with an algorithm for computing if the Pursuer has a winning strategy whose complexity is a function of the parameters of the game. For games where the position of one player does not affect the available moves of he other, a vertex elimination ordering characterization, analogous to a cop-win ordering, is given for when the Pursuer has a winning strategy. ",Characterizations and algorithms for generalized Cops and Robbers games
15,855799212759535616,3433220662,Anthony Bonato,['Our new #networkscience paper - Common adversaries form alliances: modelling complex networks via anti-transitivity <LINK>'],https://arxiv.org/abs/1704.05658,"Anti-transitivity captures the notion that enemies of enemies are friends, and arises naturally in the study of adversaries in social networks and in the study of conflicting nation states or organizations. We present a simplified, evolutionary model for anti-transitivity influencing link formation in complex networks, and analyze the model's network dynamics. The Iterated Local Anti-Transitivity (or ILAT) model creates anti-clone nodes in each time-step, and joins anti-clones to the parent node's non-neighbor set. The graphs generated by ILAT exhibit familiar properties of complex networks such as densification, short distances (bounded by absolute constants), and bad spectral expansion. We determine the cop and domination number for graphs generated by ILAT, and finish with an analysis of their clustering coefficients. We interpret these results within the context of real-world complex networks and present open problems. ","Common adversaries form alliances: modelling complex networks via
  anti-transitivity"
16,855600608782536704,2888561271,Charles Tahan,"['Cliff notes for our new paper, <LINK> (or why you should do the experiment) <LINK>']",https://arxiv.org/abs/1704.05876,"We investigate coupling an encoded spin qubit to a microwave resonator via qubit energy level curvature versus gate voltage. This approach enables quantum non-demolition readout with strength of tens to hundred MHz all while the qubit stays at its full sweet-spot to charge noise, with zero dipole moment. A ""dispersive-like"" spin readout approach similar to circuit-QED but avoiding the Purcell effect is proposed. With the addition of gate voltage modulation, selective longitudinal readout and n-qubit entanglement-by-measurement are possible. ","Quantum-limited measurement of spin qubits via curvature coupling to a
  cavity"
17,855488761765003264,15831402,Eric Rowland,"['New paper on number theory of binomial coefficients. LOTS of people have studied them, but still new things to find <LINK>']",https://arxiv.org/abs/1704.05872,"In 1947 Nathan Fine gave a beautiful product for the number of binomial coefficients $\binom{n}{m}$, for $m$ in the range $0 \leq m \leq n$, that are not divisible by $p$. We give a matrix product that generalizes Fine's formula, simultaneously counting binomial coefficients with $p$-adic valuation $\alpha$ for each $\alpha \geq 0$. For each $n$ this information is naturally encoded in a polynomial generating function, and the sequence of these polynomials is $p$-regular in the sense of Allouche and Shallit. We also give a further generalization to multinomial coefficients. ",A matrix generalization of a theorem of Fine
18,855225265420677120,23724401,Daniel Jiang,['New paper on a Monte Carlo tree search algorithm that uses information relaxations  <LINK>'],http://arxiv.org/abs/1704.05963,"Monte Carlo Tree Search (MCTS), most famously used in game-play artificial intelligence (e.g., the game of Go), is a well-known strategy for constructing approximate solutions to sequential decision problems. Its primary innovation is the use of a heuristic, known as a default policy, to obtain Monte Carlo estimates of downstream values for states in a decision tree. This information is used to iteratively expand the tree towards regions of states and actions that an optimal policy might visit. However, to guarantee convergence to the optimal action, MCTS requires the entire tree to be expanded asymptotically. In this paper, we propose a new technique called Primal-Dual MCTS that utilizes sampled information relaxation upper bounds on potential actions, creating the possibility of ""ignoring"" parts of the tree that stem from highly suboptimal choices. This allows us to prove that despite converging to a partial decision tree in the limit, the recommended action from Primal-Dual MCTS is optimal. The new approach shows significant promise when used to optimize the behavior of a single driver navigating a graph while operating on a ride-sharing platform. Numerical experiments on a real dataset of 7,000 trips in New Jersey suggest that Primal-Dual MCTS improves upon standard MCTS by producing deeper decision trees and exhibits a reduced sensitivity to the size of the action space. ",Monte Carlo Tree Search with Sampled Information Relaxation Dual Bounds
19,855130105903034368,855118392348610560,Joost Huizinga,['My new paper on Canalization in Picbreeder Images is now available on arXiv: <LINK>.'],https://arxiv.org/abs/1704.05143,"Natural evolution has produced a tremendous diversity of functional organisms. Many believe an essential component of this process was the evolution of evolvability, whereby evolution speeds up its ability to innovate by generating a more adaptive pool of offspring. One hypothesized mechanism for evolvability is developmental canalization, wherein certain dimensions of variation become more likely to be traversed and others are prevented from being explored (e.g. offspring tend to have similarly sized legs, and mutations affect the length of both legs, not each leg individually). While ubiquitous in nature, canalization almost never evolves in computational simulations of evolution. Not only does that deprive us of in silico models in which to study the evolution of evolvability, but it also raises the question of which conditions give rise to this form of evolvability. Answering this question would shed light on why such evolvability emerged naturally and could accelerate engineering efforts to harness evolution to solve important engineering challenges. In this paper we reveal a unique system in which canalization did emerge in computational evolution. We document that genomes entrench certain dimensions of variation that were frequently explored during their evolutionary history. The genetic representation of these organisms also evolved to be highly modular and hierarchical, and we show that these organizational properties correlate with increased fitness. Interestingly, the type of computational evolutionary experiment that produced this evolvability was very different from traditional digital evolution in that there was no objective, suggesting that open-ended, divergent evolutionary processes may be necessary for the evolution of evolvability. ","The Emergence of Canalization and Evolvability in an Open-Ended,
  Interactive Evolutionary System"
20,854964993028227072,303343906,SÃ©bastien Carassou ðŸŒŽ,"['Astrofolks, our new paper is out! We unveil a new way to infer robust constraints on models of galaxy evolution. <LINK> <LINK>', 'Feedback is more than welcome! Especially from the stats community. We just started exploring Approximate Bayesian Computation techniques :)']",https://arxiv.org/abs/1704.05559,"Current constraints on models of galaxy evolution rely on morphometric catalogs extracted from multi-band photometric surveys. However, these catalogs are altered by selection effects that are difficult to model, that correlate in non trivial ways, and that can lead to contradictory predictions if not taken into account carefully. To address this issue, we have developed a new approach combining parametric Bayesian indirect likelihood (pBIL) techniques and empirical modeling with realistic image simulations that reproduce a large fraction of these selection effects. This allows us to perform a direct comparison between observed and simulated images and to infer robust constraints on model parameters. We use a semi-empirical forward model to generate a distribution of mock galaxies from a set of physical parameters. These galaxies are passed through an image simulator reproducing the instrumental characteristics of any survey and are then extracted in the same way as the observed data. The discrepancy between the simulated and observed data is quantified, and minimized with a custom sampling process based on adaptive Monte Carlo Markov Chain methods. Using synthetic data matching most of the properties of a CFHTLS Deep field, we demonstrate the robustness and internal consistency of our approach by inferring the parameters governing the size and luminosity functions and their evolutions for different realistic populations of galaxies. We also compare the results of our approach with those obtained from the classical spectral energy distribution fitting and photometric redshift approach.Our pipeline infers efficiently the luminosity and size distribution and evolution parameters with a very limited number of observables (3 photometric bands). When compared to SED fitting based on the same set of observables, our method yields results that are more accurate and free from systematic biases. ","Inferring the photometric and size evolution of galaxies from image
  simulations"
21,854879336385478657,988221020,Asli Celikyilmaz,['Check out our new paper on Hierarchical Deep Reinforcement Learning for dialog modelling on arxiv! <LINK>'],https://arxiv.org/abs/1704.03084,"Building a dialogue agent to fulfill complex tasks, such as travel planning, is challenging because the agent has to learn to collectively complete multiple subtasks. For example, the agent needs to reserve a hotel and book a flight so that there leaves enough time for commute between arrival and hotel check-in. This paper addresses this challenge by formulating the task in the mathematical framework of options over Markov Decision Processes (MDPs), and proposing a hierarchical deep reinforcement learning approach to learning a dialogue manager that operates at different temporal scales. The dialogue manager consists of: (1) a top-level dialogue policy that selects among subtasks or options, (2) a low-level dialogue policy that selects primitive actions to complete the subtask given by the top-level policy, and (3) a global state tracker that helps ensure all cross-subtask constraints be satisfied. Experiments on a travel planning task with simulated and real users show that our approach leads to significant improvements over three baselines, two based on handcrafted rules and the other based on flat deep reinforcement learning. ","Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep
  Reinforcement Learning"
22,854776785560416256,580031141,"James Davenport, PhD","[""Checkout this new paper by @sjs917 @stephtdouglas et al. on gender in astro Q/A's @ smaller meetings!\n<LINK>""]",https://arxiv.org/abs/1704.05260,"We examine the gender balance of the 18th and 19th meetings of the Cambridge Workshop on Cool Stellar Systems and the Sun (CS18 and CS19). The percent of female attendees at both meetings (31% at CS18 and 37% at CS19) was higher than the percent of women in the American Astronomical Society (25%) and the International Astronomical Union (18%). The representation of women in Cool Stars as SOC members, invited speakers, and contributed speakers was similar to or exceeded the percent of women attending the meetings. We requested that conference attendees assist in a project to collect data on the gender of astronomers asking questions after talks. Using this data, we found that men were over-represented (and women were under-represented) in the question sessions after each talk. Men asked 79% of the questions at CS18 and 75% of the questions at CS19, but were 69% and 63% of the attendees respectively. Contrary to findings from previous conferences, we did not find that the gender balance of questions was strongly affected by the session chair gender, the speaker gender, or the length of the question period. We also found that female and male speakers were asked a comparable number of questions after each talk. The contrast of these results from previous incarnations of the gender questions survey indicate that more data would be useful in understanding the factors that contribute to the gender balance of question askers. We include a preliminary set of recommendations based on this and other work on related topics, but also advocate for additional research on the demographics of conference participants. Additional data on the intersection of gender with race, seniority, sexual orientation, ability and other marginalized identities is necessary to fully address the role of gender in asking questions at conferences. ",The Role of Gender in Asking Questions at Cool Stars 18 and 19
23,854322466193387520,185910194,Graham Neubig,"['New #ACL2017 paper on teaching neural nets to read Chinese, Japanese, and Korean from pixels!: <LINK> <LINK>']",https://arxiv.org/abs/1704.04859,"Previous work has modeled the compositionality of words by creating character-level models of meaning, reducing problems of sparsity for rare words. However, in many writing systems compositionality has an effect even on the character-level: the meaning of a character is derived by the sum of its parts. In this paper, we model this effect by creating embeddings for characters based on their visual characteristics, creating an image for the character and running it through a convolutional neural network to produce a visual character embedding. Experiments on a text classification task demonstrate that such model allows for better processing of instances with rare characters in languages such as Chinese, Japanese, and Korean. Additionally, qualitative analyses demonstrate that our proposed model learns to focus on the parts of characters that carry semantic content, resulting in embeddings that are coherent in visual space. ",Learning Character-level Compositionality with Visual Features
24,854235403259392002,22392129,Jasmijn Bastings,['Our new paper: Graph Convolutional Encoders for Syntax-aware Neural Machine Translation\n<LINK>\n(syntax wo hard constraints) <LINK>'],https://arxiv.org/abs/1704.04675,"We present a simple and effective approach to incorporating syntactic structure into neural attention-based encoder-decoder models for machine translation. We rely on graph-convolutional networks (GCNs), a recent class of neural networks developed for modeling graph-structured data. Our GCNs use predicted syntactic dependency trees of source sentences to produce representations of words (i.e. hidden states of the encoder) that are sensitive to their syntactic neighborhoods. GCNs take word representations as input and produce word representations as output, so they can easily be incorporated as layers into standard encoders (e.g., on top of bidirectional RNNs or convolutional neural networks). We evaluate their effectiveness with English-German and English-Czech translation experiments for different types of encoders and observe substantial improvements over their syntax-agnostic versions in all the considered setups. ",Graph Convolutional Encoders for Syntax-aware Neural Machine Translation
25,854141763409391616,148639030,Felix Juefei Xu,['Our new paper on improving the Wasserstein GAN with a maximum margin ranking loss and progressive training!!\n<LINK>'],https://arxiv.org/abs/1704.04865,"Traditional generative adversarial networks (GAN) and many of its variants are trained by minimizing the KL or JS-divergence loss that measures how close the generated data distribution is from the true data distribution. A recent advance called the WGAN based on Wasserstein distance can improve on the KL and JS-divergence based GANs, and alleviate the gradient vanishing, instability, and mode collapse issues that are common in the GAN training. In this work, we aim at improving on the WGAN by first generalizing its discriminator loss to a margin-based one, which leads to a better discriminator, and in turn a better generator, and then carrying out a progressive training paradigm involving multiple GANs to contribute to the maximum margin ranking loss so that the GAN at later stages will improve upon early stages. We call this method Gang of GANs (GoGAN). We have shown theoretically that the proposed GoGAN can reduce the gap between the true data distribution and the generated data distribution by at least half in an optimally trained WGAN. We have also proposed a new way of measuring GAN quality which is based on image completion tasks. We have evaluated our method on four visual datasets: CelebA, LSUN Bedroom, CIFAR-10, and 50K-SSFF, and have seen both visual and quantitative improvement over baseline WGAN. ","Gang of GANs: Generative Adversarial Networks with Maximum Margin
  Ranking"
26,853898167661715456,460069521,Andrew Francis,"['New paper on drug resistance in TB, using approx Bayesian computation (ABC). To appear in the Handbook of ABC:  <LINK>', 'Joint with Mark Tanaka, Scott Sisson (@ABC_research), and talented PhD student Guillherme Rodriguez.  What a team!']",https://arxiv.org/abs/1704.04355,"We investigate the rates of drug resistance acquisition in a natural population using molecular epidemiological data from Bolivia. First, we study the rate of direct acquisition of double resistance from the double sensitive state within patients and compare it to the rates of evolution to single resistance. In particular, we address whether or not double resistance can evolve directly from a double sensitive state within a given host. Second, we aim to understand whether the differences in mutation rates to rifampicin and isoniazid resistance translate to the epidemiological scale. Third, we estimate the proportion of MDR TB cases that are due to the transmission of MDR strains compared to acquisition of resistance through evolution. To address these problems we develop a model of TB transmission in which we track the evolution of resistance to two drugs and the evolution of VNTR loci. However, the available data is incomplete, in that it is recorded only {for a fraction of the population and} at a single point in time. The likelihood function induced by the proposed model is computationally prohibitive to evaluate and accordingly impractical to work with directly. We therefore approach statistical inference using approximate Bayesian computation techniques. ","Inferences on the acquisition of multidrug resistance in
  \emph{Mycobacterium tuberculosis} using molecular epidemiological data"
27,853890193744678912,741121173472333824,Wang Ruohan,"['MAGAN: Margin Adaptation for Adversarial Networks, our new paper on auto-encoder based GAN.\n\n<LINK>\n<LINK>']",https://arxiv.org/abs/1704.03817,"We propose the Margin Adaptation for Generative Adversarial Networks (MAGANs) algorithm, a novel training procedure for GANs to improve stability and performance by using an adaptive hinge loss function. We estimate the appropriate hinge loss margin with the expected energy of the target distribution, and derive principled criteria for when to update the margin. We prove that our method converges to its global optimum under certain assumptions. Evaluated on the task of unsupervised image generation, the proposed training procedure is simple yet robust on a diverse set of data, and achieves qualitative and quantitative improvements compared to the state-of-the-art. ",MAGAN: Margin Adaptation for Generative Adversarial Networks
28,853362061220487170,3336393142,Dr. Elizabeth A. Silber,['A product of great international collaboration is our new paper on shockwaves &amp; overdense #meteors <LINK>. @RoyalAstroSoc'],https://arxiv.org/abs/1704.03830,"Studies of meteor trails have until now been limited to relatively simple models, with the trail often being treated as a conducting cylinder, and the head (if considered at all) treated as a ball of ionized gas. In this article, we bring the experience gleaned in other fields to the domain of meteor studies, and adapt this prior knowledge to give a much clearer view of the microscale physics and chemistry involved in meteor-trail formation, with particular emphasis on the first 100 or so milliseconds of the trail formation. We discuss and examine the combined physico-chemical effects of meteor-generated and ablationally amplified cylindrical shock waves which appear in the ambient atmosphere immediately surrounding the meteor train, as well as the associated hyperthermal chemistry on the boundaries of the high temperature postadiabatically expanding meteor train. We demonstrate that the cylindrical shock waves produced by overdense meteors are sufficiently strong to dissociate molecules in the ambient atmosphere when it is heated to temperatures in the vicinity of 6,000 K, which substantially alters the considerations of the chemical processes in and around the meteor train. We demonstrate that some ambient O2, along with O2 that comes from the shock dissociation of O3, survives the passage of the cylindrical shock wave, and these constituents react thermally with meteor metal ions, thereby subsequently removing electrons from the overdense meteor train boundary through fast, temperature independent, dissociative recombination governed by the second Damkohler number. Possible implications for trail diffusion and lifetimes are discussed. ","On Shock Waves and the Role of Hyperthermal Chemistry in the Early
  Diffusion of Overdense Meteor Trains"
29,853298882025009152,164964871,"Devinder Kumar, PhD",['New paper: <LINK>\nExplaining the Unexplained: CLass-Enhancd Attntive Respnse(CLEAR) Approach to Undrstndng Deep Neural Net'],http://arxiv.org/abs/1704.04133v1,"In this work, we propose CLass-Enhanced Attentive Response (CLEAR): an approach to visualize and understand the decisions made by deep neural networks (DNNs) given a specific input. CLEAR facilitates the visualization of attentive regions and levels of interest of DNNs during the decision-making process. It also enables the visualization of the most dominant classes associated with these attentive regions of interest. As such, CLEAR can mitigate some of the shortcomings of heatmap-based methods associated with decision ambiguity, and allows for better insights into the decision-making process of DNNs. Quantitative and qualitative experiments across three different datasets demonstrate the efficacy of CLEAR for gaining a better understanding of the inner workings of DNNs during the decision-making process. ","] Explaining the Unexplained: A CLass-Enhanced Attentive Response (CLEAR)
  Approach to Understanding Deep Neural Networks"
30,852677291297488896,101980926,Masahito Yamazaki,"['My new paper: ""BPS Graphs: From Spectral Networks to BPS Quivers""\n<LINK>']",https://arxiv.org/abs/1704.04204,"We define ""BPS graphs"" on punctured Riemann surfaces associated with $A_{N-1}$ theories of class $\mathcal{S}$. BPS graphs provide a bridge between two powerful frameworks for studying the spectrum of BPS states: spectral networks and BPS quivers. They arise from degenerate spectral networks at maximal intersections of walls of marginal stability on the Coulomb branch. While the BPS spectrum is ill-defined at such intersections, a BPS graph captures a useful basis of elementary BPS states. The topology of a BPS graph encodes a BPS quiver, even for higher-rank theories and for theories with certain partial punctures. BPS graphs lead to a geometric realization of the combinatorics of Fock-Goncharov $N$-triangulations and generalize them in several ways. ",BPS Graphs: From Spectral Networks to BPS Quivers
31,852472816263983106,158659687,Sibylle Anderl,"[""We've published a new paper with exciting results based on the OI emission of shocks in Cep E observed with SOFIA! <LINK>"", '@SebFreitag BlÃ¶de Autokorrektur :(']",http://arxiv.org/abs/1704.03796,"Protostellar jets and outflows are key features of the star-formation process, and primary processes of the feedback of young stars on the interstellar medium. Understanding the underlying shocks is necessary to explain how jets and outflows are launched, and to quantify their chemical and energetic impacts on the surrounding medium. We performed a high-spectral resolution study of the [OI]$_{\rm 63 \mu m}$ emission in the outflow of the intermediate-mass Class 0 protostar Cep E-mm. We present observations of the OI $^3$P$_1 \rightarrow$ $^3$P$_2$, OH between $^2\Pi_{1/2}$ $J = 3/2$ and $J = 1/2$ at 1837.8 GHz, and CO (16-15) lines with SOFIA-GREAT at three positions in the Cep E outflow: mm (the driving protostar), BI (in the southern lobe), and BII (the terminal position in the southern lobe). The CO line is detected at all three positions. The OI line is detected in BI and BII, whereas the OH line is not detected. In BII, we identify three kinematical components in OI and CO, already detected in CO: the jet, the HH377 terminal bow-shock, and the outflow cavity. The OI column density is higher in the outflow cavity than in the jet, which itself is higher than in the terminal shock. The terminal shock is where the abundance ratio of OI to CO is the lowest (about 0.2), whereas the jet component is atomic (ratio $\sim$2.7). In the jet, we compare the OI observations with shock models that successfully fit the integrated intensity of 10 CO lines: these models do not fit the OI data. The high intensity of OI emission points towards the propagation of additional dissociative or alternative FUV-irradiated shocks, where the illumination comes from the shock itself. From the sample of low-to-high mass protostellar outflows where similar observations have been performed, the effects of illumination seem to increase with the mass of the protostar. ","Nature of shocks revealed by SOFIA OI observations in the Cepheus E
  protostellar outflow"
32,852092371068125184,3403213937,Paul MolliÃ¨re,"[""Exciting paper by Matthias Samland, on #exoplanet 51 Eri b, w/ new data from #VLT's #SPHERE &amp; my #petitCODE models! <LINK>""]",https://arxiv.org/abs/1704.02987,"51 Eridani b is an exoplanet around a young (20 Myr) nearby (29.4 pc) F0-type star, recently discovered by direct imaging. Being only 0.5"" away from its host star it is well suited for spectroscopic analysis using integral field spectrographs. We aim to refine the atmospheric properties of this and to further constrain the architecture of the system by searching for additional companions. Using the SPHERE instrument at the VLT we extend the spectral coverage of the planet to the complete Y- to H-band range and provide photometry in the K12-bands (2.11, 2.25 micron). The object is compared to other cool and peculiar dwarfs. Furthermore, the posterior probability distributions of cloudy and clear atmospheric models are explored using MCMC. We verified our methods by determining atmospheric parameters for the two benchmark brown dwarfs Gl 570D and HD 3651B. For probing the innermost region for additional companions, archival VLT-NACO (L') SAM data is used. We present the first spectrophotometric measurements in the Y- and K-bands for the planet and revise its J-band flux to values 40% fainter than previous measurements. Cloudy models with uniform cloud coverage provide a good match to the data. We derive the temperature, radius, surface gravity, metallicity and cloud sedimentation parameter f_sed. We find that the atmosphere is highly super-solar (Fe/H~1.0) with an extended, thick cloud cover of small particles. The model radius and surface gravity suggest planetary masses of about 9 M_jup. The evolutionary model only provides a lower mass limit of >2 M_jup (for pure hot-start). The cold-start model cannot explain the planet's luminosity. The SPHERE and NACO/SAM detection limits probe the 51 Eri system at Solar System scales and exclude brown-dwarf companions more massive than 20 M_jup beyond separations of ~2.5 au and giant planets more massive than 2 M_jup beyond 9 au. ","Spectral and atmospheric characterization of 51 Eridani b using
  VLT/SPHERE"
33,852079164920352768,377431987,Jorge P. RodrÃ­guez,"['Cooperation between diseases, both for reception and transmission: you can check details in our new paper in arxiv <LINK>']",https://arxiv.org/abs/1704.03294,"We propose a fully cooperative coinfection model in which singly infected individuals are more likely to acquire a second disease than those who are susceptible, and doubly infected individuals are also assumed to be more contagious than those infected with one disease. The dynamics of such fully cooperative coinfection model between two interacting infectious diseases is investigated through well-mixed and network-based approaches. We show that the former approach exhibits three types of hysteresis, namely, $C$, $S_l$ and $S_r$ types, where the last two types have not been identified before. The first (resp., the second and the third) type exhibits (resp., exhibit) discontinuous outbreak transition from the disease free (resp., low prevalence) state to the high prevalence state when a transmission rate crosses a threshold from the below. Moreover, the third (resp., the first and the second) type possesses (resp., possess) discontinuous eradication transition from the high prevalence state to the low prevalence (resp., disease free) state when the transmission rate reaches a threshold from the above. Complete characterization of these three types of hysteresis in term of parameters measuring the uniformity of the model is also provided. Finally, we assess numerically this epidemic dynamics in random networks. ",Diversity of hysteresis in a fully cooperative coinfection model
34,852027966783488003,2425754287,Roman Orus,['New paper out! Simulating (1+1)d QED and prospects for (2+1)d <LINK>'],https://arxiv.org/abs/1704.03015,"The simulation of lattice gauge theories with tensor network (TN) methods is becoming increasingly fruitful. The vision is that such methods will, eventually, be used to simulate theories in $(3+1)$ dimensions in regimes difficult for other methods. So far, however, TN methods have mostly simulated lattice gauge theories in $(1+1)$ dimensions. The aim of this paper is to explore the simulation of quantum electrodynamics (QED) on infinite lattices with TNs, i.e., fermionic matter fields coupled to a $U(1)$ gauge field, directly in the thermodynamic limit. With this idea in mind we first consider a gauge-invariant iDMRG simulation of the Schwinger model -i.e., QED in $(1+1)d$-. After giving a precise description of the numerical method, we benchmark our simulations by computing the substracted chiral condensate in the continuum, in good agreement with other approaches. Our simulations of the Schwinger model allow us to build intuition about how a simulation should proceed in $(2+1)$ dimensions. Based on this, we propose a variational ansatz using infinite Projected Entangled Pair States (PEPS) to describe the ground state of $(2+1)d$ QED. The ansatz includes $U(1)$ gauge symmetry at the level of the tensors, as well as fermionic (matter) and bosonic (gauge) degrees of freedom both at the physical and virtual levels. We argue that all the necessary ingredients for the simulation of $(2+1)d$ QED are, a priori, already in place, paving the way for future upcoming results. ","Tensor network simulation of QED on infinite lattices: learning from
  (1+1)d, and prospects for (2+1)d"
35,851953092404838403,101980926,Masahito Yamazaki,"['Our new paper, on the proof of sum/integral transformation formulas for ""lens"" elliptic gamma function!\n<LINK>']",https://arxiv.org/abs/1704.03159,"We prove a pair of transformation formulas for multivariate elliptic hypergeometric sum/integrals associated to the $A_n$ and $BC_n$ root systems, generalising the formulas previously obtained by Rains. The sum/integrals are expressed in terms of the lens elliptic gamma function, a generalisation of the elliptic gamma function that depends on an additional integer variable, as well as a complex variable and two elliptic nomes. As an application of our results, we prove an equality between $S^1\times S^3/\mathbb{Z}_r$ supersymmetric indices, for a pair of four-dimensional $\mathcal{N}=1$ supersymmetric gauge theories related by Seiberg duality, with gauge groups $SU(n+1)$ and $Sp(2n)$. This provides one of the most elaborate checks of the Seiberg duality known to date. As another application of the $A_n$ integral, we prove a star-star relation for a two-dimensional integrable lattice model of statistical mechanics, previously given by the second author. ","Elliptic hypergeometric sum/integral transformations and supersymmetric
  lens index"
36,851720661739466752,2676457430,MAGIC telescopes ðŸŒ´ðŸŒº,['MAGIC performance under the moonlight in the new MAGIC paper <LINK>. Photo credit MAGIC and moon Adiv Gonzalez. <LINK>'],http://arxiv.org/abs/1704.00906,"MAGIC, a system of two imaging atmospheric Cherenkov telescopes, achieves its best performance under dark conditions, i.e. in absence of moonlight or twilight. Since operating the telescopes only during dark time would severely limit the duty cycle, observations are also performed when the Moon is present in the sky. Here we develop a dedicated Moon-adapted analysis to characterize the performance of MAGIC under moonlight. We evaluate energy threshold, angular resolution and sensitivity of MAGIC under different background light levels, based on Crab Nebula observations and tuned Monte Carlo simulations. This study includes observations taken under non-standard hardware configurations, such as reducing the camera photomultiplier tubes gain by a factor ~1.7 (Reduced HV settings) with respect to standard settings (Nominal HV) or using UV-pass filters to strongly reduce the amount of moonlight reaching the cameras of the telescopes. The Crab Nebula spectrum is correctly reconstructed in all the studied illumination levels, that reach up to 30 times brighter than under dark conditions. The main effect of moonlight is an increase in the analysis energy threshold and in the systematic uncertainties on the flux normalization. The sensitivity degradation is constrained to be below 10%, within 15-30% and between 60 and 80% for Nominal HV, Reduced HV and UV-pass filter observations, respectively. No worsening of the angular resolution was found. Thanks to observations during moonlight, the maximal duty cycle of MAGIC can be increased from ~18%, under dark nights only, to up to ~40% in total with only moderate performance degradation. ",Performance of the MAGIC telescopes under moonlight
37,851618122364665856,767659609,Yoshihiko Hasegawa,['I uploaded my new paper to arXiv <LINK>'],https://arxiv.org/abs/1704.02564,"Cells receive signaling molecules by receptors and relay information via sensory networks so that they can respond properly depending on the type of signal. Recent studies have shown that cells can extract multi-dimensional information from dynamical concentration patterns of signaling molecules. We herein study how biochemical systems can process multi-dimensional information embedded in dynamical patterns. We model the decoding networks by linear response functions, and optimize the functions with the calculus of variations to maximize the mutual information between patterns and output. We find that, when the noise intensity is lower, decoders with different linear response functions, i.e., distinct decoders, can extract much information. However, when the noise intensity is higher, distinct decoders do not provide the maximum amount of information. This indicates that, when transmitting information by dynamical patterns, embedding information in multiple patterns is not optimal when the noise intensity is very large. Furthermore, we explore the biochemical implementations of these decoders using control theory and demonstrate that these decoders can be implemented biochemically through the modification of cascade-type networks, which are prevalent in actual signaling pathways. ","Multi-dimensional biochemical information processing of dynamical
  patterns"
38,851107747085123586,3000107776,Douglas Boubert,['I found the perfect lager to celebrate my new paper about hypervelocity stars from a different galaxy! <LINK> @ChurchillCol <LINK>'],https://arxiv.org/abs/1704.01373,"We explore the possibility that the observed population of Galactic hypervelocity stars (HVSs) originate as runaway stars from the Large Magellanic Cloud (LMC). Pairing a binary evolution code with an N-body simulation of the interaction of the LMC with the Milky Way, we predict the spatial distribution and kinematics of an LMC runaway population. We find that runaway stars from the LMC can contribute Galactic HVSs at a rate of $3 \times 10^{-6}\;\mathrm{yr}^{-1}$. This is composed of stars at different points of stellar evolution, ranging from the main-sequence to those at the tip of the asymptotic giant branch. We find that the known B-type HVSs have kinematics which are consistent with an LMC origin. There is an additional population of hypervelocity white dwarfs whose progenitors were massive runaway stars. Runaways which are even more massive will themselves go supernova, producing a remnant whose velocity will be modulated by a supernova kick. This latter scenario has some exotic consequences, such as pulsars and supernovae far from star-forming regions, and a small rate of microlensing from compact sources around the halo of the LMC. ",Hypervelocity runaways from the Large Magellanic Cloud
39,850340343400869888,185910194,Graham Neubig,"[""New #ACL2017 paper on neural nets to translate English commands to Python programs by exploiting the code's syntax! <LINK> <LINK>"", ""@zehavoc Thanks! I'm pretty excited by this direction.""]",https://arxiv.org/abs/1704.01696,"We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches. ",A Syntactic Neural Model for General-Purpose Code Generation
40,849573295913660416,547776192,Chris Lovell,"['New paper with me name on it:\n""The properties of the first galaxies in the BLUETIDES simulation""\n<LINK>']",https://arxiv.org/abs/1704.00954v1,"We employ the very large cosmological hydrodynamical simulation BLUETIDES to investigate the predicted properties of the galaxy population during the epoch of reionisation ($z>8$). BLUETIDES has a resolution and volume ($(400/h\approx 577)^{3}\,{\rm cMpc^3}$) providing a population of galaxies which is well matched to depth and area of current observational surveys targeting the high-redshift Universe. At $z=8$ BLUETIDES includes almost 160,000 galaxies with stellar masses $>10^{8}\,{\rm M_{\odot}}$. The population of galaxies predicted by BLUETIDES closely matches observational constraints on both the galaxy stellar mass function and far-UV ($150\,{\rm nm}$) luminosity function. Galaxies in BLUETIDES are characterised by rapidly increasing star formation histories. Specific star formation rates decrease with redshift though remain largely insensitive to stellar mass. As a result of the enhanced surface density of metals more massive galaxies are predicted to have higher dust attenuation resulting in a significant steepening of the observed far-UV luminosity function at high luminosities. The contribution of active SMBHs to the UV luminosities of galaxies with stellar masses $10^{9-10}\,{\rm M_{\odot}}$ is around $3\%$ on average. Approximately $25\%$ of galaxies with $M_{*}\approx 10^{10}\,{\rm M_{\odot}}$ are predicted to have active SMBH which contribute $>10\%$ of the total UV luminosity. ",] The properties of the first galaxies in the BLUETIDES simulation
41,849536818206953473,1523174335,Kolja Kleineberg,['Heterogeneity does not always favor--but can even hinder--cooperation in social dilemmas. New paper <LINK> @FuturICT @cxdig <LINK>'],https://arxiv.org/abs/1704.00952,"The evolution of cooperation in social dilemmas in structured populations has been studied extensively in recent years. Whereas many theoretical studies have found that a heterogeneous network of contacts favors cooperation, the impact of spatial effects in scale-free networks is still not well understood. In addition to being heterogeneous, real contact networks exhibit a high mean local clustering coefficient, which implies the existence of an underlying metric space. Here, we show that evolutionary dynamics in scale-free networks self-organize into spatial patterns in the underlying metric space. The resulting metric clusters of cooperators are able to survive in social dilemmas as their spatial organization shields them from surrounding defectors, similar to spatial selection in Euclidean space. We show that under certain conditions these metric clusters are more efficient than the most connected nodes at sustaining cooperation and that heterogeneity does not always favor--but can even hinder--cooperation in social dilemmas. Our findings provide a new perspective to understand the emergence of cooperation in evolutionary games in realistic structured populations. ",Metric clusters in evolutionary games on scale-free networks
42,849453220963524608,101980926,Masahito Yamazaki,"['Submitted a new paper on volume conjecture, with Dongmin and Mauricio!\n<LINK>\nä½“ç©äºˆæƒ³ã®è«–æ–‡ã¯å®Ÿã¯åˆã‚ã¦ï¼Œæ•°å€¤è¨ˆç®—ã‚‚ã§ãã‚‹ã®ã§åƒ•ã‚‰ã®äºˆæƒ³ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã¿ã¦ä¸‹ã•ã„ï¼Ž']",http://arxiv.org/abs/1704.00918,"We propose an extension of the recently-proposed volume conjecture for closed hyperbolic 3-manifolds, to all orders in perturbative expansion. We first derive formulas for the perturbative expansion of the partition function of complex Chern-Simons theory around a hyperbolic flat connection, which produces infinitely-many perturbative invariants of the closed oriented 3-manifold. The conjecture is that this expansion coincides with the perturbative expansion of the Witten-Reshetikhin-Turaev invariants at roots of unity $q=e^{2 \pi i/r}$ with $r$ odd, in the limit $r \to \infty$. We provide numerical evidence for our conjecture. ","All-Order Volume Conjecture for Closed 3-Manifolds from Complex
  Chern-Simons Theory"
43,849418891436675072,139709337,David Dumas,['New research paper with Andrew Sanders:  <LINK>'],https://arxiv.org/abs/1704.01091,"We study the topology and geometry of compact complex manifolds associated to Anosov representations of surface groups and other hyperbolic groups in a complex semisimple Lie group $G$. These manifolds are obtained as quotients of the domains of discontinuity in generalized flag varieties $G/P$ constructed by Kapovich-Leeb-Porti (arXiv:1306.3837), and in some cases by Guichard-Wienhard (arXiv:1108.0733). For $G$-Fuchsian representations and their Anosov deformations, where $G$ is simple, we compute the homology of the domains of discontinuity and of the quotient manifolds. For $G$-Fuchsian and $G$-quasi-Fuchsian representations in simple $G$ of rank at least two, we show that the quotient manifolds are not K\""{a}hler. We also describe the Picard groups of these quotient manifolds, compute the cohomology of line bundles on them, and show that for $G$ of sufficiently large rank these manifolds admit nonconstant meromorphic functions. In a final section, we apply our topological results to several explicit families of domains and derive closed formulas for topological invariants in some cases. We also show that the quotient manifold for a $G$-Fuchsian representation in $\mathrm{PSL}_3(\mathbb{C})$ is a fiber bundle over a surface, and we conjecture that this holds for all simple $G$. ","Geometry of compact complex manifolds associated to generalized
  quasi-Fuchsian representations"
44,849412538773229569,837133583558987776,Colin Raffel,"['My new paper, ""Online and Linear-Time Attention by Enforcing Monotonic Alignments"", is online! <LINK>', 'Shows how hard monotonic attention provides online+linear-time seq2seq models; derives an algorithm for training in expectation w/ backprop.', 'Simple to swap out with softmax-attention, and an example @tensorflow implementation is available: https://t.co/vFevyXZohV', '.@tensorflow Co-authored with @lmthang @douglas_eck Peter J. Liu and Ron Weiss']",https://arxiv.org/abs/1704.00784,"Recurrent neural network models with an attention mechanism have proven to be extremely effective on a wide variety of sequence-to-sequence problems. However, the fact that soft attention mechanisms perform a pass over the entire input sequence when producing each element in the output sequence precludes their use in online settings and results in a quadratic time complexity. Based on the insight that the alignment between input and output sequence elements is monotonic in many problems of interest, we propose an end-to-end differentiable method for learning monotonic alignments which, at test time, enables computing attention online and in linear time. We validate our approach on sentence summarization, machine translation, and online speech recognition problems and achieve results competitive with existing sequence-to-sequence models. ",Online and Linear-Time Attention by Enforcing Monotonic Alignments
45,849165331927117824,365363143,Lars MaalÃ¸e,['Check out our new paper on semi-supervised generative modelling. <LINK>'],https://arxiv.org/abs/1704.00637,"Deep generative models trained with large amounts of unlabelled data have proven to be powerful within the domain of unsupervised learning. Many real life data sets contain a small amount of labelled data points, that are typically disregarded when training generative models. We propose the Cluster-aware Generative Model, that uses unlabelled information to infer a latent representation that models the natural clustering of the data, and additional labelled data points to refine this clustering. The generative performances of the model significantly improve when labelled information is exploited, obtaining a log-likelihood of -79.38 nats on permutation invariant MNIST, while also achieving competitive semi-supervised classification accuracies. The model can also be trained fully unsupervised, and still improve the log-likelihood performance with respect to related methods. ",Semi-Supervised Generation with Cluster-aware Generative Models
46,849097155717586944,1858779979,Meysam Alizadeh,"['Our new paper ""Psychological and Personality Profiles of Political Extremists"" with @ingmarweber @santo_fortunato <LINK>']",https://arxiv.org/abs/1704.00119,"Global recruitment into radical Islamic movements has spurred renewed interest in the appeal of political extremism. Is the appeal a rational response to material conditions or is it the expression of psychological and personality disorders associated with aggressive behavior, intolerance, conspiratorial imagination, and paranoia? Empirical answers using surveys have been limited by lack of access to extremist groups, while field studies have lacked psychological measures and failed to compare extremists with contrast groups. We revisit the debate over the appeal of extremism in the U.S. context by comparing publicly available Twitter messages written by over 355,000 political extremist followers with messages written by non-extremist U.S. users. Analysis of text-based psychological indicators supports the moral foundation theory which identifies emotion as a critical factor in determining political orientation of individuals. Extremist followers also differ from others in four of the Big Five personality traits. ",Psychological and Personality Profiles of Political Extremists
47,849096316236029955,2562351306,Alexander Engelen,['In this paper we propose a new way to measure the largest scales in the Universe.  <LINK>'],https://arxiv.org/abs/1704.00718,"The observed dipole anisotropy of the cosmic microwave background (CMB) temperature is much larger than the fluctuations observed on smaller scales and is dominated by the kinematic contribution from the Doppler shifting of the monopole due to our motion with respect to the CMB rest frame. In addition to this kinematic component, there is expected to be an intrinsic contribution with an amplitude about two orders of magnitude smaller. Here we explore a method whereby the intrinsic CMB dipole can be reconstructed through observation of temperature fluctuations on small scales which result from gravitational lensing. Though the experimental requirements pose practical challenges, we show that one can in principle achieve a cosmic variance limited measurement of the primary dipole using the reconstruction method we describe. Since the primary CMB dipole is sensitive to the largest observable scales, such a measurement would have a number of interesting applications for early universe physics, including testing large-scale anomalies, extending the lever-arm for measuring local non-Gaussianity, and constraining isocurvature fluctuations on super-horizon scales. ",Reconstructing the Primary CMB Dipole
48,849060755458502656,21611239,Sean Carroll,"[""Hilbert space! It's big, but is it really all that big? New paper in which Ning Bao, Ashmeet Singh and I wonder.\n<LINK>"", '@brettmsinclair Not that I know of.']",https://arxiv.org/abs/1704.00066,"We argue in a model-independent way that the Hilbert space of quantum gravity is locally finite-dimensional. In other words, the density operator describing the state corresponding to a small region of space, when such a notion makes sense, is defined on a finite-dimensional factor of a larger Hilbert space. Because quantum gravity potentially describes superpo- sitions of different geometries, it is crucial that we associate Hilbert-space factors with spatial regions only on individual decohered branches of the universal wave function. We discuss some implications of this claim, including the fact that quantum field theory cannot be a fundamental description of Nature. ",The Hilbert Space of Quantum Gravity Is Locally Finite-Dimensional
49,857959934427901953,2826958076,Abhi Datta,['Paper on new model for spatial disease mapping now on ArXiV\n<LINK>'],https://arxiv.org/abs/1704.07848,"Hierarchical models for regionally aggregated disease incidence data commonly involve region specific latent random effects that are modeled jointly as having a multivariate Gaussian distribution. The covariance or precision matrix incorporates the spatial dependence between the regions. Common choices for the precision matrix include the widely used ICAR model, which is singular, and its nonsingular extension which lacks interpretability. We propose a new parametric model for the precision matrix based on a directed acyclic graph (DAG) representation of the spatial dependence. Our model guarantees positive definiteness and, hence, in addition to being a valid prior for regional spatially correlated random effects, can also directly model the outcome from dependent data like images and networks. Theoretical results establish a link between the parameters in our model and the variance and covariances of the random effects. Substantive simulation studies demonstrate that the improved interpretability of our model reaps benefits in terms of accurately recovering the latent spatial random effects as well as for inference on the spatial covariance parameters. Under modest spatial correlation, our model far outperforms the CAR models, while the performances are similar when the spatial correlation is strong. We also assess sensitivity to the choice of the ordering in the DAG construction using theoretical and empirical results which testify to the robustness of our model. We also present a large-scale public health application demonstrating the competitive performance of the model. ","Spatial disease mapping using Directed Acyclic Graph Auto-Regressive
  (DAGAR) models"
50,857937193628831745,27047369,CÃ©sar A. Hidalgo,"[""How do networks reunify? In this new working paper we study research collaborations during Germany's reunification.\n<LINK> <LINK>""]",https://arxiv.org/abs/1704.08426,"In 1990, Germany began the reunification of two separate research systems. In this study, we explore the factors predicting the East-West integration of academic fields by examining the evolution of Germany's co-authorship network between 1974 and 2014. We find that the unification of the German research network accelerated rapidly during the 1990s, but then stagnated at an intermediate level of integration. We then study the integration of the 20 largest academic fields (by number of publications prior to 1990), finding an inverted U-shaped relationship between each field's East or West ""dominance"" (a measure of the East-West concentration of a field's scholarly output prior to 1990) and the fields' subsequent level of integration. We checked for the robustness of these results by running Monte Carlo simulations and a differences-in-differences analysis. Both methods confirmed that fields that were dominated by either West or East Germany prior to reunification integrated less than those whose output was balanced. Finally, we explored the origins of this inverted U-shaped relationship by considering the tendency of scholars from a given field to collaborate with scholars from similarly productive regions. These results shed light on the mechanisms governing the reintegration of research networks that were separated by institutions. ",Meet me in the middle: The reunification of Germany's research network
51,857263921006231556,18262687,Rushil,"['In a new working paper, we bootstrap graph-CNNs w/ randomized patient graphs and improve ASD classification <LINK>']",https://arxiv.org/abs/1704.07487,"Using predictive models to identify patterns that can act as biomarkers for different neuropathoglogical conditions is becoming highly prevalent. In this paper, we consider the problem of Autism Spectrum Disorder (ASD) classification where previous work has shown that it can be beneficial to incorporate a wide variety of meta features, such as socio-cultural traits, into predictive modeling. A graph-based approach naturally suits these scenarios, where a contextual graph captures traits that characterize a population, while the specific brain activity patterns are utilized as a multivariate signal at the nodes. Graph neural networks have shown improvements in inferencing with graph-structured data. Though the underlying graph strongly dictates the overall performance, there exists no systematic way of choosing an appropriate graph in practice, thus making predictive models non-robust. To address this, we propose a bootstrapped version of graph convolutional neural networks (G-CNNs) that utilizes an ensemble of weakly trained G-CNNs, and reduce the sensitivity of models on the choice of graph construction. We demonstrate its effectiveness on the challenging Autism Brain Imaging Data Exchange (ABIDE) dataset and show that our approach improves upon recently proposed graph-based neural networks. We also show that our method remains more robust to noisy graphs. ","Bootstrapping Graph Convolutional Neural Networks for Autism Spectrum
  Disorder Classification"
52,856954316527194112,590951273,Tom Shanks,['Our paper on the CMB Cold Spot is at <LINK>    RAS press release is at <LINK>'],https://arxiv.org/abs/1704.03814,"We report the results of the 2dF-VST ATLAS Cold Spot galaxy redshift survey (2CSz) based on imaging from VST ATLAS and spectroscopy from 2dF AAOmega over the core of the CMB Cold Spot. We sparsely surveyed the inner 5$^{\circ}$ radius of the Cold Spot to a limit of $i_{AB} \le 19.2$, sampling $\sim7000$ galaxies at $z<0.4$. We have found voids at $z=$ 0.14, 0.26 and 0.30 but they are interspersed with small over-densities and the scale of these voids is insufficient to explain the Cold Spot through the $\Lambda$CDM ISW effect. Combining with previous data out to $z\sim1$, we conclude that the CMB Cold Spot could not have been imprinted by a void confined to the inner core of the Cold Spot. Additionally we find that our 'control' field GAMA G23 shows a similarity in its galaxy redshift distribution to the Cold Spot. Since the GAMA G23 line-of-sight shows no evidence of a CMB temperature decrement we conclude that the Cold Spot may have a primordial origin rather than being due to line-of-sight effects. ",Evidence against a supervoid causing the CMB Cold Spot
53,856686028840718336,12691172,Keenan Crane,"['New paper on conformal parameterization with boundary control: ""Boundary First Flattening (BFF)"": <LINK> (w/ Rohan Sawhney) <LINK>', '@jerrytalton You mean rather than the complex job I have now?']",https://arxiv.org/abs/1704.06873,"A conformal flattening maps a curved surface to the plane without distorting angles---such maps have become a fundamental building block for problems in geometry processing, numerical simulation, and computational design. Yet existing methods provide little direct control over the shape of the flattened domain, or else demand expensive nonlinear optimization. Boundary first flattening (BFF) is a linear method for conformal parameterization which is faster than traditional linear methods, yet provides control and quality comparable to sophisticated nonlinear schemes. The key insight is that the boundary data for many conformal mapping problems can be efficiently constructed via the Cherrier formula together with a pair of Poincare-Steklov operators; once the boundary is known, the map can be easily extended over the rest of the domain. Since computation demands only a single factorization of the real Laplace matrix, the amortized cost is about 50x less than any previously published technique for boundary-controlled conformal flattening. As a result, BFF opens the door to real-time editing or fast optimization of high-resolution maps, with direct control over boundary length or angle. We show how this method can be used to construct maps with sharp corners, cone singularities, minimal area distortion, and uniformization over the unit disk; we also demonstrate for the first time how a surface can be conformally flattened directly onto any given target shape. ",Boundary First Flattening
54,854507090458619906,244840704,Antonio CÃ³rcoles,"['New paper from our group <LINK>\nGreat work, guys! #quantumexperience']",https://arxiv.org/abs/1704.05018,"Quantum computers can be used to address molecular structure, materials science and condensed matter physics problems, which currently stretch the limits of existing high-performance computing resources. Finding exact numerical solutions to these interacting fermion problems has exponential cost, while Monte Carlo methods are plagued by the fermionic sign problem. These limitations of classical computational methods have made even few-atom molecular structures problems of practical interest for medium-sized quantum computers. Yet, thus far experimental implementations have been restricted to molecules involving only Period I elements. Here, we demonstrate the experimental optimization of up to six-qubit Hamiltonian problems with over a hundred Pauli terms, determining the ground state energy for molecules of increasing size, up to BeH2. This is enabled by a hardware-efficient variational quantum eigensolver with trial states specifically tailored to the available interactions in our quantum processor, combined with a compact encoding of fermionic Hamiltonians and a robust stochastic optimization routine. We further demonstrate the flexibility of our approach by applying the technique to a problem of quantum magnetism. Across all studied problems, we find agreement between experiment and numerical simulations with a noisy model of the device. These results help elucidate the requirements for scaling the method to larger systems, and aim at bridging the gap between problems at the forefront of high-performance computing and their implementation on quantum hardware. ","Hardware-efficient Variational Quantum Eigensolver for Small Molecules
  and Quantum Magnets"
55,859417596076183554,53931217,Tom Barclay,['In my new paper we predict @NASAWFIRST will find a dozen Mars-mass free-floating planets but no Earth-mass ones. <LINK>'],https://arxiv.org/abs/1704.08749,"Planets are thought to form via accretion from a remnant disk of gas and solids around a newly formed star. During this process material in the disk either remains bound to the star as part of either a planet, a smaller celestial body, or makes up part of the interplanetary medium; falls into the star; or is ejected from the system. Herein we use dynamical models to probe the abundance and properties of ejected material during late-stage planet formation and estimate their contribution to the free-floating planet population. We present 300 N-body simulations of terrestrial planet formation around a solar-type star, with and without giant planets present, using a model that accounts for collisional fragmentation. In simulations with Jupiter and Saturn analogs, about one-third of the initial (~5 Mearth) disk mass is ejected, about half in planets more massive than Mercury but less than 0.3 Mearth, and the remainder in smaller bodies. Most ejections occur within 25 Myr, which is shorter than the timescale typically required for Earth-mass planets to grow (30-100 Myr). When giant planets are omitted from our simulations, almost no material is ejected within 200 Myr and only about 1% of the initial disk is ejected by 2 Gyr. We show that about 2.5 terrestrial-mass planets are ejected per star in the Galaxy. We predict that the space-borne microlensing search for free-floating planets from the Wide-Field Infra-Red Space Telescope (WFIRST) will discover up to 15 Mars-mass planets, but few free-floating Earth-mass planets. ","The Demographics of Rocky Free-Floating Planets and their Detectability
  by WFIRST"
56,851425949036032000,101857975,Adrian Del Maestro,['Where we study superfluids and atomtronic circuits and solve the Langer-Fisher mystery of *giant* driving pressures <LINK>'],https://arxiv.org/abs/1704.01968,"We investigate the maximum speed at which a driven superfluid can flow through a narrow constriction with a size on the order of the healing length. Considering dissipation via the thermal nucleation of quantized vortices, we calculate the critical velocity for superfluid $^4$He and ultracold atomtronic circuits, identify fundamental length and velocity scales, and are thus able to present results obtained in widely different temperature and density ranges in a universal framework. For ultra-narrow channels we predict a drastic reduction in the critical velocity as the energy barrier for flow reducing thermally activated phase slip fluctuations is suppressed. ",Dissipation in mesoscale superfluids
57,849096316236029955,2562351306,Alexander Engelen,['In this paper we propose a new way to measure the largest scales in the Universe.  <LINK>'],https://arxiv.org/abs/1704.00718,"The observed dipole anisotropy of the cosmic microwave background (CMB) temperature is much larger than the fluctuations observed on smaller scales and is dominated by the kinematic contribution from the Doppler shifting of the monopole due to our motion with respect to the CMB rest frame. In addition to this kinematic component, there is expected to be an intrinsic contribution with an amplitude about two orders of magnitude smaller. Here we explore a method whereby the intrinsic CMB dipole can be reconstructed through observation of temperature fluctuations on small scales which result from gravitational lensing. Though the experimental requirements pose practical challenges, we show that one can in principle achieve a cosmic variance limited measurement of the primary dipole using the reconstruction method we describe. Since the primary CMB dipole is sensitive to the largest observable scales, such a measurement would have a number of interesting applications for early universe physics, including testing large-scale anomalies, extending the lever-arm for measuring local non-Gaussianity, and constraining isocurvature fluctuations on super-horizon scales. ",Reconstructing the Primary CMB Dipole
58,857937193628831745,27047369,CÃ©sar A. Hidalgo,"[""How do networks reunify? In this new working paper we study research collaborations during Germany's reunification.\n<LINK> <LINK>""]",https://arxiv.org/abs/1704.08426,"In 1990, Germany began the reunification of two separate research systems. In this study, we explore the factors predicting the East-West integration of academic fields by examining the evolution of Germany's co-authorship network between 1974 and 2014. We find that the unification of the German research network accelerated rapidly during the 1990s, but then stagnated at an intermediate level of integration. We then study the integration of the 20 largest academic fields (by number of publications prior to 1990), finding an inverted U-shaped relationship between each field's East or West ""dominance"" (a measure of the East-West concentration of a field's scholarly output prior to 1990) and the fields' subsequent level of integration. We checked for the robustness of these results by running Monte Carlo simulations and a differences-in-differences analysis. Both methods confirmed that fields that were dominated by either West or East Germany prior to reunification integrated less than those whose output was balanced. Finally, we explored the origins of this inverted U-shaped relationship by considering the tendency of scholars from a given field to collaborate with scholars from similarly productive regions. These results shed light on the mechanisms governing the reintegration of research networks that were separated by institutions. ",Meet me in the middle: The reunification of Germany's research network
59,850326515266891776,803897648684081153,Rahaf Aljundi,['We propose a new solution to the catastrophic forgetting  when learning tasks sequentially using task autoencoders. <LINK>'],https://arxiv.org/abs/1704.01920,"This paper introduces a new lifelong learning solution where a single model is trained for a sequence of tasks. The main challenge that vision systems face in this context is catastrophic forgetting: as they tend to adapt to the most recently seen task, they lose performance on the tasks that were learned previously. Our method aims at preserving the knowledge of the previous tasks while learning a new one by using autoencoders. For each task, an under-complete autoencoder is learned, capturing the features that are crucial for its achievement. When a new task is presented to the system, we prevent the reconstructions of the features with these autoencoders from changing, which has the effect of preserving the information on which the previous tasks are mainly relying. At the same time, the features are given space to adjust to the most recent environment as only their projection into a low dimension submanifold is controlled. The proposed system is evaluated on image classification tasks and shows a reduction of forgetting over the state-of-the-art ",Encoder Based Lifelong Learning
