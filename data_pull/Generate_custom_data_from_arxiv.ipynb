{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0244c7c3-9287-4a90-8ef7-780453fd849b",
   "metadata": {},
   "source": [
    "Here we generate a dataset of arXiv abstracts based of my (Nitsan's) papers, because it's fun and I can manually evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa84f8d-ac97-4e41-9314-543428ddb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "arxiv_nums = ['2202.10179', '2111.03070', '2102.11522', '1907.05020', '1905.11745', '1903.03402', '1811.11178', '1805.00122', '1608.05030']\n",
    "\n",
    "import arxiv_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325221df-2d42-416b-8fbd-89ebf0144c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = []\n",
    "for arxiv_num in arxiv_nums:\n",
    "    title, author_list, abstract = arxiv_utils.get_arXiv_details('https://arxiv.org/abs/'+arxiv_num)\n",
    "    abstracts.append(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850c6869-a6ca-4869-bf7b-17649906cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Abstract'] = abstracts\n",
    "df['Tweets'] = '<>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa43f29b-6cb2-4900-84a2-13a3bdd72a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultra-diffuse galaxies that contain a large sa...</td>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We look for and place observational constraint...</td>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We investigate what the orbits of globular clu...</td>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We present a critical assessment of the SN1987...</td>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Measurements of the dynamical environment of s...</td>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analytic arguments and numerical simulations s...</td>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We study the ratio of neutrino-proton elastic ...</td>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bosonic ultra-light dark matter (ULDM) would f...</td>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Turbulent thermal diffusion is a combined effe...</td>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract Tweets\n",
       "0  Ultra-diffuse galaxies that contain a large sa...     <>\n",
       "1  We look for and place observational constraint...     <>\n",
       "2  We investigate what the orbits of globular clu...     <>\n",
       "3  We present a critical assessment of the SN1987...     <>\n",
       "4  Measurements of the dynamical environment of s...     <>\n",
       "5  Analytic arguments and numerical simulations s...     <>\n",
       "6  We study the ratio of neutrino-proton elastic ...     <>\n",
       "7  Bosonic ultra-light dark matter (ULDM) would f...     <>\n",
       "8  Turbulent thermal diffusion is a combined effe...     <>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3169d631-4e27-41b5-8662-b6f70226567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in /data folder in parent directory\n",
    "from pathlib import Path\n",
    "import os\n",
    "path_here = os.getcwd()\n",
    "path = Path(path_here)\n",
    "df.to_csv(str(path.parent.absolute())+'/data/custom_data_my_papers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e316c4f-875c-44d5-a9b6-579a8a2b9ba7",
   "metadata": {},
   "source": [
    "## Sagie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050b1aba-d5da-41f6-8a4e-0c22b4e064b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "arxiv_nums = ['2109.08085', '2103.15359']\n",
    "\n",
    "import arxiv_utils\n",
    "\n",
    "abstracts = []\n",
    "for arxiv_num in arxiv_nums:\n",
    "    title, author_list, abstract = arxiv_utils.get_arXiv_details('https://arxiv.org/abs/'+arxiv_num)\n",
    "    abstracts.append(abstract)\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['Abstract'] = abstracts\n",
    "df['Tweets'] = '<>'\n",
    "\n",
    "#df.to_csv('custom_data_sagie.csv')\n",
    "\n",
    "# save in /data folder in parent directory\n",
    "from pathlib import Path\n",
    "import os\n",
    "path_here = os.getcwd()\n",
    "path = Path(path_here)\n",
    "df.to_csv(str(path.parent.absolute())+'/data/custom_data_sagie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e6e1e-bbee-4440-9766-ee4392d78b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
